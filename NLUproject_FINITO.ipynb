{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLUproject.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "d297a312"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b0f6519363854974810a92c69e572157": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b668ec350d634a32bfd0fb0bc753d87a",
              "IPY_MODEL_5740f58f84c34a7e99f4984db13b956e",
              "IPY_MODEL_900fedd80c984cdaa1df431f4105c2c0"
            ],
            "layout": "IPY_MODEL_a7395d0b5ee54e66ae7d9ea177ecd3b1"
          }
        },
        "b668ec350d634a32bfd0fb0bc753d87a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06bd04b9f45e4b2ca28e34b9c754f10d",
            "placeholder": "​",
            "style": "IPY_MODEL_2c73d229ee7541c1aaaad011b778ac17",
            "value": "100%"
          }
        },
        "5740f58f84c34a7e99f4984db13b956e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_239b4b7a0c17452c92ac6a4d89ae2a36",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c306494f41b44a9a017adce5e4286d7",
            "value": 1
          }
        },
        "900fedd80c984cdaa1df431f4105c2c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21111f4e1d6648469abb292abb5b2a48",
            "placeholder": "​",
            "style": "IPY_MODEL_68599ee639e842c2b60698074d3ae49d",
            "value": " 1/1 [09:34&lt;00:00, 574.34s/it]"
          }
        },
        "a7395d0b5ee54e66ae7d9ea177ecd3b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06bd04b9f45e4b2ca28e34b9c754f10d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c73d229ee7541c1aaaad011b778ac17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "239b4b7a0c17452c92ac6a4d89ae2a36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c306494f41b44a9a017adce5e4286d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21111f4e1d6648469abb292abb5b2a48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68599ee639e842c2b60698074d3ae49d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fc367d32f4747afbe6379241d72ba91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12d973bbeeab4dcd820f0b1ac9d6b8d8",
              "IPY_MODEL_0c2749ba96854a09a48d33006c598696",
              "IPY_MODEL_3178e1bdc24a407ea2e04b2071c54c5a"
            ],
            "layout": "IPY_MODEL_80303f59b7ef4ac1ba9897af6b2f8ae8"
          }
        },
        "12d973bbeeab4dcd820f0b1ac9d6b8d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83f5c7c431314521bb9d91bfc8a35aec",
            "placeholder": "​",
            "style": "IPY_MODEL_1c465efdb5204bb28f6ef17068716654",
            "value": " 12%"
          }
        },
        "0c2749ba96854a09a48d33006c598696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37eef8c9c2384f6b8742fa5f8e328583",
            "max": 199,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6c2604234224cf8ad51871e77508d0b",
            "value": 23
          }
        },
        "3178e1bdc24a407ea2e04b2071c54c5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db10a3b69a324900a0f53d8d37380041",
            "placeholder": "​",
            "style": "IPY_MODEL_29239bb39e234d40bc1929f514e001f3",
            "value": " 23/199 [09:30&lt;1:09:27, 23.68s/it]"
          }
        },
        "80303f59b7ef4ac1ba9897af6b2f8ae8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83f5c7c431314521bb9d91bfc8a35aec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c465efdb5204bb28f6ef17068716654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37eef8c9c2384f6b8742fa5f8e328583": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6c2604234224cf8ad51871e77508d0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db10a3b69a324900a0f53d8d37380041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29239bb39e234d40bc1929f514e001f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **NLU final project - Barba Edoardo**\n",
        "##Intent Classification and Slot Filling"
      ],
      "metadata": {
        "id": "jFTrITijzLzX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "80808524"
      },
      "outputs": [],
      "source": [
        "# Global variables\n",
        "import os\n",
        "device = 'cuda:0'\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
        "PAD_TOKEN = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2AvSsQtQClbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1dbc948-5d9d-415c-c949-5ae2d9cd1aa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
      ],
      "metadata": {
        "id": "UzgUWSV9ZxSv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data preparation"
      ],
      "metadata": {
        "id": "BEA7KL_Q34gx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to load dataset"
      ],
      "metadata": {
        "id": "dx6eQTIJbfhw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3e1ea7f1"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pprint import pprint\n",
        "\n",
        "def load_data(path):\n",
        "    '''\n",
        "        input: path/to/data\n",
        "        output: json \n",
        "    '''\n",
        "    dataset = []\n",
        "    with open(path) as f:\n",
        "        dataset = json.loads(f.read())\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load ATIS train and test set"
      ],
      "metadata": {
        "id": "cnUAHF15bpT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_ATIS_train_raw = load_data(os.path.join('drive', 'MyDrive', 'data','ATIS','train.json'))\n",
        "ATIS_test_raw = load_data(os.path.join('drive','MyDrive', 'data','ATIS','test.json'))\n",
        "print('Train samples:', len(tmp_ATIS_train_raw))\n",
        "print('Test samples:', len(ATIS_test_raw))"
      ],
      "metadata": {
        "id": "F-TUB-_CbbWV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ed2b61d-b113-4b17-8210-e0f96c8847e5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 4978\n",
            "Test samples: 893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(tmp_ATIS_train_raw[0])"
      ],
      "metadata": {
        "id": "vD_88s6G0DfG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7338047-6193-4ab5-fdb2-e3f56d0fed48"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'intent': 'flight',\n",
            " 'slots': 'O O O O O B-fromloc.city_name O B-depart_time.time '\n",
            "          'I-depart_time.time O O O B-toloc.city_name O B-arrive_time.time O O '\n",
            "          'B-arrive_time.period_of_day',\n",
            " 'utterance': 'i want to fly from boston at 838 am and arrive in denver at '\n",
            "              '1110 in the morning'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load SNIPS train and test set\n"
      ],
      "metadata": {
        "id": "hMVVUSxitg3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_SNIPS_train_raw = load_data(os.path.join('drive', 'MyDrive', 'data','SNIPS','train.json'))\n",
        "SNIPS_test_raw = load_data(os.path.join('drive','MyDrive', 'data','SNIPS','test.json'))\n",
        "print('Train samples:', len(tmp_SNIPS_train_raw))\n",
        "print('Test samples:', len(SNIPS_test_raw))"
      ],
      "metadata": {
        "id": "z7W91yIMtqKm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c74a33e-3698-4bd6-acc0-002747d070da"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 13084\n",
            "Test samples: 700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(tmp_SNIPS_train_raw[0])"
      ],
      "metadata": {
        "id": "xsGWYShG0Isl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7e5d2e5-e435-4238-89c6-78b833224fac"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'intent': 'PlayMusic',\n",
            " 'slots': 'O O B-artist O B-album O B-service I-service',\n",
            " 'utterance': 'listen to westbam alumb allergic on google music'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create validation set"
      ],
      "metadata": {
        "id": "DSyG0mNH4HSA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ccd6da44"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "\n",
        "def create_dev(tmp_train_raw, test_raw):\n",
        "\n",
        "  portion = round(((len(tmp_train_raw) + len(test_raw)) * 0.10)/(len(tmp_train_raw)),2)\n",
        "\n",
        "  intents = [x['intent'] for x in tmp_train_raw] \n",
        "\n",
        "  count_y = Counter(intents) \n",
        "\n",
        "  Y = []\n",
        "  X = []\n",
        "  mini_Train = []\n",
        "\n",
        "  for id_y, y in enumerate(intents):\n",
        "      if count_y[y] > 1: # Some intents have only one instance, we put them in training\n",
        "          X.append(tmp_train_raw[id_y])\n",
        "          Y.append(y)\n",
        "      else:\n",
        "          mini_Train.append(tmp_train_raw[id_y])\n",
        "          \n",
        "  # Random Stratify\n",
        "  X_train, X_dev, y_train, y_dev = train_test_split(X, Y, test_size=portion, \n",
        "                                                      random_state=42, \n",
        "                                                      shuffle=True,\n",
        "                                                      stratify=Y)\n",
        "  X_train.extend(mini_Train)\n",
        "  train_raw = X_train\n",
        "  dev_raw = X_dev\n",
        "\n",
        "  y_test = [x['intent'] for x in test_raw]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  return train_raw, dev_raw, test_raw, y_train, y_dev, y_test\n",
        "  #some intents are not present in train set!!!!!!!!!!!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ATIS_train_raw, ATIS_dev_raw, ATIS_test_raw, ATIS_y_train, ATIS_y_dev, ATIS_y_test = create_dev(tmp_ATIS_train_raw, ATIS_test_raw)"
      ],
      "metadata": {
        "id": "kGlWhFQ-6LDZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SNIPS_train_raw, SNIPS_dev_raw, SNIPS_test_raw, SNIPS_y_train, SNIPS_y_dev, SNIPS_y_test = create_dev(tmp_SNIPS_train_raw, SNIPS_test_raw)"
      ],
      "metadata": {
        "id": "oYWaTrLg6tAv"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_data_distr(train_raw, dev_raw, test_raw, y_train, y_dev, y_test):\n",
        "  #Number of labels \n",
        "  print(\"Number of Intent labels: \", len(Counter(y_train + y_test + y_dev)))\n",
        "  \n",
        "  # Intent distribution\n",
        "  print('Train:')\n",
        "  odict = {k:round(v/len(y_train),3)*100 for k, v in sorted(Counter(y_train).items())}\n",
        "  plt.barh(list(odict.keys()), odict.values(), align = 'center')\n",
        "  plt.show()\n",
        "  #pprint({k:round(v/len(y_train),3)*100 for k, v in sorted(Counter(y_train).items())})\n",
        "  print('Dev:')\n",
        "  odict = {k:round(v/len(y_dev),3)*100 for k, v in sorted(Counter(y_dev).items())}\n",
        "  plt.barh(list(odict.keys()), odict.values(), align = 'center')\n",
        "  plt.show()\n",
        "  #pprint({k:round(v/len(y_dev),3)*100 for k, v in sorted(Counter(y_dev).items())})\n",
        "  print('Test:') \n",
        "  odict = {k:round(v/len(y_test),3)*100 for k, v in sorted(Counter(y_test).items())}\n",
        "  plt.barh(list(odict.keys()), odict.values())\n",
        "  plt.show()\n",
        "  #pprint({k:round(v/len(y_test),3)*100 for k, v in sorted(Counter(y_test).items())})\n",
        "  print('='*89)\n",
        "  #print(\"train_raw[0]: \", train_raw[0])\n",
        "\n",
        "  # Dataset size\n",
        "  print('TRAIN size:', len(train_raw))\n",
        "  print('DEV size:', len(dev_raw))\n",
        "  print('TEST size:', len(test_raw))"
      ],
      "metadata": {
        "id": "G0XaQqc584Xg"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Intent distribution"
      ],
      "metadata": {
        "id": "4KtJEAgY9jko"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ATIS"
      ],
      "metadata": {
        "id": "qVyZG8iY9sTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_data_distr(ATIS_train_raw, ATIS_dev_raw, ATIS_test_raw, ATIS_y_train, ATIS_y_dev, ATIS_y_test)"
      ],
      "metadata": {
        "id": "KirdAuR89pBD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 900
        },
        "outputId": "531c1a63-7cf5-4109-bb93-b7225fd6ff40"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Intent labels:  22\n",
            "Train:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dev:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbcAAAD4CAYAAABv7qjmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZRcZZ3/8feHJIQtJCwZTgTGdjCYYQ3Q7KBBAiOgEH7AsIkJIAwuxGVwBEGJiiMzOMMimwEhoAxkWM0AsoU9w5LOThKWQeJRRPaEJYCSfH9/3KfIpajqruqu6qqu/rzO6dNVd3nut+o0eXjuvc/nKiIwMzNrJas1ugAzM7Nac+dmZmYtx52bmZm1HHduZmbWcty5mZlZyxnY6AIMNtxww2hra2t0GWZmfcqsWbNeiYjhpda5c2sCbW1tdHR0NLoMM7M+RdLvy63zaUkzM2s57tzMzKzluHMzM7OW487NzMxajjs3MzNrOe7czMys5bhzMzOzluPOzczMWo47tyaw4PlltJ16W6PLMDNrGe7cKiTpm5LWyr2/XdKw9PPVRtZmZmYf5s6tct8EPujcImL/iFgKDAPcuZmZNZGW6dwknS7paUkPS7pW0imS7pfUntZvKGlJet0m6SFJs9PPbmn5mLTPDZKelHSNMhOBjwH3SbovbbtE0obA2cBmkuZKOkfS1ZLG5eq6RtJBvfx1mJn1ay0RnCxpB+AIYDTZZ5oNzOpkl5eAfSLiXUkjgWuB9rRuO2BL4E/ADGD3iLhA0reBvSLilaK2TgW2iojRqZbPAN8CbpE0FNgNGF+i5hOBEwEGrFsy1NrMzLqpVUZuewI3R8TyiHgDmNbF9oOAyyQtAK4Htsitezwi/hgRK4G5QFs1hUTEA8BIScOBI4EbI+L9EttNjoj2iGgfsNbQag5hZmZdaImRWyfeZ1UHvkZu+beAF4Ft0/p3c+vey71eQfe+o6uBL5KNJo/txv5mZtYDrTJyexAYJ2lNSUOAL6TlS4Ad0utDc9sPBV5Io7NjgAEVHONNYEiFy6eQ3YBCRCyqoG0zM6uhlujcImI2MBWYB/wWmJlW/Qz4iqQ5wIa5XS4GxkuaB4wC3q7gMJOBOwo3lOSO/SowQ9ITks5Jy14EFgNXVlL/1hsPZcnZB1SyqZmZVUAR0egaak7SJOCtiPhZg46/FrAA2D4ilnW1fXt7e/hJ3GZm1ZE0KyLaS61riZFbM5E0lmzU9vNKOjZYlVDilBIzs9poyRtKImJSA499D/BxyObTAbdGxFaNqsfMrD/yyM3MzFqOO7ckpZY8KWlKSjq5RtJYSTMkPSNpJ0lrS7pC0uOS5hSSR8olnpiZWWO05GnJHvgkcBhwHNkdl0cBewAHAt8DFgH3RsRxkoYBj0u6h84TT0pyQomZWf24c/uw5yJiAYCkhcD0iIiUZNIGbAIcKOmUtP0awN+SRXVdKGk02cTvzbs6UERMJptewOARI1vvllUzswZy5/Zh+XSSlbn3K8m+qxXAIRHxVH6nNPWgXOKJmZn1Ml9zq86dwMmSBCBpu7S8O4knZmZWJx65VefHwHnAfEmrAc8BnydLPLlR0peAO6gs8eQDW288lA4nlJiZ1UxLJpT0NU4oMTOrXmcJJR65NYFCQklPOZ/SzCzja25mZtZy+nTnJmlS7rb83jpmu6QLevOYZmZWnbqflpQ0sNSTqJtZZzVHRAfgC2RmZk2sxyM3Sd+X9JSkhyVdK+kUSfdLOk9SB/ANSXunuKoFKb5qcNp3iaQN0+t2Sfen15PSdvdL+p2kibnjnZ7isR4GPtVFbRMlLZI0X9J1aVm5CK0JkqZJuheYLuk6SQfk2poi6VBJYyTdmpatI+nK9LnmSzokLd9X0iMpiut6SeuUqO1ESR2SOlYsr+jhAWZmVqEejdwk7QgcQjZ5eRAwG5iVVq8eEe2S1gCeAfaOiKclXQ18heyW+s6MAvYie8r1U5IuAbYBjgBGp9rzxyvlVOATEfFeissCOJ3SEVoA2wPbRMRrkg4G/hG4TdLqwN6p7p1z7X8fWBYRW6fvY73UWZ8BjI2ItyV9F/g28KN8YU4oMTOrn56O3HYHfhMR70bEm8D/5NZNTb8/RRZr9XR6fxXw6Qravi0i3ouIV8iyGzcC9gRujojlEfEGMK2LNuYD10j6IlA4zbgvcKqkucD9rIrQArg7Il5Lr38L7JVGmfsBD0bEO0XtjwUuKryJiNeBXYAtyJ7OPRcYT3oEjpmZ9Y56XnOrZCLz+6zqYNcoWpePwlpB92o9gKwj/QJwuqStAVE6QmvnfM0pBPl+4B+Aw4HrKjymyDrJI7tRr5mZ1UBPO7cZwC8k/TS19XnSqbacp4A2SZ+MiP8ji6d6IK1bAuxANko6pILjPQhMyR3vC8AvSm2YEkQ2jYj70vW5I4B1WBWhdXIKRd4uIuaUOd5U4MtkCf8TSqy/G/ga8M10zPWAR4GLCp9X0trAxrmR60c4ocTMrLZ6dFoyImaSnRqcT9ZBLQCWFW3zLnAscH1K118JXJpW/xA4P914sqKC480m63DmpePN7GTzAcCv0zHnABdExFKyCK1BZBFaC9P7cu4CPgPcExF/KbH+LGA9SU9ImgfsFREvk3WE10qaDzxCdv3QzMx6SY/jtyStExFvSVqLbGR1YuqErEKDR4yMEeNX3V/jpBEzs67VO35rsqQtyK6ZXeWOzczMGq3HnVtEHFWLQnpC0kVkd27mnR8RV3ax3yTgrYj4WZn1o8huJAng0Ih4tgblmplZnTV9cHIlCScR8bU6HX4ccENEnFXpDpIGRESX1w/NzKx+Gp4t2awJJ5L2J7sL8iuS7kvLbpE0S9JCSSfmtn1L0n+km0p2lfTFlIAyV9IvJH3k4aVOKDEzq5+Gdm5FCSf7kd1yX7B6ulB4ETAFODwlgQwkSwrpyiiyOWo7AWdKGiRpB1YlnOwP7Fhu54i4neyuznMjYq+0+LiI2CHVOVHSBmn52sBjEbEt8CrZvLjdI2I02V2gR5dof3JEtEdE+4C1hlbwcczMrFKNHrk1e8JJsYlpdPYosCkwMi1fAdyYXu9NNndvZkoo2Rv4uyqPY2ZmPdDM19yaIeHkA5LGkMVt7RoRy9Mp0MIx381dZxPZXaOn9eR4ZmbWfY0euc0AviBpjZSc//kS23yQcJLel0o4gcoTTsZJWlPSELKEk0oNBV5PHdsosgzJUqYDh0r6GwBJ60vqNFty642HsuTsAz74MTOznmlo59bkCSfF7gAGSloMnE12arLUMRaRPRXgrpRQcjcwoorjmJlZD/U4oaTHBTjhhMEjRsZ7LzzT6DLMzPqUeieU9JQTTszMrKYafc2NiDgqIkZHxKiI+GlhubKnaC+W9LykC9OykyR9qbP2lD1R+8Iy675XZvlFaU7aAkl/SK+PlfQxSTf05POZmVnva4aRWzlfJbs7cSxp/ltEXNrpHl37HvCvxQsLCSeS2oBb0/y0gkN7eEwzM+tlDR+5lSLpUrK5Yb8F1sstnyTplPR6R0nz0yjrHElP5Jr4mKQ7JD0j6d/T9mcDa6btrylz6LOBzXJtthXaTSPCWyTdnZJRvi7p2yk55VFJ66ftNkvHniXpoXRnZanP6IQSM7M6acrOLSJOAv4E7AW8XmazK4F/yqWA5I0mSwnZGjhc0qYRcSrwTjoF+pHEkORU4Nm0zXdKrN8K+H9kySY/AZZHxHZkz2wrnC6dDJyckkxOAS4u8xmdUGJmVifNfFqyLEnDgCER8Uha9F98eI7c9IhYlrZdBHwc+EMNDn1fSlJ5U9IyViWqLAC2SXP1diObtlDYZ3ANjmtmZlXok51bBWqaTlKm3ZW59yvTMVYDlhZdszMzs17WlKcluxIRS8lGTzunRUdUuOtfJQ3qZP2bwJAe1PUG8JykwwCU2bar/bbe2KclzcxqqU92bsnxwGUpnHhtipJNypgMzC93Q0lEvArMkPSEpHO6WdfRwPEpYHkhcFA32zEzs25qeEJJdxWSTdLrU4EREfGNBpfVLU4oMTOrXrMnlHTXAZJOI/sMvwcmNLYcMzNrFl2eluzNpJBqRMTUdMv+VhFxQES8XOm+kjZIc9nmplOQS9PrDYq2y89za5d0QU/rNjOz+qtk5NZrSSG1ImlJRLSVW5+urXV6R6OkD303EdEBdNSkQDMzq6tOR26NSgpJI6bFki6TtFDSXZLWTOtGp0SQ+ZJulrReqTbKtPmQpNnpZ7fc8nwKyTRJ95I9ly2//xhJt+Y+/xWS7pf0O0kTc9t9UdLj6fP9QtKAMvU4ocTMrE467dwamBQCMBK4KCK2BJay6mGkVwPfjYhtyCZPn9nZZ8h5CdgnIrZPNZU7xbg9cGhEfKaL9kYB/wDsBJwpaZCkv09t7577Pkp+RieUmJnVT49uKKlzUshzETE3vZ5F9jTuocCwiCg8ifsq4PrU/unAYWn5x9IUAYAZKRh5EHChpEKns3mZ494dEa9VUN9tEfEe8J6kl4CNgL3Jngw+MyWUrEnWqZqZWS+q992SPUkKKd53zc42joifkOU9Fq65FV9T+xbwIrAt2Yj13TJNvd3N+gYCInsm3WkVtmFmZnXQo0ncdUwKKXe8ZcDrkvZMi44BHuhkl7yhwAsRsTLtV/JaWA9NBw6V9DcAktaX9PGudnJCiZlZbdUioaTmSSFdGA+cI2k+2TW9H1W438XA+JQcMorKR2gVi4hFwBnAXam+u4ERtT6OmZl1rscJJa2UFNIog0eMjBHjz/vg/ZKzD2hgNWZmfUO9E0qcFGJmZk2lx6cla5gUkv/ZoOu9P2ijKRNUzMyscRqaLVlJUkgF+lyCipmZ1VdffuRNn05QcUKJmVn99OnOrS8nqDihxMysfvp059aVMgkqedMjYllEvAsUElQqVWmCyqe7Wb6ZmXVTS3duFahlgkpffjaemVlLael/kCNiqaQ3Je0cEY9RZYJKRPy1yuMtk/S6pD0j4iEqTFDZeuOhdHhum5lZzbR055YUElRWknU01SSozO7iulsp44FLJa0F/A44tsr9zcysh3qcUNLs+kKCyuARI+O9F55pdBlmZn1KZwklvXbNrYGTrQ9It/U/AewJnFWinbJ1FE0r+JGksRUc08zMGqjXRm6SniQ32Toivl7hfhPKbS/prYhYp8TyMcCEiJjQw5r/BphPdsNIPnll7zQBvSY8cjMzq17DR26Nmmxdoo4TJM2UNE/Sjem6WHEd90s6T1IH2Q0hlwLnpnlyc4GzIuJVSUsk/VDSbEkLJI1K+68t6QpJj0uaI+mgnn17ZmZWrV7p3Bo82TrvpojYMSK2BRaT3WxSyuppgvV/dNHeKxGxPXAJcEpadjpwb0TsRPZ5z5G0dvGOTigxM6ufppjnVqvJ1pIeU/ZcucuBA3NBzP+QNtlK0kOSFgBHA1uWKWlqhaXflH7PAtrS632BU1Md9wNrAH9bvKMTSszM6qevTAWoaMJ0ROwMnV5zmwKMi4h56VremDLHq/RBpoW68jUJOCQinqqwDTMzq7GmGLlFxFLgTUk7p0VVTbau4lBDgBfSPtXOX6vUncDJkgQgabs6HcfMzMpois4tKUy2ngusTXWTrSu6oQT4PvAYMAN4sltVdu3HwKBU18L0vlNbb+zTkmZmtdQ0k7j7wmTremlvb4+Ojo5Gl2Fm1qd0NhWgma65HSDpNLKafg9MaGw5vWfB88toO/W2jyxf4rxJM7NuqftpyUqTSSJiarqtf6uIOICss+tJMkkltXWWTDI83X05R9KetTiemZn1jt645vZVYB+y+V8ARMSlEXF1D9os2blJGiNpSqWNlKtD0kBgb2BBRGyXEv67JGlApcc2M7P6qWvn1oeTSb4B/DtwUDrOmpIuSZOuF0r6Ya7tJZL+TdJs4DBJ+0p6JCWXXC/pI/FgZmZWX3Xt3Pp4MskPgMKp0neA09OFy22Az0jaJrffqymp5B7gDGBset8BfLvUgZxQYmZWPw29oaRMMsnnc5tMj4hladtCMskfSrTzGDAYWAdYP00nAPhuRNxJlkxyFjAsbXNnmZI6Syb5R0knkn1nI4AtyEKV8/vtkpbPSNPcVgceoYSImEw2lYHBI0Y2xy2rZmYtopnuliylKZJJJH2CLDtyx4h4PV3XW6PEfgLujogjy7RvZma9oKGTuPtQMsm6ZB3YMkkbAfuV2e5RYHdJn4QPnhCweTeOZ2ZmPdAMI7dCMslK4AGqSyaZXeF1t0Iyycvp95BqCkwjvjlkqSZ/IEs4KbXdy2lkeK2kwWnxGcDTnbW/9cZD6fCcNjOzmml4Qkl/TiYpcEKJmVn1mj2hpN8mkxSUSygxM2tl9UxhanhwcnEySUS83Ig6Kk1SKbHfhHonqZiZWXUa3rk1kV5LUjEzs/py50bzJKmYmVltuHOjMUkqTigxM6sfd24VKJOkkjc9IpZFxLtAIUmlUxExOUV9tQ9Yyw8rNTOrJXdutVFRkoqZmfUOd24V6MUkFTMzqwGPMCpXtyQVJ5SYmdVWwxNK+op6Jqk4ocTMrHrNnlDSV9QtSaVUQkk9Z+6bmbW6luvcJE0C3iJL8n8wIu4ps9044OmIWFRJuxExlc6f92ZmZk2iZW8oiYgflOvYknFkDxY1M7MW0xKdm6TTJT0t6WHgU2nZFEmHptdnS1qUEkZ+Jmk34EDgnJQgspmkEyTNlDRP0o2S1sq1c4Gk/5X0u0Kbad13JS1I+5ydlm2W0kpmSXpI0qhe/0LMzPq5Pn9aUtIOZLfmjyb7PLOBWbn1GwAHA6MiIiQNi4ilkqYBt0bEDWm7pRFxWXp9FtndkT9PzYwA9gBGAdOAGyTtBxwE7BwRyyWtn7adDJwUEc+kqQMXA58tUfeJwIkAA9YdXrsvxMzM+n7nBuwJ3BwRywFSp5W3DHgX+KWkW4Fby7SzVerUhgHrAHfm1t0SESuBRelJ3ABjgSsLx42I1yStA+wGXC+psO9gSoiIyWQdIYNHjPQtq2ZmNdQKnVunIuJ9STsBewOHAl+nxEgKmAKMS0/dngCMya3LJ5CI8lYDlqb8STMza5BWuOb2IDBO0pqShgBfyK9Mo6mhEXE78C1g27TqTWBIbtMhwAspUaTshOucu4Fjc9fm1o+IN4DnJB2WlknStp01YmZmtdfnR24RMVvSVGAe8BIws2iTIcBvJK1BNur6dlp+HVniyESyEd33gceAl9PvIXQiIu6QNBrokPQX4Hay57cdDVwi6QxgUDrOvM7ackKJmVltOaGkCTihxMysep0llLTCack+b8Hzfp6bmVktuXMzM7OW06c6N0mTJJ3S6DrMzKy59anOzczMrBJN37mVidb6SFSWpCGSnis8HFTSuvn3Jdq9X9K/SXo8tb9nWt6WYrNmp5/d0vIxkh6Q9JsUw3W2pKPT/gskbZa2G55qmpl+di9z/BMldUjqWLHc19zMzGqpqTu3omit/YEd06qbImLHiNgWWAwcHxFvAvcDhXvqj0jb/bWTQwyMiJ2AbwJnpmUvAftExPbA4cAFue23BU4C/h44Btg87X85cHLa5nzg3IjYETgkrfuIiJgcEe0R0T5graFdfxlmZlaxZp/nVi5aq1xU1uXAvwC3AMcCJ3TR/k3p9yygLb0eBFyY5rCtADbPbT8zIl5ItTwL3JWWLwD2Sq/HAlvk4rfWzT/o1MzM6q/ZO7dyplAiKisiZqTTimOAARHxRBftFGK1VrDqu/gW8CLZKG01slzK4u0BVuber8ztvxqwS0Tk9zMzs17U1KclKR+t1VlU1tXAfwFXdvOYQ4EXUlDyMcCAKve/i1WnKEkjwE5tvbFPS5qZ1VJTd24RMZvs6dfzgN+yKlqrEJU1A3iyaLdrgPWAa7t52IuB8ZLmkT3i5u0q958ItKdnxy0iu0ZnZma9qOXit9LDRA+KiGMaXUulBo8YGSPGnwfAEmdMmplVpLP4rb56za0kST8H9iO7s7LexzoJWB4RV6frfndFxJ/qfVwzM+taS3VuEXFy8TJJFwHFc83Oj4juXpMrHOvS3NsJwBOAOzczsybQUp1bKRHxtVq0I+lLwClAAPOBZ4G3gCVAO3CNpHeA04ETImJc2m8f4KsRcXAt6jAzs6419Q0lzULSlsAZwGfTxPFvFNZFxA1AB3B0egL37cAoScPTJscCV5Ro0wklZmZ14s6tMp8Fro+IVwAi4rVyG0Z2h86vgC9KGgbsSnanZ/F2TigxM6uTlj8t2SBXAv9DNgH8+oh4v8H1mJn1Kx65VeZe4DBJGwBIWr9o/ZtkE8sBSHdN/onsVGaPblwxM7PqeeRWgYhYKOknwAOSVgBzyG4kKZgCXJpuKNk1It4hm0w+PCIWd9X+1hsPpcPz28zMasadW4Ui4irgqjLrbgRuLFq8B3BZvesyM7OPcudWB5JmkcV2/XMl2y94fhltp95WUdtOMDEz65qvuXWTpJPS3DckTZD0scK6iNghIj4dEe+Vb8HMzOrFI7duckKJmVnzapmRm6QvpST+eZJ+JekLkh6TNEfSPZI2SttNSusfkfSMpBPS8nUkTZc0W9ICSQeVazvXzikpqLmQUDJX0gGSbsntu4+km3v32zAz699aYuSWSxDZLSJeSbfqB9lDQ0PSl8me0F24BrYNsAuwNjBH0m3AS8DBEfGGpA2BR9OTv7co0fYHIuIGSV8HTomIDmWP4P4PScMj4mU6SSgBTgQYsO7w4tVmZtYDrTJyK5Ugsglwp6QFwHeALXPb/yYi3knb3wfsBAj4V0nzgXuAjYGNyrRdlhNKzMwaryVGbmX8HPjPiJgmaQwwKbeu+CF2QfZE7+HADhHxV0lLgDW6eWwnlJiZNVCrjNxKJYgMBZ5P68cXbX+QpDXS9mPInvA9FHgpdWx7AR/vpO1iTigxM2siLTFyK5MgMgm4XtLrZB3UJ3K7zCc7Hbkh8OOI+JOka4D/SacxO4AnO2l7QlEJU3BCiZlZ01B2iaj/kDQJeCsiflbn41wIzImIX3a1bXt7e3R0dNSzHDOzliNpVkS0l1rXEiO3ZlOPhBInk5iZVa7fdW4RMSn/XtLtwFERsbSGx9ghtT1O0tMRsahWbZuZWdda5YaSbouI/Ys7NmV69N1IGgiMI5snZ2ZmvahfdW6SbpE0S9LCNIkaSUskbSipTdJTkq4mi9LaVNJbks5N20+XNDztM1rSoym15GZJ66Xl90s6T1IH8F3gQOCclFyyWYM+tplZv9OvOjfguHTKsB2YWLi9P2ckcHFEbBkRvydLMOmIiC2BB4Az03ZXA9+NiG2ABbnlAKunydk/AaYB34mI0RHxbP5Akk6U1CGpY8XyZTX/oGZm/Vl/69wmSpoHPApsStaZ5f0+Ih7NvV8JTE2vfw3sIWkoMCwiHkjLrwI+ndtnKhVwQomZWf30mxtKUkrJWLJ5aMsl3c9HE0je7qKZSuZNdNWGmZnVWX8auQ0FXk8d2yiy4OSurAYcml4fBTwcEcuA1yXtmZYfQ3bKspQPJZeYmVnv6DcjN+AO4CRJi4GnyE5NduVtYCdJZ5A9NeDwtHw8WSLJWsDvyJL/S7kOuEzSRODQ4utuBU4oMTOrrX6XUFINSW9FxDr1Po4TSszMqueEkiZXSUJJNZxmYmb9XX+65tYpSben5699oDBqK8yFS6//txH1mZlZ5TxySyJi/+Jl6anaKtput14ryszMuqVfjtyqTSop2vet9HtMSiS5QdKTkq5JnSGSdpD0QDrGnZJG9PZnNDPrz/rryO24iHhN0prATEk3Fq0fCYwvTOhOfVYp2wFbkj2YdAawu6THyJ4CflBEvCzpcOAnwHH5HVOneiLAgHWH1+ZTmZkZ0H87t4mSDk6vK0kqKefxiPgjgKS5QBuwFNgKuDt1igOAF4p3jIjJwGSAwSNG+pZVM7Ma6nedW42SSgrey71eQfZ9ClgYEbv2sFQzM+um/njNrTtJJdV4ChguaVcASYMkbVnjY5iZWSf63ciN7iWVVCwi/iLpUOCCFLI8EDgPWFhuHyeUmJnVlhNKmoATSszMqtdZQkl/PC3ZdBY87+e5mZnVUsM6t1KJILl1h0laLOm+XqplzzTnba6kv5f0RFreLumCLvZtK2xfYt0ESR+rR81mZlZewzq3iNg/IpbmlymzGnA8cEJE7FVJW5IqunaYOptJJVYdDfw0IkYD7+Rq7IiIiZW0XcYEwJ2bmVkv65XOrcpEkO8DewC/lHROWv+QpNnpZ7e0/5i0fBqwSNKAtP1MSfMl/VOFtX0Z+Efgx5KuKVo3RtKt6fVwSXenz3C5pN8X8iaBAZIuS+vukrRmuqmkHbgmjQjX7Pk3aWZmleituyWrTQTZCzglIjrSM9P2iYh3JY0EriXrNAC2B7aKiOdSp7ksInaUNBiYIemuiHius8Ii4nJJewC3RsQNktrKbHomcG9E/FTS58hGl/n6j4yIEyT9N3BIRPxa0tcLn6O4MSeUmJnVT291bj1JBBkEXChpNNlE6c1z6x7PdV77AtukERNk89lGSnoDmJ6WrQ+sLmlcen9MRCyo8DPsARwMEBF3SHo9t+65iJibXs8iSyrplBNKzMzqp+6dWw0SQb4FvAhsS3Ya9d0y+wk4OSLuLNHG6FTLBKAtIiZV/gkqUpxU4lOQZmYN1BvX3HqaCDIUeCEiVgLHkGU1lnIn8BVJgwAkbS5p7e4WXcIMsmtzSNoXWK+Cfd4EhtSwBjMzq0BvdG53AANTIsjZVJ8IcjEwXtI8YBTlR3mXA4uA2enW/F9Q25HpD4F9U9uHAX8m67w6MwW4tKsbSrbeeGjNijQzMyeUVCzdpLIiIt5PuZGXpKkDPeaEEjOz6nWWUNIfsyW762+B/07z8P4CnFCrhhc8v4y2U2+rVXMlLXF2pZn1I/2+c5N0O3BU8YTytO4w4EfAn9OE8u16uz4zM6tev+/cImL/4mXKnjIqViWlPFxJW5IGRsT7NS7RzMyq1K+Ck5s5KcXMzGqnv43cmiYpxQklZmb10986t4YlpQAf6tycUGJmVj/9pnNrkqQUMzPrBf3pmlurJKWYmVkX+s3IjSwp5aSUlPIU3UtKuVHSl1JbnSWltJElpQh4GRhXZlsgSyjp8Dw0M7OacUJJE3BCiZlZ9cbaiCMAAAiiSURBVJxQ0uRKJZQ4UcTMrPv60zW3D0i6XdKwOrQ7WNI9KSj5cEnfq/UxzMysa/1y5NZZKkm6YaSsLlJItkvtF54f9xbwrz0s18zMqtTynZukW8jmtK0BnB8RkyUtIZuAvQ7Z3Y2PATsA+0s6AvgisBL4bUScmqYNzCVLLLlW0tPAGcDqwKvA0UAAvwaGS5oLPAOsmV4vjIije+kjm5n1ey3fuVFFKomk/YCDgJ3TlIH1c9utXrhwKWk9YJeICElfBv4lIv45vT4lIj6ftnur3GNxnFBiZlY//aFzqyaVZCxwZUQsB4iI13LbTc293gSYKmkE2ejtQ+kjlXBCiZlZ/bT0DSVFqSTbAnOoLpWk3HY/By6MiK2BfyrRppmZNVBLd25Un0pyN3BsCkmm6LRkcbvPp9fjO2nvr4WkEjMz6z2tflqyqlSSiLgjBSN3SPoLcDtQ6nb+ScD1kl4H7gU+UabJycB8SbM7u6HECSVmZrXlhJIm4IQSM7PqOaGkyZVKKKmWE03MzFZpmmtuacJzqeX3SyrZM/fweCelEOTOthknaYvc+x9JGlvrWszMrLZaYuTWRWpISRFxaQWbjQNuBRalfX7QjfLMzKyXNWTkJukWSbMkLUyTmQvLz03LpkvKz2w+JuU1PiFpp7TtJEm/kjQD+JWk4ZJulDQz/ewuaTVJS/I5kpKekbRR2v+UtOyEtM+81MZaknYDDgTOScfeTNKUwhO2Je0taY6kBZKukDQ4LV8i6YeSZqd1o+r/jZqZWV6jTkseFxE7kEVgTZS0AbA20BERWwIPAGfmtl8rJX18Fbgit3wLYGxEHAmcD5wbETsChwCXp5zI3wAHA0jamWzS9otF9dwUETumuXCLgeMj4n+BacB3ImJ0RDxb2FjSGsAU4PA0120g8JVce69ExPbAJcAppb4ASSdK6pDUsWL5soq+NDMzq0yjOreJkuaR3ZpfSA1ZyaoUkF+T5TgWXAsQEQ8C6+ZGYtMi4p30eixwYcpynJa2Wye1eXja5gg+nDRSsJWkhyQtIMuJ3LKL+j8FPBcRT6f3VwGfzq2/Kf2eRfbg0o+IiMkR0R4R7QPWGtrF4czMrBq9fs2tKDVkeQolLpXwEWVe59/nU0NWI8t7fLfoeI8An0ynOccBZ5U41hRgXETMkzQBGFPJZ+nEe+n3ClrkuqaZWV/SiJFbudSQ1YBD0+ujgIdz+xwOIGkPYFlElDqPdxdwcuFNmoxNZBP5bgb+E1gcEa+W2HcI8EJKE8lPtn4zrSv2FNAm6ZPp/TFkp1LNzKwJNGJUUS415G1gJ0lnAC+x6lQiwLuS5gCDgOPKtDsRuEjSfLLP9SBwUlo3FZgJTCiz7/fJHnvzcvpd6NCuAy6TNJFVHS8R8a6kY8lSSgamtiu5+7IkJ5SYmdWWE0qagBNKzMyq11lCSdNM4jYzM6sVd25mZtZy3LmZmVnLcedmZmYtx52bmZm1HHduZmbWcty5mZlZy3HnZmZmLceTuJuApDfJ0lr6kg2BVxpdRJVcc+/oizVD36y7v9f88YgYXmqFQ32bw1PlZtk3K0kdrrn+XHPv6Yt1u+byfFrSzMxajjs3MzNrOe7cmsPkRhfQDa65d7jm3tMX63bNZfiGEjMzazkeuZmZWctx52ZmZi3HnVuDSfqcpKck/Z+kUxtdTymSrpD0kqQncsvWl3S3pGfS7/UaWWMxSZtKuk/SIkkLJX0jLW/auiWtIelxSfNSzT9Myz8h6bH0NzJV0uqNrrWYpAGS5ki6Nb1v6polLZG0QNJcSR1pWdP+bQBIGibpBklPSlosaddmrlnSp9L3W/h5Q9I3e6tmd24NJGkAcBGwH7AFcKSkLRpbVUlTgM8VLTsVmB4RI4Hp6X0zeR/454jYAtgF+Fr6bpu57veAz0bEtsBo4HOSdgH+DTg3Ij4JvA4c38Aay/kGsDj3vi/UvFdEjM7NuWrmvw2A84E7ImIUsC3Z9920NUfEU+n7HQ3sACwHbqa3ao4I/zToB9gVuDP3/jTgtEbXVabWNuCJ3PungBHp9QiyiegNr7OT+n8D7NNX6gbWAmYDO5OlOQws9TfTDD/AJukfqc8CtwLqAzUvATYsWta0fxvAUOA50k2AfaHmojr3BWb0Zs0euTXWxsAfcu//mJb1BRtFxAvp9Z+BjRpZTGcktQHbAY/R5HWn03tzgZeAu4FngaUR8X7apBn/Rs4D/gVYmd5vQPPXHMBdkmZJOjEta+a/jU8ALwNXptO/l0tam+auOe8I4Nr0uldqdudmPRbZ/4I15ZwSSesANwLfjIg38uuase6IWBHZaZxNgJ2AUQ0uqVOSPg+8FBGzGl1LlfaIiO3JLgl8TdKn8yub8G9jILA9cElEbAe8TdHpvCasGYB0vfVA4PridfWs2Z1bYz0PbJp7v0la1he8KGkEQPr9UoPr+QhJg8g6tmsi4qa0uOnrBoiIpcB9ZKf0hkkq5MA229/I7sCBkpYA15Gdmjyf5q6ZiHg+/X6J7DrQTjT338YfgT9GxGPp/Q1knV0z11ywHzA7Il5M73ulZndujTUTGJnuLFudbOg+rcE1VWoaMD69Hk92TatpSBLwS2BxRPxnblXT1i1puKRh6fWaZNcIF5N1coemzZqq5og4LSI2iYg2sr/feyPiaJq4ZklrSxpSeE12PegJmvhvIyL+DPxB0qfSor2BRTRxzTlHsuqUJPRWzY2+0Njff4D9gafJrq2c3uh6ytR4LfAC8Fey/4M8nuy6ynTgGeAeYP1G11lU8x5kpzvmA3PTz/7NXDewDTAn1fwE8IO0/O+Ax4H/Izu1M7jRtZapfwxwa7PXnGqbl34WFv67a+a/jVTfaKAj/X3cAqzXB2peG3gVGJpb1is1O37LzMxajk9LmplZy3HnZmZmLcedm5mZtRx3bmZm1nLcuZmZWctx52ZmZi3HnZuZmbWc/w+sIMyr5WHgWQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================\n",
            "TRAIN size: 4381\n",
            "DEV size: 597\n",
            "TEST size: 893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SNIPS"
      ],
      "metadata": {
        "id": "QQ6Hq4EC98VG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_data_distr(SNIPS_train_raw, SNIPS_dev_raw, SNIPS_test_raw, SNIPS_y_train, SNIPS_y_dev, SNIPS_y_test)"
      ],
      "metadata": {
        "id": "l3bVUmSO9p24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 900
        },
        "outputId": "d11b8b27-625e-43e2-b212-e7e3f744b7f1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Intent labels:  7\n",
            "Train:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dev:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================\n",
            "TRAIN size: 11644\n",
            "DEV size: 1440\n",
            "TEST size: 700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Slot labels distribution"
      ],
      "metadata": {
        "id": "TDkHr0NTA3Yy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ATIS"
      ],
      "metadata": {
        "id": "FxTHGzL5BBr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#slot distribution\n",
        "train_slots = []\n",
        "for sample in ATIS_train_raw:\n",
        "  train_slots.extend(sample['slots'].split())\n",
        "\n",
        "dev_slots = []\n",
        "for sample in ATIS_dev_raw:\n",
        "  dev_slots.extend(sample['slots'].split())\n",
        "\n",
        "test_slots = []\n",
        "for sample in ATIS_test_raw:\n",
        "  test_slots.extend(sample['slots'].split())\n",
        "\n",
        "print(\"Number of slot labels: \", len(Counter(train_slots + dev_slots + test_slots)))\n",
        "\n",
        "ordered_train_slots = dict(sorted(Counter(train_slots).items(), key=lambda item: item[1], reverse=True)[:10])\n",
        "ordered_dev_slots = dict(sorted(Counter(dev_slots).items(), key=lambda item: item[1], reverse=True)[:10])\n",
        "ordered_test_slots = dict(sorted(Counter(test_slots).items(), key=lambda item: item[1], reverse=True)[:10])\n",
        "\n",
        "print('Train:')\n",
        "odict = {k:round(v/len(train_slots),3)*100 for k, v in ordered_train_slots.items()}\n",
        "odict.pop(\"O\")\n",
        "plt.barh(list(odict.keys())[:10], list(odict.values())[:10], align = 'center')\n",
        "plt.show()\n",
        "\n",
        "print('Dev:')\n",
        "odict = {k:round(v/len(dev_slots),3)*100 for k, v in ordered_dev_slots.items()}\n",
        "odict.pop(\"O\")\n",
        "plt.barh(list(odict.keys())[:10], list(odict.values())[:10], align = 'center')\n",
        "plt.show()\n",
        "\n",
        "print('Test:') \n",
        "odict = {k:round(v/len(test_slots),3)*100 for k, v in ordered_test_slots.items()}\n",
        "odict.pop(\"O\")\n",
        "plt.barh(list(odict.keys())[:10], list(odict.values())[:10], align = 'center')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "djJ23x-tMsm4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830
        },
        "outputId": "3fcf788b-dce5-4a62-b5b2-37c403e79404"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of slot labels:  129\n",
            "Train:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dev:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SNIPS"
      ],
      "metadata": {
        "id": "idCMmuFpA8Gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Number of slot labels: \n",
        "#slot distribution\n",
        "train_slots = []\n",
        "for sample in SNIPS_train_raw:\n",
        "  train_slots.extend(sample['slots'].split())\n",
        "\n",
        "dev_slots = []\n",
        "for sample in SNIPS_dev_raw:\n",
        "  dev_slots.extend(sample['slots'].split())\n",
        "\n",
        "test_slots = []\n",
        "for sample in SNIPS_test_raw:\n",
        "  test_slots.extend(sample['slots'].split())\n",
        "\n",
        "print(\"Number of slot labels: \", len(Counter(train_slots + dev_slots + test_slots)))\n",
        "\n",
        "ordered_train_slots = dict(sorted(Counter(train_slots).items(), key=lambda item: item[1], reverse=True)[:10])\n",
        "ordered_dev_slots = dict(sorted(Counter(dev_slots).items(), key=lambda item: item[1], reverse=True)[:10])\n",
        "ordered_test_slots = dict(sorted(Counter(test_slots).items(), key=lambda item: item[1], reverse=True)[:10])\n",
        "\n",
        "print('Train:')\n",
        "odict = {k:round(v/len(train_slots),3)*100 for k, v in ordered_train_slots.items()}\n",
        "odict.pop(\"O\")\n",
        "plt.barh(list(odict.keys())[:10], list(odict.values())[:10], align = 'center')\n",
        "plt.show()\n",
        "\n",
        "print('Dev:')\n",
        "odict = {k:round(v/len(dev_slots),3)*100 for k, v in ordered_dev_slots.items()}\n",
        "odict.pop(\"O\")\n",
        "plt.barh(list(odict.keys())[:10], list(odict.values())[:10], align = 'center')\n",
        "plt.show()\n",
        "\n",
        "print('Test:') \n",
        "odict = {k:round(v/len(test_slots),3)*100 for k, v in ordered_test_slots.items()}\n",
        "odict.pop(\"O\")\n",
        "plt.barh(list(odict.keys())[:10], list(odict.values())[:10], align = 'center')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a-rS7ZKnMiHQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830
        },
        "outputId": "117514c7-dcf5-4775-e654-6b35b83b58ec"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of slot labels:  72\n",
            "Train:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dev:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Lang class"
      ],
      "metadata": {
        "id": "AQ6bS79Z6-fk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use it to convert word,intent and slot to id and vice versa"
      ],
      "metadata": {
        "id": "Sr8prT1_7Alj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "4c04f608"
      },
      "outputs": [],
      "source": [
        "class Lang():\n",
        "    def __init__(self, words, intents, slots, cutoff=0):\n",
        "        self.word2id = self.w2id(words, cutoff=cutoff, unk=True)\n",
        "        self.slot2id = self.lab2id(slots)\n",
        "        self.intent2id = self.lab2id(intents, pad=False)\n",
        "        self.id2word = {v:k for k, v in self.word2id.items()}\n",
        "        self.id2slot = {v:k for k, v in self.slot2id.items()}\n",
        "        self.id2intent = {v:k for k, v in self.intent2id.items()}\n",
        "\n",
        "    #method to transform words to id \n",
        "    def w2id(self, elements, cutoff=None, unk=True):\n",
        "        vocab = {'pad': PAD_TOKEN}\n",
        "        if unk:\n",
        "            vocab['unk'] = len(vocab)\n",
        "        count = Counter(elements)\n",
        "        for k, v in count.items():\n",
        "            if v > cutoff:\n",
        "                #print(\"k: \", k)\n",
        "                #print(\"v: \", v)\n",
        "                #print(\"len(vocab): \", len(vocab))\n",
        "                vocab[k] = len(vocab)\n",
        "                #print(\"vocab[k]: \", vocab[k])\n",
        "        #pprint(vocab)\n",
        "        return vocab\n",
        "    \n",
        "    def lab2id(self, elements, pad=True):\n",
        "        vocab = {}\n",
        "        if pad:\n",
        "            vocab['pad'] = PAD_TOKEN\n",
        "        for elem in elements:\n",
        "                vocab[elem] = len(vocab)\n",
        "        return vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create lang object of ATIS and SNIPS datasets"
      ],
      "metadata": {
        "id": "LdWkSxTj7NB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ATIS_words = sum([x['utterance'].split() for x in ATIS_train_raw], []) # No set() since we want to compute \n",
        "                                                            # the cutoff\n",
        "ATIS_corpus = ATIS_train_raw + ATIS_dev_raw + ATIS_test_raw # We do not want unk labels, \n",
        "                                        # however this depends on the research purpose\n",
        "ATIS_slots = set(sum([line['slots'].split() for line in ATIS_corpus],[])) # the type of slots\n",
        "ATIS_intents = set([line['intent'] for line in ATIS_corpus]) #all the intent types\n",
        "\n",
        "ATIS_lang = Lang(ATIS_words, ATIS_intents, ATIS_slots, cutoff=0)"
      ],
      "metadata": {
        "id": "FTEVjlsp7cqW"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "d77bc3bc"
      },
      "outputs": [],
      "source": [
        "SNIPS_words = sum([x['utterance'].split() for x in SNIPS_train_raw], []) # No set() since we want to compute \n",
        "                                                            # the cutoff\n",
        "SNIPS_corpus = SNIPS_train_raw + SNIPS_dev_raw + SNIPS_test_raw # We do not want unk labels, \n",
        "                                        # however this depends on the research purpose\n",
        "SNIPS_slots = set(sum([line['slots'].split() for line in SNIPS_corpus],[])) # the type of slots\n",
        "SNIPS_intents = set([line['intent'] for line in SNIPS_corpus]) #all the intent types\n",
        "\n",
        "SNIPS_lang = Lang(SNIPS_words, SNIPS_intents, SNIPS_slots, cutoff=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can see how words, intent and slots are mapped into ids"
      ],
      "metadata": {
        "id": "q5Pef4b4-cZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(ATIS_lang.word2id)\n",
        "print(ATIS_lang.intent2id)\n",
        "print(ATIS_lang.slot2id)"
      ],
      "metadata": {
        "id": "vckmCutL8Eqx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cc8c0a4-08cf-40c9-917f-71d49b3554b8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'pad': 0, 'unk': 1, 'what': 2, 'type': 3, 'of': 4, 'aircraft': 5, 'does': 6, 'eastern': 7, 'fly': 8, 'from': 9, 'atlanta': 10, 'to': 11, 'denver': 12, 'before': 13, '6': 14, 'pm': 15, 'show': 16, 'me': 17, 'the': 18, 'fares': 19, 'dallas': 20, 'san': 21, 'francisco': 22, 'and': 23, 'flights': 24, 'pittsburgh': 25, 'philadelphia': 26, 'flight': 27, 'will': 28, 'originate': 29, 'boston': 30, 'are': 31, 'available': 32, 'on': 33, 'monday': 34, 'is': 35, 'first': 36, 'after': 37, '8': 38, 'am': 39, 'that': 40, 'arrive': 41, 'in': 42, 'afternoon': 43, 'give': 44, 'a': 45, 'list': 46, 'between': 47, 'oakland': 48, 'i': 49, 'need': 50, 'leaves': 51, 'late': 52, 'wednesday': 53, 'salt': 54, 'lake': 55, 'city': 56, 'there': 57, 'newark': 58, 'seattle': 59, 'saturday': 60, \"'d\": 61, 'like': 62, 'see': 63, 'all': 64, 'economy': 65, 'baltimore': 66, 'times': 67, 'for': 68, 'phoenix': 69, 'sfo': 70, 'let': 71, \"'s\": 72, 'how': 73, 'much': 74, 'would': 75, 'direct': 76, 'be': 77, 'may': 78, 'seventh': 79, 'do': 80, 'you': 81, 'have': 82, 'leaving': 83, 'arriving': 84, 'night': 85, 'my': 86, 'destination': 87, 'live': 88, 'august': 89, 'thirtieth': 90, 'morning': 91, 'any': 92, 'airline': 93, 'get': 94, 'overnight': 95, 'washington': 96, 'dc': 97, 'their': 98, 'schedule': 99, 'airlines': 100, 'going': 101, 'next': 102, 'cheapest': 103, 'one': 104, 'way': 105, '4': 106, 'houston': 107, 'los': 108, 'angeles': 109, 'departing': 110, '1026': 111, 'toronto': 112, 'besides': 113, 'continental': 114, 'flies': 115, 'can': 116, 'via': 117, 'at': 118, 'level': 119, 'find': 120, 'travel': 121, 'arrangements': 122, 'round': 123, 'trip': 124, '10': 125, 'leave': 126, 'nashville': 127, 'us': 128, 'air': 129, 'ground': 130, 'transportation': 131, 'look': 132, 'prices': 133, 'class': 134, 'okay': 135, 'tell': 136, 'earliest': 137, 'want': 138, 'milwaukee': 139, 'orlando': 140, 'either': 141, 'evening': 142, 'or': 143, 'thursday': 144, 'st.': 145, 'petersburg': 146, 'charlotte': 147, 'chicago': 148, 'also': 149, 'miami': 150, 'types': 151, 'airport': 152, 'please': 153, 'new': 154, 'york': 155, 'information': 156, 'only': 157, 'local': 158, 'time': 159, 'twenty': 160, 'fare': 161, 'least': 162, 'expensive': 163, '630': 164, 'your': 165, 'last': 166, 'tomorrow': 167, 'abbreviations': 168, 'go': 169, '5': 170, 'price': 171, 'limousine': 172, 'service': 173, 'kind': 174, 'used': 175, 'american': 176, 'with': 177, 'stopover': 178, 'day': 179, 'las': 180, 'vegas': 181, 'memphis': 182, 'sunday': 183, 'right': 184, 'indianapolis': 185, 'fort': 186, 'worth': 187, 'july': 188, 'third': 189, 'which': 190, \"o'clock\": 191, 'thirty': 192, 'nonstop': 193, 'far': 194, '838': 195, '1110': 196, 'bwi': 197, 'serves': 198, 'dinner': 199, '1024': 200, 'downtown': 201, 'stop': 202, 'noon': 203, 'flying': 204, 'fifth': 205, 'know': 206, 'about': 207, 'car': 208, 'rental': 209, 'thrift': 210, 'takeoff': 211, 'general': 212, 'mitchell': 213, 'international': 214, 'display': 215, 'codes': 216, 'long': 217, 'beach': 218, 'tampa': 219, 'diego': 220, 'northwest': 221, 'united': 222, 'stopovers': 223, 'lowest': 224, 'code': 225, 'qw': 226, 'latest': 227, 'cleveland': 228, 'transport': 229, 'ontario': 230, 'texas': 231, 'now': 232, 'tuesday': 233, 'no': 234, 'into': 235, '12': 236, '3': 237, '1991': 238, 'florida': 239, 'requesting': 240, 'mco': 241, 'f': 242, 'returning': 243, 'make': 244, 'starting': 245, 'back': 246, 'love': 247, 'field': 248, 'other': 249, 'airports': 250, 'train': 251, 'california': 252, 'depart': 253, 'burbank': 254, 'by': 255, 'delta': 256, 'kansas': 257, '845': 258, '2153': 259, 'plane': 260, 'jose': 261, '7': 262, 'tacoma': 263, 'symbols': 264, 'stand': 265, 'daily': 266, 'using': 267, 'could': 268, 'listings': 269, 'montreal': 270, 'canada': 271, 'trips': 272, 'ff': 273, 'twa': 274, 'paul': 275, '530': 276, 'around': 277, 'minneapolis': 278, 'y': 279, 'mean': 280, 'many': 281, 'december': 282, 'airfare': 283, 'louis': 284, 'arrives': 285, 'along': 286, 'less': 287, 'than': 288, '466': 289, 'dollars': 290, 'business': 291, 'cost': 292, 'detroit': 293, 'month': 294, 'h': 295, 'pennsylvania': 296, 'possible': 297, 'classes': 298, 'weekday': 299, '1115': 300, '1245': 301, 'friday': 302, 'saturdays': 303, 'number': 304, 'people': 305, 'carried': 306, 'each': 307, 'june': 308, 'eleventh': 309, 'sa': 310, 'ticket': 311, 'dl': 312, '296': 313, 'm': 314, 'columbus': 315, 'second': 316, 'take': 317, 'ten': 318, '11': 319, 'great': 320, 'too': 321, 'we': 322, \"'re\": 323, 'april': 324, 'nighttime': 325, 'departure': 326, 'it': 327, 'rent': 328, 'serve': 329, 'planes': 330, \"'m\": 331, 'interested': 332, 'early': 333, 'hello': 334, 'plan': 335, 'coach': 336, 'approximately': 337, '1': 338, 'layover': 339, 'eighteenth': 340, 'cincinnati': 341, 'should': 342, 'october': 343, 'fn': 344, 'explain': 345, 'restriction': 346, 'ap': 347, '1020': 348, 'carries': 349, 'smallest': 350, 'passengers': 351, 'november': 352, 'through': 353, '934': 354, 'september': 355, 'this': 356, 'prefer': 357, 'fourth': 358, 'equal': 359, 'goes': 360, 'difference': 361, 'q': 362, 'cities': 363, 'served': 364, 'canadian': 365, 'yes': 366, 'breakfast': 367, 'today': 368, 'town': 369, 'schedules': 370, 'an': 371, 'fifteenth': 372, '747': 373, '1222': 374, 'later': 375, '2': 376, 'use': 377, 'meal': 378, 's': 379, 'march': 380, 'meaning': 381, 'ap80': 382, 'serving': 383, '2134': 384, 'hp': 385, '80': 386, 'la': 387, 'as': 388, 'connecting': 389, 'stopping': 390, 'oh': 391, 'during': 392, 'week': 393, 'days': 394, 'offer': 395, 'dc10': 396, 'midwest': 397, 'express': 398, 'sixteenth': 399, 'jfk': 400, 'guardia': 401, 'arrange': 402, 'two': 403, 'friends': 404, 'coming': 405, 'eighth': 406, '1000': 407, '1145': 408, '430': 409, 'ninth': 410, 'another': 411, 'out': 412, 'soon': 413, 'thereafter': 414, 'where': 415, 'ea': 416, 'book': 417, 'reaches': 418, 'colorado': 419, '210': 420, 'options': 421, 'noontime': 422, 'originating': 423, 'order': 424, 'twelfth': 425, 'names': 426, 'itinerary': 427, 'departs': 428, 'sixth': 429, '1765': 430, 'anything': 431, 'non': 432, 'meals': 433, 'eight': 434, 'sixteen': 435, 'qx': 436, 'listing': 437, 'lunch': 438, 'nineteenth': 439, 'seating': 440, 'capacity': 441, 'various': 442, 'airplanes': 443, 'uses': 444, 'nw': 445, '1220': 446, 'return': 447, 'jersey': 448, 'ohio': 449, 'weekdays': 450, 'wednesdays': 451, '4400': 452, '1083': 453, 'fridays': 454, '9': 455, 'eleven': 456, 'quebec': 457, 'philly': 458, 'say': 459, 'mealtime': 460, 'then': 461, 'thank': 462, 'has': 463, '852': 464, 'when': 465, 'under': 466, 'following': 467, 'westchester': 468, 'county': 469, 'ewr': 470, 'north': 471, 'carolina': 472, '415': 473, 'again': 474, 'reverse': 475, 'dfw': 476, '1133': 477, '43': 478, 'tenth': 479, 'most': 480, 'anywhere': 481, 'stops': 482, 'twentieth': 483, 'doesn': 484, \"'t\": 485, 'provided': 486, '445': 487, '515': 488, 'same': 489, 'trying': 490, '650': 491, 'cheap': 492, 'southwest': 493, 'tuesdays': 494, 'provide': 495, '269': 496, '428': 497, 'arrival': 498, 'looking': 499, 'choices': 500, 'if': 501, '813': 502, 'enroute': 503, 'connect': 504, 'mia': 505, 'takes': 506, 'amount': 507, 'january': 508, 'dinnertime': 509, 'oak': 510, 'atl': 511, 'makes': 512, 'sd': 513, 'd': 514, 'stapleton': 515, 'define': 516, 'ua': 517, 'some': 518, 'making': 519, 'reservation': 520, 'seats': 521, '100': 522, 'includes': 523, 'hi': 524, 'sometime': 525, '201': 526, 'help': 527, 'repeat': 528, 'departures': 529, 'rates': 530, 'limo': 531, 'distance': 532, 'fourteenth': 533, 'total': 534, '270': 535, 'sounds': 536, 'sorry': 537, 'wanted': 538, 'ap57': 539, 'seventeenth': 540, 'route': 541, '1992': 542, 'landings': 543, 'tickets': 544, 'arrivals': 545, 'logan': 546, '106': 547, 'boeing': 548, '737': 549, 'shortest': 550, 'numbers': 551, 'minnesota': 552, 'fit': 553, '72s': 554, 'airplane': 555, 'qo': 556, 'capacities': 557, 'turboprop': 558, 'takeoffs': 559, '402': 560, 'tennessee': 561, 'inform': 562, 'cars': 563, '825': 564, '555': 565, '300': 566, 'wish': 567, 'discount': 568, '323': 569, '229': 570, 'dulles': 571, 'arizona': 572, 'within': 573, 'final': 574, 'yn': 575, 'sundays': 576, 'cp': 577, 'traveling': 578, 'they': 579, 'these': 580, '230': 581, 'more': 582, 'advertises': 583, 'having': 584, 'fine': 585, '55': 586, 'very': 587, '57': 588, 'both': 589, 'ac': 590, 'trans': 591, 'world': 592, '1030': 593, '1130': 594, 'georgia': 595, 'four': 596, '257': 597, '500': 598, 'airfares': 599, 'run': 600, '212': 601, 'everywhere': 602, 'connection': 603, 'those': 604, 'ls': 605, 'buy': 606, 'including': 607, 'connections': 608, '767': 609, 'gets': 610, 'nationair': 611, 'mornings': 612, '1100': 613, 'stands': 614, 'lufthansa': 615, 'listed': 616, '1055': 617, '405': 618, 'greatest': 619, 'maximum': 620, 'well': 621, \"'ll\": 622, 'try': 623, 'michigan': 624, 'different': 625, '400': 626, '539': 627, 'still': 628, 'being': 629, 'serviced': 630, 'rentals': 631, '345': 632, '720': 633, 'f28': 634, 'name': 635, '1600': 636, 'hours': 637, 'come': 638, 'located': 639, 'date': 640, 'start': 641, '645': 642, 'abbreviation': 643, '2100': 644, 'iah': 645, 'preferably': 646, 'february': 647, 'area': 648, 'but': 649, 'taxi': 650, 'reservations': 651, 'over': 652, '1993': 653, 'kinds': 654, 'midway': 655, 'indiana': 656, 'three': 657, 'j31': 658, 'midnight': 659, '21': 660, '757': 661, 'co': 662, '281': 663, 'spend': 664, 'lastest': 665, 'land': 666, '217': 667, '815': 668, 'currently': 669, 'sort': 670, 'so': 671, 'priced': 672, '718': 673, '1300': 674, '1700': 675, 'proper': 676, 'tower': 677, 'b': 678, 'economic': 679, 'longest': 680, 'offers': 681, 'd10': 682, 'describe': 683, 'seven': 684, '271': 685, 'america': 686, 'west': 687, 'charges': 688, 'bay': 689, '98': 690, '1940': 691, '723': 692, 'o': 693, \"'hare\": 694, 'zone': 695, '82': 696, '139': 697, 'thanks': 698, 'd9s': 699, 'bound': 700, 'costs': 701, 'limousines': 702, 'services': 703, 'bur': 704, 'include': 705, '1205': 706, 'hold': 707, '3357': 708, 'runs': 709, '329': 710, 'ord': 711, 'regarding': 712, 'booking': 713, '343': 714, 'm80': 715, 'repeating': 716, 'closest': 717, 'companies': 718, '71': 719, 'visit': 720, 'here': 721, 'them': 722, 'lives': 723, 'continuing': 724, 'near': 725, '324': 726, 'just': 727, 'highest': 728, 'six': 729, '1039': 730, 'nonstops': 731, 'hou': 732, 'close': 733, 'travels': 734, '746': 735, 'afternoons': 736, 'laying': 737, '1291': 738, 'lester': 739, 'pearson': 740, '1500': 741, '1059': 742, '3724': 743, 'aa': 744, '459': 745, '819': 746, 'represented': 747, 'database': 748, '150': 749, 'afterwards': 750, 'while': 751, '73s': 752, 'sure': 753, 'planning': 754, '305': 755, 'designate': 756, 'jet': 757, 'heading': 758, 'restrictions': 759, '416': 760, 'actually': 761, 'once': 762, 'snack': 763, 'seat': 764, 'question': 765, '1045': 766, 'bring': 767, 'up': 768, 'tonight': 769, 'twelve': 770, 'belong': 771, 'seventeen': 772, 'working': 773, 'scenario': 774, '727': 775, '297': 776, 'rate': 777, 'thursdays': 778, 'c': 779, 'hopefully': 780, 'thirteenth': 781, 'grounds': 782, 'such': 783, 'connects': 784, '352': 785, '124': 786, '730': 787, '19': 788, 'thing': 789, '110': 790, '315': 791, 'alaska': 792, 'staying': 793, 'straight': 794, 'without': 795, '615': 796, 'operation': 797, 'provides': 798, 'usa': 799, 'year': 800, 'lax': 801, 'begins': 802, 'lands': 803, '225': 804, '1158': 805, 'equipment': 806, 'minimum': 807, 'intercontinental': 808, 'transcontinental': 809, \"'ve\": 810, 'got': 811, 'somebody': 812, 'else': 813, 'who': 814, 'wants': 815, '505': 816, '163': 817, 'cover': 818, 'kindly': 819, 'missouri': 820, 'utah': 821, 'taking': 822, '311': 823, 'must': 824, '932': 825, '1505': 826, 'home': 827, 'directly': 828, '130': 829, 'nights': 830, '771': 831, '420': 832, 'qualify': 833, '823': 834, 'reaching': 835, 'landing': 836, 'able': 837, 'put': 838, '755': 839, '0900': 840, 'earlier': 841, '1209': 842, 'red': 843, 'eye': 844, 'calling': 845, '734': 846, 'supper': 847, '1850': 848, 'toward': 849, 'single': 850, 'vicinity': 851, '497766': 852, 'nevada': 853, 'off': 854, '733': 855, 'largest': 856, 'beginning': 857, 'across': 858, 'continent': 859, 'concerning': 860, 'scheduled': 861, 'summer': 862}\n",
            "{'flight_time': 0, 'day_name': 1, 'restriction': 2, 'flight+airfare': 3, 'cheapest': 4, 'ground_fare': 5, 'airfare': 6, 'airfare+flight_time': 7, 'capacity': 8, 'airline+flight_no': 9, 'flight_no+airline': 10, 'flight_no': 11, 'airport': 12, 'aircraft': 13, 'flight+airline': 14, 'abbreviation': 15, 'distance': 16, 'flight': 17, 'quantity': 18, 'aircraft+flight+flight_no': 19, 'ground_service+ground_fare': 20, 'ground_service': 21, 'airline': 22, 'city': 23, 'airfare+flight': 24, 'meal': 25}\n",
            "{'pad': 0, 'B-round_trip': 1, 'I-depart_time.time': 2, 'B-depart_date.date_relative': 3, 'B-fromloc.airport_code': 4, 'I-arrive_time.start_time': 5, 'B-city_name': 6, 'B-return_date.day_name': 7, 'B-flight_days': 8, 'I-depart_time.time_relative': 9, 'B-return_date.day_number': 10, 'B-arrive_time.start_time': 11, 'I-airport_name': 12, 'I-time': 13, 'B-fromloc.airport_name': 14, 'B-stoploc.state_code': 15, 'I-depart_date.day_number': 16, 'I-city_name': 17, 'B-arrive_time.time_relative': 18, 'B-economy': 19, 'I-arrive_time.time': 20, 'I-arrive_time.period_of_day': 21, 'I-flight_number': 22, 'B-restriction_code': 23, 'B-toloc.city_name': 24, 'I-fare_amount': 25, 'B-depart_time.period_mod': 26, 'B-depart_time.end_time': 27, 'B-depart_date.year': 28, 'I-return_date.date_relative': 29, 'B-arrive_time.time': 30, 'I-depart_time.start_time': 31, 'I-round_trip': 32, 'B-flight': 33, 'B-stoploc.airport_code': 34, 'I-cost_relative': 35, 'B-month_name': 36, 'B-depart_time.time': 37, 'I-toloc.airport_name': 38, 'I-depart_date.today_relative': 39, 'B-period_of_day': 40, 'B-day_name': 41, 'B-toloc.state_name': 42, 'B-depart_date.today_relative': 43, 'B-airline_name': 44, 'B-depart_date.day_number': 45, 'I-restriction_code': 46, 'B-arrive_time.period_mod': 47, 'B-state_name': 48, 'B-depart_date.month_name': 49, 'I-flight_time': 50, 'B-aircraft_code': 51, 'I-flight_mod': 52, 'I-arrive_time.time_relative': 53, 'I-depart_time.end_time': 54, 'B-toloc.country_name': 55, 'I-meal_description': 56, 'I-class_type': 57, 'B-stoploc.airport_name': 58, 'I-today_relative': 59, 'B-arrive_date.day_number': 60, 'B-depart_time.period_of_day': 61, 'I-flight_stop': 62, 'I-state_name': 63, 'B-fromloc.state_name': 64, 'B-flight_stop': 65, 'B-arrive_time.end_time': 66, 'B-fare_basis_code': 67, 'B-today_relative': 68, 'B-meal_code': 69, 'B-return_date.month_name': 70, 'B-fromloc.city_name': 71, 'B-arrive_date.month_name': 72, 'B-booking_class': 73, 'B-fromloc.state_code': 74, 'I-mod': 75, 'B-flight_time': 76, 'I-toloc.city_name': 77, 'B-days_code': 78, 'B-state_code': 79, 'I-depart_date.day_name': 80, 'B-arrive_date.date_relative': 81, 'I-arrive_time.end_time': 82, 'I-stoploc.city_name': 83, 'B-depart_date.day_name': 84, 'B-return_date.date_relative': 85, 'B-transport_type': 86, 'B-mod': 87, 'I-airline_name': 88, 'I-fromloc.airport_name': 89, 'B-return_date.today_relative': 90, 'I-return_date.today_relative': 91, 'I-arrive_date.day_number': 92, 'B-depart_time.time_relative': 93, 'B-meal_description': 94, 'B-depart_time.start_time': 95, 'B-toloc.state_code': 96, 'B-flight_mod': 97, 'B-arrive_date.day_name': 98, 'B-return_time.period_of_day': 99, 'B-day_number': 100, 'B-meal': 101, 'B-toloc.airport_code': 102, 'B-time_relative': 103, 'B-fare_amount': 104, 'I-meal_code': 105, 'I-toloc.state_name': 106, 'O': 107, 'I-depart_time.period_of_day': 108, 'I-fromloc.state_name': 109, 'B-arrive_date.today_relative': 110, 'B-time': 111, 'B-stoploc.city_name': 112, 'B-toloc.airport_name': 113, 'I-return_date.day_number': 114, 'B-airline_code': 115, 'I-fare_basis_code': 116, 'B-class_type': 117, 'B-connect': 118, 'B-flight_number': 119, 'I-economy': 120, 'I-transport_type': 121, 'B-arrive_time.period_of_day': 122, 'B-cost_relative': 123, 'B-airport_name': 124, 'B-compartment': 125, 'B-airport_code': 126, 'I-fromloc.city_name': 127, 'B-return_time.period_mod': 128, 'B-or': 129}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(SNIPS_lang.word2id)\n",
        "print(SNIPS_lang.intent2id)\n",
        "print(SNIPS_lang.slot2id)"
      ],
      "metadata": {
        "id": "MjrZ9egLKjTA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f454e05-f567-44d7-f93c-3290dfe3fd7c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'pad': 10605, 'unk': 1, 'can': 2, 'i': 3, 'get': 4, 'the': 5, 'showtimes': 6, 'for': 7, 'films': 8, 'at': 9, 'closest': 10, 'movie': 11, 'house': 12, 'book': 13, 'a': 14, 'restaurant': 15, 'in': 16, 'michigan': 17, '4': 18, 'people': 19, 'give': 20, '3': 21, 'out': 22, 'of': 23, '6': 24, 'to': 25, 'current': 26, 'textbook': 27, 'one': 28, 'stars': 29, 'shiva': 30, 'option': 31, 'need': 32, 'reservation': 33, 'five': 34, 'top-rated': 35, 'english': 36, 'elma': 37, 'please': 38, 'add': 39, 'track': 40, 'by': 41, 'david': 42, 'freiberg': 43, 'my': 44, 'workout': 45, 'playlist': 46, 'put': 47, 'on': 48, 'vimeo': 49, 'and': 50, 'play': 51, 'kacapi': 52, 'suling': 53, 'if': 54, 'you': 55, 'go': 56, 'table': 57, 'irma': 58, 'hotel': 59, 'mount': 60, 'repose': 61, 'which': 62, 'cinemark': 63, 'theatres': 64, 'is': 65, 'playing': 66, 'atom': 67, 'take': 68, 'me': 69, 'nine': 70, 'close': 71, 'westfield': 72, 'delaware': 73, 'when': 74, 'will': 75, 'boys': 76, 'next': 77, 'door': 78, 'be': 79, 'nearest': 80, 'more': 81, 'unbelievable': 82, 'grandes': 83, 'unplugged': 84, 'are': 85, 'neighborhood': 86, 'second': 87, 'from': 88, 'now': 89, 'where': 90, 'watch': 91, 'television': 92, 'show': 93, 'called': 94, 'fangs': 95, 'arctic': 96, 'switzerland': 97, 'pub': 98, 'serving': 99, 'gateau': 100, 'ms': 101, 'schedules': 102, 'movies': 103, 'around': 104, 'here': 105, 'today': 106, 'this': 107, 'duetos': 108, 'rating': 109, '0': 110, 'chronicle': 111, 'want': 112, 'nautch': 113, 'girls': 114, 'india': 115, 'four': 116, 'points': 117, 'find': 118, 'ten': 119, 'am': 120, 'reserve': 121, 'spot': 122, '9': 123, 'eat': 124, 'monaco': 125, 'rate': 126, 'bok': 127, 'series': 128, 'preparedness': 129, '101:': 130, 'zombie': 131, 'apocalypse': 132, 'two': 133, 'search': 134, 'title': 135, 'twilight': 136, 'saga:': 137, 'breaking': 138, 'dawn': 139, 'part': 140, '2': 141, 'rated': 142, 'better': 143, 'than': 144, 'previous': 145, 'would': 146, 'novel': 147, '5': 148, 'best': 149, 'disco': 150, 'tango': 151, 'power': 152, 'walk': 153, 'some': 154, 'salsa': 155, 'music': 156, 'it': 157, 'chillier': 158, 'saxis': 159, 'north': 160, 'dakota': 161, 'make': 162, 'son': 163, 'twenty': 164, 'three': 165, 'o': 166, 'clock': 167, 'what': 168, 's': 169, 'weather': 170, 'going': 171, 'like': 172, 'mi': 173, 'august': 174, 'twenty-eighth': 175, '2033': 176, 'painting': 177, 'live': 178, '–': 179, 'very': 180, 'concert': 181, 'forecast': 182, 'kinbrae': 183, 'with': 184, 'wifi': 185, 'france': 186, 'something': 187, 'classic': 188, 'jazz': 189, 'funk': 190, 'zvooq': 191, 'diana': 192, 'herself': 193, 'average': 194, 'gets': 195, 'how': 196, 'may': 197, 'wyoming': 198, 'work': 199, 'compiled': 200, 'fragments': 201, '1997-2003': 202, 'tell': 203, 'sam': 204, 'd': 205, 'hamilton': 206, 'noxubee': 207, 'national': 208, 'wildlife': 209, 'refuge': 210, 'point': 211, 'compendium': 212, 'analytical': 213, 'nomenclature': 214, 'nuclear': 215, 'war': 216, 'survival': 217, 'skills': 218, 'zero': 219, 'step': 220, 'grandfather': 221, 'fifty-five': 222, 'nv': 223, 'animated': 224, 'bridge': 225, 'san': 226, 'luis': 227, 'rey': 228, 'picture': 229, 'hot': 230, 'west': 231, 'union': 232, 'malaysia': 233, 'tales': 234, 'organ': 235, 'trade': 236, 'warpaint': 237, 'pre-party': 238, 'list': 239, 'glenn': 240, 'stetson': 241, 'spotify': 242, 'highly': 243, 'oyster': 244, 'bar': 245, 'ar': 246, 'month': 247, 'jeanne': 248, 'collins': 249, 'amy': 250, '11': 251, 'm': 252, 'dickinson': 253, 'ik': 254, 'tara': 255, 'laundry': 256, 'playlst': 257, 'roland': 258, 'alphonso': 259, 'tunes': 260, 'that': 261, 'most': 262, 'popular': 263, 'temperate': 264, 'farallon': 265, 'islands': 266, 'oct': 267, '10': 268, 'cuyabeno': 269, 'pilot': 270, 'mound': 271, 'palau': 272, 'feb': 273, 'twenty-fourth': 274, 'takes': 275, 'place': 276, 'your': 277, 'space': 278, 'eddie': 279, 'kendricks': 280, 'cold': 281, 'cargray': 282, 'argentina': 283, 'time': 284, 'taking': 285, 'pelham': 286, '1': 287, 'theatre': 288, 'adventures': 289, 'stationery': 290, 'saga': 291, 'good': 292, 'amber': 293, 'gristak': 294, 'lastfm': 295, 'korean': 296, 'osts': 297, 'parents': 298, 'romagna': 299, 'brasserie': 300, 'tv': 301, 'have': 302, 'nice': 303, 'day': 304, 'goshenville': 305, 'pr': 306, 'october': 307, '16': 308, '2038': 309, 'game': 310, 'special': 311, 'christmas': 312, '7': 313, 'anniston': 314, 'shahrum': 315, 'kashani': 316, 'country': 317, 'hits': 318, 'windy': 319, 'anderson': 320, 'lake': 321, 'state': 322, 'fish': 323, 'area': 324, 'soundtrack': 325, 'shoes': 326, 'september': 327, 'kb': 328, 'fourties': 329, 'chant': 330, 'last': 331, 'fm': 332, 'alamo': 333, 'drafthouse': 334, 'cinema': 335, 'carmichaels': 336, 'gambia': 337, 'there': 338, 'cloud': 339, 'year': 340, 'kewanee': 341, 'artist': 342, 'mark': 343, 'ashley': 344, 'wondering': 345, 'see': 346, 'beating': 347, 'heart': 348, 'trying': 349, 'remote': 350, 'look': 351, 'all': 352, 'broken': 353, 'up': 354, 'dancing': 355, 'video': 356, 'spring': 357, 'shore': 358, 'club': 359, 'buy': 360, 'brokeback': 361, 'mountain': 362, 'use': 363, 'deezer': 364, 'rainfall': 365, 'faraway': 366, 'uganda': 367, 'seven': 368, 'hours': 369, 'rain': 370, 'depression': 371, 'washington': 372, 'forest': 373, 'broke:': 374, 'who': 375, 'killed': 376, 'middle': 377, 'classes': 378, 'while': 379, 'gate': 380, 'open': 381, 'supposed': 382, 'hail': 383, 'rosenberg': 384, 'french': 385, 'polynesia': 386, 'november': 387, 'twelfth': 388, '2030': 389, 'party': 390, 'currituck': 391, 'chilly': 392, 'conditions': 393, 'chad': 394, '28': 395, '2034': 396, 'times': 397, 'has': 398, 'far': 399, 'tx': 400, 'southern': 401, 'rock': 402, 'include': 403, 'emily': 404, 'remler': 405, 'indie': 406, 'bluegrass': 407, 'rainy': 408, 'malta': 409, 'eight': 410, 'days': 411, 'luke': 412, 'rainbow': 413, 'eyes': 414, 'starts': 415, 'minute': 416, 'alles': 417, 'heeft': 418, 'ritme': 419, 'liu': 420, 'tianhua': 421, 'essay': 422, 'sister': 423, 'nebraska': 424, 'seconds': 425, 'schedule': 426, 'skull': 427, 'loews': 428, 'cineplex': 429, 'blizzard': 430, 'egypt': 431, 'lost': 432, 'land': 433, 'tiger': 434, 'word': 435, 'brand': 436, 'manadonese': 437, 'six': 438, '21:49': 439, 'distant': 440, 'baby': 441, 'winchell': 442, 'mississippi': 443, 'imax': 444, 'corporation': 445, 'minutes': 446, 'love': 447, '80': 448, 'rollerdisco': 449, 'song': 450, 'avispa': 451, '1965': 452, 'itunes': 453, 'songs': 454, 'gerard': 455, 'way': 456, 'punk': 457, 'essentials': 458, 'google': 459, 'album': 460, 'saint': 461, 'vincent': 462, 'grenadines': 463, 'robin': 464, 'trower': 465, 'feminist': 466, 'friday': 467, '1993': 468, 'marshall': 469, 'sixteen': 470, 'cloudy': 471, 'georgia': 472, 'ways': 473, 'escape': 474, 'fever': 475, 'belarus': 476, '1994': 477, 'sunrise': 478, 'lands': 479, 'dub': 480, 'beach': 481, 'kerasotes': 482, 'parry': 483, 'birch': 484, 'river': 485, 'mo': 486, 'boy': 487, 'meets': 488, 'paulinho': 489, 'da': 490, 'viola': 491, '1999': 492, 'puccini': 493, 'jacqueline': 494, 'wilson': 495, 'deanna': 496, 'carpenter': 497, 'uncas': 498, 'neighbourhood': 499, 'kings': 500, 'high': 501, 'frontier': 502, 'girl': 503, 'man': 504, 'hold': 505, 'blonde': 506, 'deserves': 507, 'only': 508, 'nightmare': 509, 'providence': 510, 'street': 511, 'cave': 512, 'canem': 513, 'demos': 514, 'photograph': 515, '1952': 516, 'symphony': 517, 'star': 518, 'looking': 519, 'right': 520, 'merry': 521, 'sisters': 522, 'fate': 523, 'codebreakers': 524, 'value': 525, 'selling': 526, 'price': 527, 'sims': 528, '3:': 529, 'island': 530, 'paradise': 531, 'creativity': 532, 'dead': 533, 'hour': 534, 'exira': 535, 'sd': 536, 'serves': 537, 'oysters': 538, 'rockefeller': 539, 'warmer': 540, 'same': 541, 'as': 542, 'sandy': 543, 'dave': 544, 'acoustic': 545, 'blues': 546, 'an': 547, 'aboriginal': 548, 'port': 549, 'folio': 550, 'east': 551, 'berlin': 552, 'al': 553, 'intimidators': 554, 'tin': 555, 'tree': 556, 'brunch': 557, 'drift:': 558, 'unmooring': 559, 'american': 560, 'military': 561, 'conan': 562, 'buccaneer': 563, 'cj': 564, 'snare': 565, 'mim': 566, 'faroe': 567, 'third': 568, 'eye': 569, 'showing': 570, 'joint': 571, 'republic': 572, 'congo': 573, 'help': 574, 'scholarmate': 575, 'boyce': 576, 'hart': 577, 'urban': 578, 'seating': 579, 'person': 580, 'cafeteria': 581, 'pauls': 582, 'crossroads': 583, 'snowfall': 584, '2/21/2022': 585, 'cristo': 586, 'link': 587, 'little': 588, 'us': 589, 'tempunauts': 590, 'novedades': 591, 'viernes': 592, 'sudamérica': 593, 'tanzania': 594, 'kirsten': 595, 'audra': 596, 'our': 597, 'location': 598, 'outdoor': 599, 'taverna': 600, 'kaya': 601, 'newest': 602, '00': 603, 'r&b': 604, 'marshal': 605, 'however': 606, 'much': 607, 'booze': 608, 'atmospheric': 609, 'black': 610, 'metal': 611, 'hardstyle': 612, 'local': 613, 'food': 614, 'court': 615, 'j': 616, 'mclean': 617, 'wanderer': 618, 'his': 619, 'shadow': 620, 'move': 621, 'named': 622, 'matt': 623, 'walker': 624, 'parking': 625, 'morris': 626, 'listen': 627, 'vickers': 628, 'tune': 629, 'twenties': 630, 'reservations': 631, 'vickie': 632, 'caitlin': 633, 'february': 634, '2018': 635, 'diner': 636, 'ribs': 637, 'not': 638, 'lexington': 639, 'av-53rd': 640, 'st': 641, 'lets': 642, 'aliens': 643, 'grill': 644, '&': 645, 'marcus': 646, 'swedish': 647, 'butler': 648, 'saw': 649, 'overcast': 650, 'twelve': 651, 'pm': 652, 'creative': 653, 'ufo': 654, 'senshi': 655, 'dai': 656, 'apolon': 657, 'cross': 658, 'bones': 659, 'style': 660, 'guest': 661, 'cat': 662, 'colder': 663, 'apolobamba': 664, 'integrated': 665, 'management': 666, 'natural': 667, 'oh': 668, 'warm': 669, 'woman': 670, 'mu': 671, 'ko': 672, 'phetra': 673, 'park': 674, 'administrative': 675, 'professionals': 676, 'attack': 677, 'surface': 678, 'analyzer': 679, 'christina': 680, 'schollin': 681, 'sleeping': 682, 'enemy': 683, 'bump': 684, 'off': 685, 'lover': 686, 'expected': 687, 'blue': 688, 'meaning': 689, 'mellowed': 690, 'gaming': 691, 'nineteen': 692, 'hear': 693, 'adam': 694, 'piano': 695, 'ballads': 696, 'netflix': 697, 'name': 698, 'shall': 699, 'we': 700, 'dance': 701, 'these': 702, 'neighboring': 703, 'lincoln': 704, 'king': 705, 'kitchen': 706, 'fifteen': 707, 'creole': 708, 'joey': 709, 'fatone': 710, 'spotlight': 711, '2016': 712, 'world': 713, 'vl': 714, 'mike': 715, 'dcode2016': 716, 'bon': 717, 'secour': 718, 'recovery': 719, 'road': 720, 'sita': 721, 'bettie': 722, 'global': 723, 'saturday': 724, 'review': 725, 'macy': 726, 'indiespensables': 727, 'info': 728, 'hands': 729, 'across': 730, 'border': 731, 'laying': 732, 'trip': 733, 'priorities': 734, 'parade': 735, 'verona': 736, 'into': 737, 'la': 738, 'mejor': 739, 'música': 740, '2017': 741, 'karina': 742, 'folk': 743, 'pop': 744, 'farruko': 745, 'presenta': 746, 'los': 747, 'menores': 748, 'amor': 749, 'check': 750, 'hulmeville': 751, 'wv': 752, 'karnataka': 753, 'california': 754, 'oak': 755, 'ridge': 756, 'lil': 757, 'jon': 758, 'sonja': 759, 'pizzeria': 760, 'battleaxe': 761, 'windows': 762, 'lebanon': 763, 'toucher': 764, 'rich': 765, '8': 766, 'massachusetts': 767, 'spirits': 768, 'pheba': 769, 'another': 770, 'added': 771, 'louis': 772, 'nelson': 773, 'delisle': 774, 'pulse': 775, 'americana': 776, '2012': 777, 'nardwuar': 778, 'human': 779, 'serviette': 780, 'down': 781, 'soft': 782, 'tetrazzini': 783, 'hollywood': 784, 'connection': 785, 'ricky': 786, 'bell': 787, 'invisible': 788, 'hook': 789, 'trailer': 790, 'fourche': 791, 'slovakia': 792, 'chris': 793, 'de': 794, 'burgh': 795, 'melancholia': 796, 'slap': 797, 'doctor': 798, 'home': 799, 'hill': 800, 'elizabeth': 801, 'queen': 802, 'ecola': 803, 'movement': 804, 'sheryfa': 805, 'luna': 806, 'jan': 807, 'smit': 808, 'endorphin': 809, 'rush': 810, 'don': 811, 'sherri': 812, 'meditate': 813, 'sounds': 814, 'nature': 815, '1977': 816, 'whats': 817, 'blythewood': 818, 'louisiana': 819, 'ep': 820, 'quasimoto': 821, 'nineties': 822, 'mjr': 823, '02:39:23': 824, 'apr': 825, 'sixteenth': 826, '2027': 827, 'cazenovia': 828, 'ca': 829, 'eleven': 830, 'reading': 831, 'visit': 832, 'pool': 833, 'fourteen': 834, 'samoa': 835, 'latin': 836, 'pa': 837, 'tritonian': 838, 'ring': 839, 'hitman': 840, 'city': 841, 'rex': 842, 'griffin': 843, 'steampunk': 844, 'ginestrata': 845, 'endangered': 846, 'species': 847, 'internet': 848, 'should': 849, 'melva': 850, 'heidi': 851, 'natasha': 852, 'things': 853, 'post': 854, 'melody': 855, 'b&b': 856, 'laos': 857, 'theme': 858, 'megon': 859, 'mcdonough': 860, 'slackers': 861, 'journal': 862, 'episode': 863, 'crossing': 864, 'lines': 865, 'come': 866, 'again': 867, 'smith': 868, 'new': 869, 'mexico': 870, 'lakes': 871, 'douglas': 872, 'company': 873, 'snowstorm': 874, 'coming': 875, 'dana': 876, 'pediatric': 877, 'oncology': 878, 'nursing': 879, 'thirties': 880, 'brazilian': 881, 'within': 882, 'comoros': 883, 'position': 884, 'inheritance': 885, 'loss': 886, 'misato': 887, 'watanabe': 888, 'trapeo': 889, 'idea': 890, 'fun': 891, 'salò': 892, 'available': 893, 'anywhere': 894, 'jag': 895, 'vill': 896, 'leva': 897, 'europa': 898, 'porta': 899, 'oman': 900, 'reckoning': 901, 'dodge': 902, 'merrily': 903, 'roll': 904, 'along': 905, 'marko': 906, 'desantis': 907, 'no': 908, 'young': 909, 'amc': 910, 'theaters': 911, 'monkeys': 912, 'tails': 913, 'zamboanga': 914, 'nearby': 915, 'northeast': 916, 'indian': 917, 'carolina': 918, 'during': 919, 'kent': 920, 'shootings': 921, 'remembrance': 922, 'el': 923, 'cocuy': 924, 'instrumental': 925, '15:04': 926, 'valley': 927, 'view': 928, 'night': 929, 'earth': 930, 'siler': 931, 'russia': 932, 'main': 933, 'cyprus': 934, 'ibm': 935, 'program': 936, 'temporary': 937, 'fix': 938, 'first': 939, 'other': 940, 'stories': 941, 'pandora': 942, 'udhreko': 943, 'choli': 944, 'chowdiah': 945, 'kaori': 946, 'mochida': 947, 'slimm': 948, 'cutta': 949, 'calhoun': 950, 'sing': 951, 'car': 952, 'expendables': 953, 'starting': 954, 'p': 955, 'pickens': 956, 'chill': 957, 'white': 958, 'heath': 959, 'south': 960, 'midnight': 961, 'truck': 962, 'nisswa': 963, 'ice': 964, 'cream': 965, 'mother': 966, 'law': 967, 'rise': 968, 'danni': 969, 'bassan': 970, 'jack': 971, 'scott': 972, 'fantasía': 973, 'histoires': 974, 'sans': 975, 'paroles': 976, 'women': 977, 'k-pop': 978, 'stone': 979, 'key': 980, 'dorchester': 981, 'shores': 982, 'jacob': 983, 'wirth': 984, 'proceed': 985, '2003': 986, 'taylor': 987, 'dayne': 988, 'kids': 989, 'recite': 990, 'dj': 991, 'green': 992, 'lantern': 993, 'targeted': 994, 'pull': 995, 'raining': 996, 'hundred': 997, 'thirty': 998, 'ion': 999, 'gobles': 1000, 'canada': 1001, 'chasing': 1002, 'fortune': 1003, 'lacuna': 1004, 'under': 1005, 'greenland': 1006, 'winter': 1007, 'she': 1008, 'anheuser': 1009, 'bush': 1010, 'pete': 1011, 'doherty': 1012, 'blood': 1013, 'décadas': 1014, 'rebekah': 1015, 'marcie': 1016, 'clink': 1017, 'senegal': 1018, 'ladyhawke': 1019, 'record': 1020, 'death': 1021, 'nurse': 1022, 'roadrunner': 1023, 'rec': 1024, 'releases': 1025, 'maldives': 1026, 'sixties': 1027, 'slacker': 1028, 'tom': 1029, 'titled': 1030, 'leaps': 1031, 'wang': 1032, 'lun': 1033, 'firepower': 1034, 'fair': 1035, 'hard': 1036, 'handle': 1037, 'onto': 1038, 'ultimate': 1039, '00s': 1040, 'francesco': 1041, 'gregori': 1042, 'classical': 1043, 'picks': 1044, 'feeling': 1045, 'tinker': 1046, 'legend': 1047, 'neverbeast': 1048, 'leeds': 1049, 'khedive': 1050, 'palace': 1051, 'aug': 1052, 'fifth': 1053, 'scandalous': 1054, 'corn': 1055, 'relish': 1056, 'walking': 1057, 'distance': 1058, 'hutchinson': 1059, 'll': 1060, 'freezing': 1061, '333': 1062, 'caplinger': 1063, 'mills': 1064, 'florida': 1065, 'does': 1066, 'miss': 1067, 'sloane': 1068, 'ad': 1069, 'sxsw': 1070, 'back': 1071, 'future': 1072, 'juniper': 1073, 'bûche': 1074, 'noël': 1075, 'bilal': 1076, 'heroes': 1077, 'might': 1078, 'magic': 1079, 'tables': 1080, 'kosher': 1081, 'steakhouse': 1082, 'kosovo': 1083, 'sun': 1084, 'houston': 1085, 'knowledge': 1086, 'decisions': 1087, 'read': 1088, 'control': 1089, 'trey': 1090, 'gunn': 1091, 'n': 1092, 'heavy': 1093, 'extraordinary': 1094, 'deus': 1095, 'deceptor': 1096, 'bouchon': 1097, 'tonga': 1098, 'jimmie': 1099, 'chasity': 1100, 'howard': 1101, 'snowy': 1102, 'parnell': 1103, 'week': 1104, 'camp': 1105, 'bird': 1106, 'bakery': 1107, 'souvlaki': 1108, 'tomorrow': 1109, 'satire': 1110, 'father': 1111, 'geraldine': 1112, 'ghostbusters': 1113, '-': 1114, 'acchiappafantasmi': 1115, 'gus': 1116, 'stevens': 1117, 'seafood': 1118, 'lounge': 1119, 'papua': 1120, 'guinea': 1121, 'emperor': 1122, 'wears': 1123, 'clothes': 1124, 'was': 1125, 'too': 1126, 'naive': 1127, 'simple': 1128, 'uncle': 1129, 'afternoon': 1130, 'shannon': 1131, 'pitcairn': 1132, 'london': 1133, 'borough': 1134, 'dirty': 1135, 'thompson': 1136, 'medical': 1137, 'philip': 1138, 'glass': 1139, 'quest': 1140, 'iranon': 1141, 'just': 1142, 'smile': 1143, '10:37': 1144, 'top': 1145, 'maynard': 1146, 'james': 1147, 'keenan': 1148, 'cotopaxi': 1149, 'breakfast': 1150, 'gastropub': 1151, 'rose': 1152, 'creek': 1153, 'elevenses': 1154, 'northern': 1155, 'mariana': 1156, 'delicatessen': 1157, 'testaroli': 1158, 'somalia': 1159, '7/25/2027': 1160, 'consequences': 1161, 'sos': 1162, '48': 1163, 'sword': 1164, 'travel': 1165, 'leap': 1166, 'darkness': 1167, 'niue': 1168, 'kiss': 1169, 'before': 1170, 'dying': 1171, 'tavern': 1172, 'tale': 1173, 'toa': 1174, 'gun': 1175, 'service': 1176, 'mick': 1177, 'johnson': 1178, 'apathy': 1179, 'electro': 1180, 'sur': 1181, 'pastelaria': 1182, 'svalbard': 1183, 'mayen': 1184, 'neon': 1185, 'bible': 1186, '/': 1187, 'currently': 1188, 'runs': 1189, 'drawn': 1190, 'theater': 1191, 'drums': 1192, 'marcial': 1193, 'ak': 1194, 'message': 1195, 'deaths': 1196, 'ian': 1197, 'richard': 1198, 'summer': 1199, 'dr': 1200, 'know': 1201, '90': 1202, 'sugarfoot': 1203, 'yauch': 1204, 'spooning': 1205, 'cooper': 1206, 'foundation': 1207, 'unlimited': 1208, 'igor': 1209, 'talkow': 1210, 'mary': 1211, 'kom': 1212, 'aviation': 1213, 'cocktail': 1214, 'hotter': 1215, 'pecan': 1216, 'grove': 1217, 'botswana': 1218, '09:30': 1219, 'realest': 1220, 'hillview': 1221, 'ne': 1222, 'mineiro': 1223, 'hubbardston': 1224, 'vanuatu': 1225, 'zezé': 1226, 'di': 1227, 'camargo': 1228, 'luciano': 1229, 'let': 1230, 'talk': 1231, 'devil': 1232, 'wild': 1233, 'solutions': 1234, 'montserrat': 1235, 'bright': 1236, 'ambush': 1237, 'girlfriend': 1238, 'truffade': 1239, 'virginia': 1240, 'cole': 1241, 'sunday': 1242, 'plutonium': 1243, 'files': 1244, 'lady': 1245, 'highwayman': 1246, 'dipson': 1247, 'atomic': 1248, 'cafe': 1249, 'hooksett': 1250, 'posiabble': 1251, 'genuine': 1252, 'signals': 1253, 'belief': 1254, 'early': 1255, 'england': 1256, 'greatest': 1257, 'ballad': 1258, 'seventies': 1259, 'voices': 1260, 'images': 1261, 'comertown': 1262, 'battle': 1263, 'hymn': 1264, 'china': 1265, 'ciribiribin': 1266, 'sandeep': 1267, 'khare': 1268, 'forcast': 1269, 'stanislaus': 1270, 'months': 1271, 'iron': 1272, 'fist': 1273, 'robotix': 1274, 'wy': 1275, 'gu': 1276, 'years': 1277, 'lima': 1278, 'call': 1279, 'joe': 1280, 'steve': 1281, 'albini': 1282, 'psychedelic': 1283, 'great': 1284, 'triple': 1285, 'district': 1286, 'columbia': 1287, 'deborah': 1288, 'vasquez': 1289, 'sorted': 1290, 'family': 1291, 'conexiones': 1292, 'critical': 1293, 'condition': 1294, 'assign': 1295, 'god': 1296, 'yale': 1297, 'singapore': 1298, '19': 1299, 'mccracken': 1300, 'niger': 1301, 'corner': 1302, 'justin': 1303, 'broadrick': 1304, 'type': 1305, 'super': 1306, 'robot': 1307, 'lagaylia': 1308, 'frazier': 1309, 'emotron': 1310, 'do': 1311, 'dates': 1312, 'mcdonald': 1313, 'leonard': 1314, 'cohen': 1315, 'brazuca': 1316, '2004': 1317, 'eliel': 1318, 'fred': 1319, 'knoblock': 1320, 'lo-fi': 1321, 'julian': 1322, 'cardio': 1323, 'real': 1324, 'mccoy': 1325, 'united': 1326, 'paramount': 1327, 'boss': 1328, 'glassy': 1329, 'junction': 1330, 'turkey': 1331, 'niece': 1332, 'callicoon': 1333, 'tennessee': 1334, 'story': 1335, 'cinemas': 1336, 'graduate': 1337, 'faculty': 1338, 'philosophy': 1339, 'week-end': 1340, 'selva': 1341, 'jedediah': 1342, 'wisconsin': 1343, '22:54': 1344, 'jacinto': 1345, 'concentración': 1346, 'mind': 1347, 'chaos': 1348, 'january': 1349, 'twentieth': 1350, 'brazil': 1351, '1973': 1352, '21': 1353, '33': 1354, 'wake': 1355, 'everybody': 1356, 'making': 1357, 'teacher': 1358, 'anguilla': 1359, 'harry': 1360, 'dubstep': 1361, 'dangles': 1362, 'getting': 1363, 'falls': 1364, 'provincial': 1365, 'josie': 1366, 'carissa': 1367, 'lindsay': 1368, 'trentino': 1369, 'oreo': 1370, 'bald': 1371, 'kaskade': 1372, 'express': 1373, 'mint': 1374, 'brian': 1375, 'larsen': 1376, 'digster': 1377, 'sleep': 1378, 'physics': 1379, 'impossible': 1380, '70s': 1381, 'smash': 1382, 'nicht': 1383, 'sprechen': 1384, 'partners': 1385, 'crime': 1386, 'joann': 1387, 'lo': 1388, 'que': 1389, 'suena': 1390, 'angeles': 1391, 'don’t': 1392, 'break': 1393, 'loves': 1394, 'peaches': 1395, 'discography': 1396, 'synthpop': 1397, 'through': 1398, 'x': 1399, 'playist': 1400, 'camino': 1401, 'clase': 1402, 'could': 1403, 'b': 1404, 'men': 1405, 'gahō': 1406, 'nathaniel': 1407, 'shilkret': 1408, 'trance': 1409, 'life': 1410, '2013': 1411, 'groove': 1412, 'shark': 1413, 'madagascar': 1414, 'snapfinger': 1415, 'dinner': 1416, 'mcmurray': 1417, 'seventeenth': 1418, 'marjorie': 1419, 'edith': 1420, 'martina': 1421, 'homicide:': 1422, 'killing': 1423, 'streets': 1424, 'grand': 1425, 'towne': 1426, 'mp': 1427, 'pigs': 1428, 'blankets': 1429, 'theo': 1430, 'keating': 1431, 'december': 1432, 'boca': 1433, 'raton': 1434, 'ia': 1435, 'mountains': 1436, '2000': 1437, 'millennium': 1438, 'tommy': 1439, 'ridgley': 1440, 'verjamem': 1441, 'hong': 1442, 'junyang': 1443, 'rutherfordton': 1444, 'rhode': 1445, '22nd': 1446, 'glennie': 1447, 'lewisville': 1448, 'ballachulish': 1449, 'sudan': 1450, 'own': 1451, 'serenada': 1452, 'stracciatella': 1453, 'lapponia': 1454, 'flamenco': 1455, 'ti': 1456, 'myanmar': 1457, 'about': 1458, 'sardonic': 1459, 'wrath': 1460, 'big': 1461, 'mouth': 1462, 'elk': 1463, 'poland': 1464, 'brockway': 1465, 'colorado': 1466, 'thai': 1467, 'fog': 1468, 'fairwood': 1469, 'garage': 1470, 'wave': 1471, 'revival': 1472, 'eternal': 1473, 'prisoner': 1474, 'george': 1475, 'slept': 1476, 'fairy': 1477, '100': 1478, 'tracks': 1479, 'any': 1480, 'courtship': 1481, 'princess': 1482, 'leia': 1483, 'grandmother': 1484, 'umbrian': 1485, '7th': 1486, 'robert': 1487, 'nighthawk': 1488, 'places': 1489, 'hahnville': 1490, 'minnesota': 1491, 'lord': 1492, 'construction': 1493, 'project': 1494, 'information': 1495, 'committee': 1496, 'feels': 1497, 'nationalpark': 1498, 'midongy': 1499, 'du': 1500, 'sud': 1501, 'hive': 1502, 'propolis': 1503, 'fickle': 1504, 'eighties': 1505, 'fifty': 1506, 'roeland': 1507, 'guadeloupe': 1508, 'rings:': 1509, 'conquest': 1510, 'short': 1511, 'fast': 1512, 'prey': 1513, 'relax': 1514, 'unwind': 1515, 'bad': 1516, 'live~legend': 1517, '1997': 1518, 'milligan': 1519, 'college': 1520, 'speakeasy': 1521, 'titiyo': 1522, 'harveysburg': 1523, 'wa': 1524, 'maryland': 1525, 'following': 1526, 'gear': 1527, 'terraphiles': 1528, 'dewey': 1529, 'incorporate': 1530, 'warp': 1531, 'occasional': 1532, 'wife': 1533, 'cocos': 1534, 'input': 1535, 'anything': 1536, 'chieko': 1537, 'ochi': 1538, 'pollock': 1539, 'todd': 1540, 'snider': 1541, 'latino': 1542, 'kokomo': 1543, 'fall': 1544, 'sungmin': 1545, 'elmer': 1546, 'bernstein': 1547, 'swine': 1548, 'industry': 1549, 'unravel': 1550, 'jul': 1551, '4th': 1552, 'daughter': 1553, 'rouge': 1554, 'faith': 1555, 'needs': 1556, 'starlight': 1557, 'eleventh': 1558, 'md': 1559, 'church': 1560, 'truly': 1561, 'warped': 1562, 'ky': 1563, 'loveless': 1564, 'braindead': 1565, 'megaphone': 1566, 'prompton': 1567, 'arthur': 1568, 'russell': 1569, 'trenton': 1570, 'heights': 1571, 'fort': 1572, 'pulaski': 1573, 'monument': 1574, 'engadine': 1575, 'their': 1576, 'finest': 1577, 'sort': 1578, 'form': 1579, '1959': 1580, 'stuart': 1581, 'garrard': 1582, 'turn': 1583, '1991': 1584, 'woven': 1585, 'path': 1586, 'hip': 1587, 'hop': 1588, 'rocksteady': 1589, 'osteria': 1590, 'weeks': 1591, 'being': 1592, 'played': 1593, 'warren': 1594, 'madison': 1595, 'flaxton': 1596, 'arletta': 1597, 'malawi': 1598, 'tea': 1599, 'maple': 1600, 'glen': 1601, 'reason': 1602, 'bachelor': 1603, 'carvel': 1604, 'group': 1605, 'total': 1606, 'concerto': 1607, 'thekra': 1608, 'fernley': 1609, 'mj': 1610, 'gainesville': 1611, 'daily': 1612, 'register': 1613, 'magnificent': 1614, 'rosana': 1615, 'issue': 1616, 'favorite': 1617, 'slaughterhouse': 1618, 'clowns': 1619, 'nour': 1620, 'mhanna': 1621, 'workday': 1622, 'moments': 1623, 'seychelles': 1624, '1954': 1625, 'nuestros': 1626, 'carácter': 1627, 'bolsa': 1628, 'chica': 1629, 'foggy': 1630, 'rebecca': 1631, 'hewitt': 1632, 'horrible': 1633, 'hopeful': 1634, 'enrique': 1635, 'iglesias': 1636, 'miller': 1637, 'nina': 1638, 'hagen': 1639, 'essential': 1640, 'bride’s': 1641, 'journey': 1642, 'portrait': 1643, 'nude': 1644, 'amenia': 1645, 'wi': 1646, 'joel': 1647, 'hastings': 1648, 'giving': 1649, 'wide': 1650, 'window': 1651, 'ok': 1652, 'persian': 1653, 'ex': 1654, 'husband': 1655, 'elkie': 1656, 'brooks': 1657, 'happy': 1658, 'birthday': 1659, 'roots': 1660, 'outsiders': 1661, 'highway': 1662, 'chronicles': 1663, 'soul': 1664, 'nankin': 1665, 'fr': 1666, 'iemand': 1667, 'als': 1668, 'jij': 1669, 'cliffwood': 1670, 'rustic': 1671, 'inn': 1672, 'members': 1673, 'nappanee': 1674, 'sint': 1675, 'maarten': 1676, 'zen': 1677, 'focus': 1678, 'franj': 1679, 'hess:': 1680, 'biography': 1681, 'kurt': 1682, 'classics': 1683, 'whosoever': 1684, 'offend': 1685, 'showcase': 1686, 'autobiography': 1687, 'alice': 1688, 'toklas': 1689, 'palmetto': 1690, '1985': 1691, 'patrick': 1692, 'cowley': 1693, 'adolf': 1694, 'hitler:': 1695, 'downfall': 1696, 'episodi': 1697, 'cherryh': 1698, 'odyssey': 1699, 'kulpsville': 1700, 'togo': 1701, '26th': 1702, 'eastlake': 1703, 'handover': 1704, 'arclight': 1705, 'jill': 1706, 'sound': 1707, 'murder': 1708, 'mana': 1709, 'elvira': 1710, 'scarlet': 1711, '12': 1712, 'horace': 1713, 'silver': 1714, 'messengers': 1715, 'running': 1716, '170': 1717, '190': 1718, 'bpm': 1719, 'brubeck': 1720, 'plays': 1721, 'colleagues': 1722, 'chrisman': 1723, 'cradle': 1724, 'robbers': 1725, 'storm': 1726, 'albania': 1727, 'qr': 1728, 'iii': 1729, 'bobby': 1730, 'bare': 1731, 'small': 1732, 'screen': 1733, '00:09:07': 1734, 'purchase': 1735, 'samuel': 1736, 'tyne': 1737, 'scription': 1738, 'data': 1739, 'trash': 1740, 'totally': 1741, 'framing': 1742, 'ages': 1743, '1976': 1744, 'jam': 1745, 'master': 1746, 'jay': 1747, 'vigus': 1748, 'cluster': 1749, 'computing': 1750, 'tomb': 1751, 'quotations': 1752, 'chairman': 1753, 'mao': 1754, 'tse-tung': 1755, 'definitely': 1756, 'worth': 1757, 'puppet': 1758, 'string': 1759, 'sunny': 1760, 'twenty-seventh': 1761, '2031': 1762, 'armenian': 1763, 'plitt': 1764, 'autumn': 1765, 'or': 1766, 'friend': 1767, 'holy': 1768, 'capital': 1769, 'arab': 1770, 'emirates': 1771, 'they': 1772, 'serve': 1773, 'pepperoni': 1774, 'dishes': 1775, 'southeastern': 1776, 'karthaus': 1777, 'throwback': 1778, 'christy': 1779, 'louise': 1780, 'alexandra': 1781, '17:38:04': 1782, 'hopes': 1783, 'blind': 1784, 'alley': 1785, 'screamplay': 1786, 'fight': 1787, 'northeastern': 1788, 'satanta': 1789, 'beavis': 1790, 'butt-head': 1791, 'pura': 1792, 'vida': 1793, 'kurdishmedia': 1794, 'com': 1795, 'walerij': 1796, 'leontjew': 1797, 'wonderful': 1798, 'flying': 1799, 'scotsman': 1800, 'stormy': 1801, '15th': 1802, '2026': 1803, 'federated': 1804, 'states': 1805, 'micronesia': 1806, 'radical': 1807, 'history': 1808, 'airey': 1809, 'gonna': 1810, 'raise': 1811, 'hell': 1812, 'bruce': 1813, 'lee': 1814, 'zenith': 1815, 'angle': 1816, '131': 1817, 'atanassow-see': 1818, 'ri': 1819, 'steady': 1820, 'goes': 1821, 'manthan': 1822, 'wedding': 1823, 'copy': 1824, 'skatepark': 1825, 'punks': 1826, 'turbonegro': 1827, 'why': 1828, 'leave': 1829, 'bass': 1830, 'troopers': 1831, 'scheduled': 1832, 'near': 1833, 'moldova': 1834, 'fri': 1835, 'twin': 1836, 'peaks:': 1837, 'fire': 1838, 'goodrich': 1839, 'quality': 1840, 'thirteen': 1841, 'dochū-kōtsu': 1842, 'prefectural': 1843, 'indoor': 1844, 'meal': 1845, 'searves': 1846, 'kouglof': 1847, 'wanted': 1848, 'erykah': 1849, 'badu': 1850, '22': 1851, 'chicken': 1852, 'bolivia': 1853, 'biggest': 1854, 'loser': 1855, 'brunei:': 1856, 'spirit': 1857, 'heredity': 1858, 'bullet': 1859, 'target': 1860, 'clermont': 1861, 'coffeehouse': 1862, 'midland': 1863, 'stephen': 1864, 'jones': 1865, 'harrison–crawford': 1866, 'iowa': 1867, 'wait': 1868, 'until': 1869, 'hover': 1870, 'racer': 1871, 'tonight': 1872, 'rajasthani': 1873, 'amco': 1874, 'entertainment': 1875, 'criminal': 1876, 'criminology': 1877, 'brothers': 1878, 'karamazov': 1879, 'adventure': 1880, 'carbuncle': 1881, 'dies': 1882, 'gary': 1883, 'chaw': 1884, 'flies': 1885, '1994-2009': 1886, 'jazzy': 1887, 'romance': 1888, 'ct': 1889, 'naked': 1890, 'latest': 1891, 'peter': 1892, 'appleyard': 1893, 'kerrick': 1894, 'reestaurant': 1895, 'monro': 1896, 'tatjana': 1897, 'iwanowna': 1898, 'bulanowa': 1899, 'parksdale': 1900, 'missouri': 1901, 'masterful': 1902, 'mystery': 1903, 'tour': 1904, 'morning': 1905, 'rhythm': 1906, 'jailbird': 1907, 'wynter': 1908, 'gordon': 1909, 'friends': 1910, 'players': 1911, 'falcon': 1912, 'accounting': 1913, 'political': 1914, 'liberalism': 1915, 'jets': 1916, 'dec': 1917, '23': 1918, 'banquet': 1919, 'damned': 1920, 'march': 1921, 'once': 1922, 'upon': 1923, 'groesbeck': 1924, 'cayman': 1925, 'ninety': 1926, 'kansas': 1927, 'dancehall': 1928, 'official': 1929, 'trap': 1930, 'planet': 1931, 'smashers': 1932, 'bill': 1933, 'berry': 1934, 'elrow': 1935, 'outlaw': 1936, 'gor': 1937, 'oklahoma': 1938, 'roy': 1939, 'orbison': 1940, 'youtube': 1941, 'norway': 1942, 'sunset': 1943, 'cobb': 1944, 'wendy': 1945, 'fifties': 1946, 'ancient': 1947, 'art': 1948, 'beneath': 1949, 'harvest': 1950, 'sky': 1951, 'restautant': 1952, 'bistro': 1953, 'final': 1954, 'score': 1955, 'emida': 1956, 'tries': 1957, 'marry': 1958, 'rila': 1959, 'nov': 1960, '25': 1961, 'electronics': 1962, 'upper': 1963, 'marlboro': 1964, 'uintah': 1965, 'babylon:': 1966, 'anthology': 1967, 'aisha': 1968, 'craving': 1969, 'cordon': 1970, 'bleu': 1971, 'shops': 1972, 'temps': 1973, 'memory': 1974, 'lane': 1975, 'lansford': 1976, 'cash': 1977, 'curry': 1978, 'long': 1979, 'wideacre': 1980, 'possiable': 1981, 'trout': 1982, 'bougatsa': 1983, 'weir': 1984, 'farm': 1985, 'historic': 1986, 'site': 1987, 'jessie': 1988, 'dale': 1989, 'wright': 1990, 'lupe': 1991, '20': 1992, '2040': 1993, 'vikku': 1994, 'vinayakram': 1995, 'nicky': 1996, 'really': 1997, 'baba': 1998, 'au': 1999, 'rhum': 2000, 'sudden': 2001, 'rainstorm': 2002, 'algeria': 2003, 'reklaw': 2004, '03:19:13': 2005, 'harlow': 2006, 'wilcox': 2007, 'bangers': 2008, 'cochrane': 2009, '1990': 2010, 'indonesian': 2011, 'after': 2012, 'hawaii': 2013, 'age': 2014, 'haunted': 2015, 'honeymoon': 2016, 'decoding': 2017, 'reality': 2018, '5/20/2028': 2019, 'pataskala': 2020, 'crepe': 2021, 'nc': 2022, 'pelland': 2023, 'birth': 2024, 'nation': 2025, 'author': 2026, 'knight': 2027, 'somewhere': 2028, '24th': 2029, 'indiana': 2030, 'giants': 2031, 'unbound': 2032, 'found': 2033, 'them': 2034, 'brownfield': 2035, 'wish': 2036, 'enjoy': 2037, 'johnny': 2038, 'paycheck': 2039, 'grass': 2040, 'widows': 2041, 'cova': 2042, 'frisco': 2043, 'therese': 2044, 'dolce': 2045, 'insurrection': 2046, 'random': 2047, 'bells': 2048, 'towers': 2049, 'korona': 2050, 'bondage': 2051, 'freedom': 2052, 'fill': 2053, 'yourself': 2054, 'ray': 2055, 'manzarek': 2056, 'red': 2057, 'monkey': 2058, 'nancy': 2059, 'ruiz': 2060, 'molly': 2061, 'gibraltar': 2062, 'liberia': 2063, 'sweet': 2064, 'teyana': 2065, 'limited': 2066, 'lovers': 2067, 'disturbance': 2068, 'yellow': 2069, 'star:': 2070, 'persecution': 2071, 'jews': 2072, 'europe': 2073, '1933-45': 2074, 'always': 2075, 'swan': 2076, 'minotaur': 2077, 'question': 2078, 'tokelau': 2079, 'spanish': 2080, 'rice': 2081, 'kamrar': 2082, 'midday': 2083, 'mascoutah': 2084, '09:04:38': 2085, 'nypd': 2086, 'york': 2087, 'police': 2088, 'department': 2089, 'kong': 2090, 'charlie': 2091, 'hunter': 2092, 'sea': 2093, 'twentynine': 2094, 'palms': 2095, 'spectral': 2096, 'dusk': 2097, 'merced': 2098, 'sun-star': 2099, 'lips': 2100, 'page': 2101, 'azerbaijan': 2102, 'rodriguez': 2103, 'mujeres': 2104, 'y': 2105, 'hombres': 2106, 'fiesta': 2107, 'late': 2108, 'walt': 2109, 'mickey': 2110, 'funtime': 2111, 'albino': 2112, 'blacksheep': 2113, 'denmark': 2114, 'single': 2115, 'collection:': 2116, 'hotchpotch': 2117, '165': 2118, 'nairobi': 2119, 'frankie': 2120, 'laine': 2121, 'swagger': 2122, 'panisses': 2123, 'naytahwaush': 2124, 'mopreme': 2125, 'shakur': 2126, '¡fiesta': 2127, 'without': 2128, 'witness': 2129, 'boots': 2130, 'emma': 2131, 'wood': 2132, 'cuba': 2133, 'smoking': 2134, 'room': 2135, 'ma': 2136, 'kickboxer': 2137, 'redemption': 2138, 'croatia': 2139, 'oliver': 2140, 'cheatham': 2141, 'anne': 2142, 'mon': 2143, 'nevado': 2144, 'tres': 2145, 'cruces': 2146, 'mar': 2147, '2020': 2148, 'shoo': 2149, 'iheart': 2150, 'origins': 2151, 'consciousness': 2152, '2120': 2153, 'avenue': 2154, 'jquery': 2155, 'mobile': 2156, 'playground': 2157, 'wind': 2158, 'nm': 2159, '11th': 2160, 'nitti': 2161, 'favorites': 2162, 'bronco': 2163, 'billy': 2164, 'coaldale': 2165, 'arkansas': 2166, 'brave': 2167, 'archer': 2168, 'rapids': 2169, 'roadhouse': 2170, '2039': 2171, 'playlis': 2172, 'released': 2173, '1968': 2174, 'centenary': 2175, 'evening': 2176, 'seasons': 2177, 'rosco': 2178, 'untold': 2179, 'moody': 2180, 'heaven': 2181, 'ami': 2182, 'koshimizu': 2183, 'ron': 2184, 'grainer': 2185, 'aap': 2186, 'aise': 2187, 'na': 2188, 'died': 2189, 'todo': 2190, 'yoshimi': 2191, 'battles': 2192, 'hip-hop': 2193, 'robots': 2194, 'visible': 2195, 'wings': 2196, 'entre': 2197, 'andes': 2198, 'kevin': 2199, 'johansen': 2200, 'lamb': 2201, 'lies': 2202, 'broadway': 2203, 'assignments': 2204, 'aree': 2205, 'poneto': 2206, 'creatures': 2207, 'light': 2208, 'sumner': 2209, 'vietnam': 2210, 'burleigh': 2211, 'cascading': 2212, 'waterfall': 2213, 'youngest': 2214, 'profession': 2215, 'speed': 2216, 'tiplersville': 2217, '12/28/2019': 2218, 'puerto': 2219, 'rico': 2220, 'lisa': 2221, 'tsipouro': 2222, 'connecticut': 2223, '2008': 2224, 'mashable': 2225, 'geneva': 2226, 'wilda': 2227, 'blacksville': 2228, 'force': 2229, 'newtown': 2230, 'anthony': 2231, 'peveril': 2232, 'peak': 2233, 'seventeen': 2234, 'elgin': 2235, 'schoolhouse': 2236, 'different': 2237, 'slanguages': 2238, 'labour': 2239, 'magic:': 2240, 'theory': 2241, 'practice': 2242, 'wars:': 2243, 'clone': 2244, 'wars': 2245, 'giorgio': 2246, 'moroder': 2247, 'cedar': 2248, 'wilderness': 2249, 'almyra': 2250, 'shake': 2251, 'beef': 2252, 'center': 2253, 'vortex': 2254, 'alaska': 2255, '40': 2256, 'ranch': 2257, 'twenty-second': 2258, '2023': 2259, 'thunder': 2260, 'iranian': 2261, 'fuzzy': 2262, 'systems': 2263, 'retro': 2264, 'foghat': 2265, 'georgina': 2266, 'spa': 2267, 'chapman': 2268, 'polish': 2269, 'assault': 2270, 'never': 2271, 'happened': 2272, 'seats': 2273, 'churrascaria': 2274, 'using': 2275, 'charlotte': 2276, 'hall': 2277, 'kitts': 2278, 'nevis': 2279, 'struggle': 2280, 'meg': 2281, 'seron': 2282, 'cherie': 2283, 'josephine': 2284, 'indonesia': 2285, 'casino': 2286, 'boogie': 2287, 'civil': 2288, 'kiley': 2289, 'dean': 2290, 'loving': 2291, 'couples': 2292, 'famous': 2293, 'harrowing': 2294, 'gwynedd': 2295, 'strength': 2296, 'alba': 2297, 'behind': 2298, 'closed': 2299, 'doors': 2300, 'youth': 2301, 'against': 2302, 'christ': 2303, 'pw': 2304, 'rouhollah': 2305, 'khaleghi': 2306, 'noise': 2307, '19:26': 2308, 'guests': 2309, 'lazy': 2310, 'ny': 2311, 'billion': 2312, 'dollar': 2313, 'ransom': 2314, 'rafet': 2315, 'roman': 2316, 'rising': 2317, 'mr': 2318, 'ponsonby': 2319, 'gradyville': 2320, 'brooklyn': 2321, 'beat': 2322, 'beamer': 2323, 'memorial': 2324, 'conservation': 2325, 'pimp': 2326, 'c': 2327, 'remix': 2328, 'fine': 2329, 'gilmour': 2330, 'hellboy:': 2331, 'troll': 2332, 'witch': 2333, 'others': 2334, 'shiralee': 2335, 'syreeta': 2336, 'ringgold': 2337, 'bluff': 2338, 'bottles': 2339, 'toxicology': 2340, 'environmental': 2341, 'health': 2342, 'forgetting': 2343, 'fear': 2344, 'hat': 2345, 'deenanath': 2346, 'mangeshkar': 2347, 'international': 2348, 'robotics': 2349, 'research': 2350, 'bonner': 2351, '2025': 2352, 'colleague': 2353, 'owings': 2354, 'masks': 2355, 'romania': 2356, 'montchanin': 2357, 'tbe': 2358, 'federico': 2359, 'albert': 2360, 'virgin': 2361, 'many': 2362, 'blini': 2363, 'worlds': 2364, 'nur': 2365, 'mit': 2366, 'dir': 2367, 'remember': 2368, 'hollow': 2369, 'brookdale': 2370, 'zimbabwe': 2371, 'medici': 2372, 'seal': 2373, 'ocean': 2374, 'rodna': 2375, 'herkimer': 2376, 'liver': 2377, 'onions': 2378, 'bessie': 2379, 'antonia': 2380, 'era': 2381, 'ties': 2382, 'bind': 2383, 'warning': 2384, 'purple': 2385, 'diary': 2386, 'stream': 2387, 'safety': 2388, 'timings': 2389, 'starship': 2390, 'tuscan': 2391, 'adela': 2392, 'hallam': 2393, '2005': 2394, 'ruslana': 2395, 'lyschytschko': 2396, 'greece': 2397, 'takilma': 2398, 'gaddar:': 2399, 'traitor': 2400, 'silence': 2401, 'lambs': 2402, 'cuban': 2403, 'horatio': 2404, 'surf': 2405, 'taco': 2406, 'uniontown': 2407, 'puttering': 2408, '11:47:52': 2409, 'africa': 2410, 'hero': 2411, 'francisco': 2412, 'brewing': 2413, 'located': 2414, 'stillest': 2415, 'treeful': 2416, 'starling': 2417, 'mer': 2418, 'palestine': 2419, 'gave': 2420, 'newburyport': 2421, 'caledonia': 2422, 'number': 2423, 'listings': 2424, 'deweese': 2425, 'boma': 2426, 'paul': 2427, 'cargnello': 2428, 'gillan': 2429, 'safe': 2430, 'sucks': 2431, 'top-five': 2432, '1992': 2433, 'penelopiad': 2434, 'hex': 2435, 'hector': 2436, 'old': 2437, 'school': 2438, 'inside': 2439, 'twinkie': 2440, 'clark': 2441, 'mamaroneck': 2442, 'pipe': 2443, 'turbulent': 2444, 'term': 2445, 'tyke': 2446, 'tiler': 2447, 'galsoft': 2448, 'linux': 2449, 'pavarotti': 2450, 'tatamy': 2451, 'chalice': 2452, 'sankha': 2453, 'chatterjee': 2454, 'southside': 2455, '1-1000': 2456, 'kenya': 2457, 'elitsa': 2458, 'todorova': 2459, 'elstak': 2460, '1988': 2461, 'kyle': 2462, 'riabko': 2463, 'quadrophenia': 2464, 'moya': 2465, 'brennan': 2466, 'cheryl': 2467, 'wheeler': 2468, 'dorrian': 2469, '18:28': 2470, 'order': 2471, 'noon': 2472, 'omoide': 2473, 'okkusenman': 2474, 'primate': 2475, 'tia': 2476, 'rap': 2477, 'elida': 2478, '15': 2479, 'storeys': 2480, 'somesville': 2481, 'boggs': 2482, 'demonstration': 2483, 'bridges': 2484, 'county': 2485, '90s': 2486, 'alpha': 2487, 'blondy': 2488, 'toast': 2489, 'duel:': 2490, 'pakistan': 2491, 'flight': 2492, 'yossif': 2493, 'kobzon': 2494, 'anti-semitism': 2495, '21st': 2496, 'century:': 2497, 'resurgence': 2498, 'mountainair': 2499, '1960': 2500, 'hermann': 2501, 'baumann': 2502, 'equatorial': 2503, 'jim': 2504, 'martin': 2505, 'lopeno': 2506, 'thailand': 2507, 'ticks': 2508, 'roaring': 2509, 'forecase': 2510, 'ohio': 2511, 'universe': 2512, 'maker': 2513, 'prefect': 2514, 'tortelloni': 2515, 'nh': 2516, 'body': 2517, 'pursuit': 2518, 'rhapsody': 2519, 'quicksand': 2520, 'valentine': 2521, 'access': 2522, 'contact': 2523, 'nu': 2524, 'oasis': 2525, 'drive-in': 2526, 'dive': 2527, 'bomber': 2528, 'margie': 2529, 'warhead': 2530, 'half': 2531, 'cut': 2532, 'season': 2533, 'tim': 2534, 'finn': 2535, 'rick': 2536, 'astley': 2537, '50': 2538, 'uncut': 2539, 'sasu': 2540, 'ripatti': 2541, 'edesville': 2542, 'mn': 2543, 'proudly': 2544, 'marches': 2545, 'pizza': 2546, 'animals': 2547, 'puro': 2548, 'asia': 2549, 'nitollano': 2550, 'lonergan': 2551, 'regal': 2552, 'calakmul': 2553, 'biosphere': 2554, 'selektor': 2555, 'buddy': 2556, 'desylva': 2557, 'balvin': 2558, 'locate': 2559, 'tristan': 2560, 'betrayal': 2561, 'volver': 2562, 'crown': 2563, 'candy': 2564, 'lacy': 2565, 'vi': 2566, 'reservea': 2567, 'gabon': 2568, 'circus': 2569, 'deana': 2570, 'carter': 2571, 'kingdom': 2572, 'possible': 2573, 'think': 2574, 'smoke': 2575, 'mirrors': 2576, 'erin': 2577, 'harkes': 2578, 'basement': 2579, 'screams': 2580, 'republican': 2581, 'brain': 2582, '1975': 2583, 'baxter': 2584, 'g': 2585, 'fade': 2586, 'away': 2587, 'chen': 2588, 'jiafeng': 2589, '2014': 2590, 'lpaying': 2591, 'wizard': 2592, 'ralls': 2593, 'maine': 2594, 'f': 2595, 'furniture': 2596, 'umatilla': 2597, 'lights': 2598, 'audio': 2599, 'gates': 2600, 'walsh': 2601, 'electronic': 2602, 'jesus': 2603, 'consolidated': 2604, 'dansevise': 2605, 'ebi': 2606, 'dark': 2607, 'willows:': 2608, 'sisterhood': 2609, 'grows': 2610, 'fighting': 2611, 'buffalo': 2612, 'chicamocha': 2613, 'cassie': 2614, 'ventura': 2615, 'genre': 2616, 'bender': 2617, 'simon': 2618, 'webbe': 2619, 'sensation': 2620, 'salil': 2621, 'chowdhury': 2622, '35': 2623, '1970': 2624, 'playlsit': 2625, 'brandon': 2626, 'paris': 2627, 'metalsucks': 2628, 'christian': 2629, 'gangsta': 2630, 'anna': 2631, 'yesipova': 2632, 'top-5': 2633, 'inconfundible': 2634, 'background': 2635, 'infinite': 2636, 'electric': 2637, 'tones': 2638, 'kurutta': 2639, 'taiyō': 2640, 'seward': 2641, 'community': 2642, 'shabbona': 2643, 'stress': 2644, 'free': 2645, 'leonville': 2646, 'forever': 2647, 'malcolm': 2648, 'sc': 2649, 'mellow': 2650, 'bars': 2651, 'wakefield': 2652, 'shoot': 2653, 'elephant': 2654, 'bienville': 2655, 'pioneer': 2656, 'measuring': 2657, 'mac': 2658, 'wiseman': 2659, 'caliente': 2660, 'fox': 2661, 'child': 2662, 'leann': 2663, 'rimes': 2664, 'taken': 2665, 'flood': 2666, 'lodi': 2667, 'granddaughter': 2668, 'elmore': 2669, 'heartbreak': 2670, 'pacific': 2671, 'nationaal': 2672, 'garphyttan': 2673, 'modesto': 2674, 'joanna': 2675, 'ella': 2676, 'general': 2677, 'macedonia': 2678, 'modern': 2679, 'subcontract': 2680, 'pokémon': 2681, 'movie:': 2682, 'black—victini': 2683, 'reshiram': 2684, 'white—victini': 2685, 'zekrom': 2686, 'supper': 2687, 'il': 2688, 'heat': 2689, 'bulat': 2690, 'schalwowitsch': 2691, 'okudschawa': 2692, 'cupcakes': 2693, 'section': 2694, 'itch': 2695, 'doomsday': 2696, 'comfort': 2697, 'koichi': 2698, 'sugiyama': 2699, 'whm': 2700, 'monson': 2701, 'u': 2702, 'minor': 2703, 'outlying': 2704, 'hole': 2705, '72nd': 2706, 'bonaventure': 2707, 'stick': 2708, 'fonseca': 2709, '1984': 2710, 'spider': 2711, 'moustapha': 2712, 'amar': 2713, 'bomberman': 2714, 'touch': 2715, 'linzi': 2716, 'stoppard': 2717, 'fresh': 2718, 'end': 2719, 'goldie': 2720, 'start': 2721, 'disney': 2722, 'rates': 2723, 'salute': 2724, '18th': 2725, '2029': 2726, 'kanopolis': 2727, 'countryman': 2728, 'deve': 2729, 'morire': 2730, 'thing': 2731, 'nassau': 2732, 'bay': 2733, 'uzbekistan': 2734, 'lidell': 2735, 'townsell': 2736, 'esenciales': 2737, 'eastern': 2738, 'european': 2739, 'sonora': 2740, 'qatar': 2741, 'fais': 2742, 'les': 2743, 'backs': 2744, 'sarah': 2745, 'geronimo': 2746, 'jewish': 2747, 'indiespain': 2748, 'ramble': 2749, 'halloween': 2750, 'teens': 2751, 'june': 2752, '27th': 2753, 'volume': 2754, 'ninth': 2755, '1951': 2756, 'bother': 2757, 'yma': 2758, 'sumac': 2759, 'animal': 2760, 'collective': 2761, 'sushi': 2762, 'brucetown': 2763, 'adobe': 2764, 'brackets': 2765, 'tires': 2766, 'bury': 2767, 'living': 2768, 'lavina': 2769, 'glory': 2770, 'perfect': 2771, 'beethoven': 2772, 'russian': 2773, 'beauty': 2774, 'charles': 2775, 'pinckney': 2776, 'dc': 2777, 'platinum': 2778, 'ghetto': 2779, 'operation:': 2780, 'gluten': 2781, 'arp': 2782, 'solid': 2783, 'mandya': 2784, 'swarna': 2785, 'trishna': 2786, 'playinh': 2787, 'top-50': 2788, 'jeff': 2789, 'irwin': 2790, 'coffee': 2791, 'computer': 2792, 'aspro': 2793, 'mavro': 2794, 'szymczyk': 2795, 'sushis': 2796, 'burning': 2797, 'castles': 2798, 'steel': 2799, 'rei': 2800, 'momo': 2801, 'egg': 2802, 'collecting': 2803, 'australia': 2804, 'master:': 2805, 'axis': 2806, 'evil': 2807, 'been': 2808, 'cancelled': 2809, 'sardis': 2810, 'alas': 2811, 'raíces': 2812, 'pybus': 2813, 'seat': 2814, 'cochran': 2815, 'turf': 2816, 'char': 2817, 'colombia': 2818, '12th': 2819, '2035': 2820, 'barbra': 2821, 'streisand': 2822, 'krypto': 2823, 'superdog': 2824, 'eggo': 2825, 'marcella': 2826, 'erma': 2827, 'leanne': 2828, 'rivera': 2829, 'cusinie': 2830, 'he': 2831, 'fears': 2832, 'wolf': 2833, 'wynton': 2834, 'kelly': 2835, 'raisins': 2836, 'secs': 2837, 'et': 2838, 'amandes': 2839, 'edition': 2840, 'naomi': 2841, 'schemer': 2842, 'eef': 2843, 'barzelay': 2844, 'trad': 2845, 'crack': 2846, 'olympia': 2847, '81': 2848, 'coin': 2849, 'craters': 2850, 'sac': 2851, 'takahito': 2852, 'eguchi': 2853, 'polygon': 2854, 'tea-time': 2855, 'latvia': 2856, 'impulso': 2857, 'creativo': 2858, 'echo': 2859, 'over': 2860, 'ghost': 2861, 'crisis:': 2862, 'fantasy': 2863, 'vii': 2864, 'pennsylvania': 2865, 'dissociatives': 2866, 'downtown': 2867, 'phil': 2868, 'stacey': 2869, 'rugrats': 2870, 'farewell': 2871, 'travels': 2872, 'lao': 2873, 'snow': 2874, 'believe': 2875, 'chico': 2876, 'buarque': 2877, '9am': 2878, 'dallas': 2879, 'smart': 2880, 'akhtar': 2881, 'sadmani': 2882, 'knife': 2883, 'dreams': 2884, 'flower': 2885, 'angry': 2886, 'waves': 2887, 'strayhorn': 2888, 'easy': 2889, 'stop': 2890, 'macao': 2891, 'twenty-third': 2892, 'zone': 2893, 'ii:': 2894, 'tears': 2895, 'opa-opa': 2896, 'cry': 2897, 'mis': 2898, 'niños': 2899, '30': 2900, 'behavior': 2901, 'angola': 2902, 'kipp': 2903, 'cheapest': 2904, 'online': 2905, 'instincts': 2906, 'boon': 2907, 'brick': 2908, 'store': 2909, 'grandkid': 2910, 'evans': 2911, 'provide': 2912, 'mars': 2913, 'passion': 2914, 'anchor': 2915, '55': 2916, 'brother': 2917, 'pugu': 2918, 'hills': 2919, 'cuckoo': 2920, 'clocks': 2921, 'namibia': 2922, 'moby': 2923, 'grape': 2924, 'enamorándose': 2925, 'portugal': 2926, 'thacker': 2927, 'donald': 2928, 'rubinstein': 2929, 'austria': 2930, 'eyes:': 2931, 'beginning': 2932, 'fernandina': 2933, 'claude': 2934, 'vonstroke': 2935, 'hamburger': 2936, 'wagon': 2937, 'reed': 2938, 'commons': 2939, 'pekin': 2940, 'hampshire': 2941, 'cohocton': 2942, 'feel': 2943, 'cove': 2944, 'entry': 2945, 'beau': 2946, 'sapin': 2947, 'lela': 2948, 'libre': 2949, 'hagerman': 2950, 'wuill': 2951, 'dickson': 2952, 'illinois': 2953, 'suriname': 2954, 'bilingualism': 2955, 'amusements': 2956, 'hit': 2957, 'funky': 2958, 'bluesy': 2959, 'uncommon': 2960, 'grounds': 2961, 'therapy': 2962, 'print': 2963, 't-rex': 2964, 'halsey': 2965, 'az': 2966, 'burrows': 2967, 'abacus': 2968, 'calm': 2969, 'vibes': 2970, 'galena': 2971, 'ticket': 2972, 'souvenirs': 2973, 'puthri': 2974, 'hank': 2975, 'shermann': 2976, 'hier': 2977, 'encore': 2978, 'greydon': 2979, 'square': 2980, 'watchman': 2981, 'vadivel': 2982, 'humid': 2983, 'helix': 2984, 'oldies': 2985, 'radhae': 2986, 'unakku': 2987, 'kobam': 2988, 'aagathadi': 2989, 'cuisine': 2990, 'shari': 2991, 'british': 2992, 'office': 2993, 'enter': 2994, 'agreable': 2995, 'teaching': 2996, 'cowboy': 2997, 'funny': 2998, 'football': 2999, 'frizzell': 3000, 'german': 3001, 'chocolate': 3002, 'cake': 3003, 'ecru': 3004, 'loyola': 3005, 'kin': 3006, 'acid': 3007, 'harris': 3008, 'cycle': 3009, 'needham': 3010, 'nick': 3011, 'hexum': 3012, 'singer': 3013, 'damon': 3014, 'african': 3015, 'playlists': 3016, 'lyncourt': 3017, 'royal': 3018, 'astronomy': 3019, 'moosic': 3020, 'van': 3021, 'dyke': 3022, '14': 3023, 'crofton': 3024, 'ukraine': 3025, 'hello': 3026, 'goodbye': 3027, 'century': 3028, 'myrtle': 3029, 'av': 3030, 'crisis': 3031, 'vezione': 3032, 'verro': 3033, 'livonia': 3034, 'dearest': 3035, 'colour': 3036, 'chameleon': 3037, 'zealand': 3038, '119': 3039, 'perchance': 3040, 'dream': 3041, 'channel': 3042, 'roxbox': 3043, 'yesterday': 3044, 'train': 3045, 'ride': 3046, 'app': 3047, 'top-twenty': 3048, '2015': 3049, 'so': 3050, 'self': 3051, 'tyranny': 3052, 'willy': 3053, 'mason': 3054, 'john': 3055, 'clayton': 3056, 'barker': 3057, '1978': 3058, 'ambient': 3059, 'collection': 3060, '3/22/2038': 3061, 'pierre': 3062, 'miquelon': 3063, 'wenham': 3064, 'pineridge': 3065, 'kyrgyzstan': 3066, '1958': 3067, 'wayne': 3068, 'petti': 3069, 'matrix': 3070, 'lighter': 3071, 'pamela': 3072, 'jintana': 3073, 'racine': 3074, 'sveta': 3075, 'ljubav': 3076, '2011': 3077, 'dan': 3078, 'healy': 3079, 'mayotte': 3080, '06:13': 3081, 'marino': 3082, 'town': 3083, 'uses': 3084, 'oregon': 3085, 'toys': 3086, 'ledoux': 3087, 'games': 3088, 'wizards': 3089, 'bloom:': 3090, 'mickdeth': 3091, 'walter': 3092, 'pilar': 3093, 'réunion': 3094, 'sirivantha': 3095, 'cleo': 3096, 'mysterious': 3097, 'castle': 3098, 'carpathians': 3099, 'lonely': 3100, 'hearts': 3101, 'lucerne': 3102, 'nugget': 3103, 'conception': 3104, 'mercy': 3105, 'pass': 3106, 'toi': 3107, 'perfection': 3108, '������': 3109, 'bernardsville': 3110, 'folly': 3111, 'mailman': 3112, 'twerkout': 3113, 'suffer': 3114, 'shockscape': 3115, 'javine': 3116, 'hylton': 3117, 'hridaynath': 3118, 'plya': 3119, 'kancherla': 3120, 'gopanna': 3121, 'angelo': 3122, 'amorevoli': 3123, 'carmen': 3124, 'mcrae': 3125, 'ed': 3126, 'robertson': 3127, 'steps': 3128, 'leche': 3129, 'con': 3130, 'bien': 3131, 'acompañado': 3132, '60s': 3133, 'ignacio': 3134, 'figueredo': 3135, 'electronow': 3136, 'czech': 3137, 'lewis': 3138, 'debtors': 3139, 'keltech': 3140, 'wallsburg': 3141, 'michele': 3142, 'diann': 3143, 'pam': 3144, 'reno': 3145, 'javanese': 3146, 'maltio': 3147, 'strict': 3148, 'covenant': 3149, 'tartinery': 3150, 'michael': 3151, 'batio': 3152, 'freddy': 3153, 'fender': 3154, 'boden': 3155, 'philosophic': 3156, 'thought': 3157, 'ayn': 3158, 'rand': 3159, 'sofia': 3160, 'phillips': 3161, 'winifred': 3162, 'dine': 3163, 'mughlai': 3164, '1st': 3165, 'ashes': 3166, 'sirusho': 3167, 'clásicos': 3168, 'korra': 3169, 'itv': 3170, 'w': 3171, 't': 3172, 'h': 3173, 'bum': 3174, 'note': 3175, 'bead': 3176, 'sweat': 3177, 'relief': 3178, '2036': 3179, 'ply': 3180, 'anatomy': 3181, 'typeface': 3182, 'beni': 3183, 'arashiro': 3184, 'opera': 3185, 'tortured': 3186, 'rogue': 3187, 'ship': 3188, 'caveman': 3189, 'made': 3190, 'masonville': 3191, 'vermont': 3192, 'timor': 3193, 'chandler': 3194, 'iris': 3195, 'dement': 3196, 'selena': 3197, 'seventh': 3198, 'crystal': 3199, 'lawns': 3200, 'guam': 3201, 'playlist:': 3202, 'brad': 3203, 'paisley': 3204, 'humidity': 3205, 'serbia': 3206, 'donkey': 3207, 'kuwait': 3208, 'finds': 3209, 'hiptronix': 3210, 'charenton': 3211, 'glenarden': 3212, 'darkworld': 3213, 'detective': 3214, 'accommodate': 3215, 'gretchen': 3216, 'trisha': 3217, 'dish': 3218, 'becoming': 3219, 'royston': 3220, 'kristine': 3221, 'alisha': 3222, 'florine': 3223, 'forecasted': 3224, 'ninaview': 3225, 'sex': 3226, 'isle': 3227, 'culture': 3228, 'psychology': 3229, 'nest': 3230, 'um': 3231, 'coco': 3232, 'e': 3233, 'adeus': 3234, 'williams': 3235, 'reserved': 3236, 'burgers': 3237, 'gasport': 3238, 'sheri': 3239, 'class': 3240, 'cincinnati': 3241, 'harrison': 3242, 'childs': 3243, 'restaurants': 3244, 'bruno': 3245, '6th': 3246, '2019': 3247, 'glazier': 3248, 'afterwork': 3249, 'id': 3250, 'lidia': 3251, 'latasha': 3252, 'bone': 3253, 'crusher': 3254, 'central': 3255, 'grocery': 3256, 'say': 3257, 'ain’t': 3258, 'teenager': 3259, 'lords': 3260, 'cup': 3261, 'winner': 3262, 'nothing': 3263, 'lasts': 3264, 'coats': 3265, 'knockabout': 3266, 'eva': 3267, 'shed': 3268, '4/3/2027': 3269, 'rochelle': 3270, 'meeting': 3271, 'sia': 3272, 'furler': 3273, 'terrible': 3274, 'vengeance': 3275, 'hurricane': 3276, 'hampartsoum': 3277, 'limondjian': 3278, 'hora': 3279, 'din': 3280, 'yamazaki': 3281, 'maso': 3282, 'friendesemana': 3283, 'berryessa': 3284, 'unraveling': 3285, 'marina': 3286, 'welcome': 3287, 'tokyo': 3288, 'abyss': 3289, 'wonders': 3290, 'donaldson': 3291, 'nurture': 3292, 'pastwatch:': 3293, 'christopher': 3294, 'columbus': 3295, 'sammy': 3296, 'fain': 3297, 'pat': 3298, 'margaret': 3299, 'indicate': 3300, 'aurora': 3301, 'milagros': 3302, 'pocono': 3303, 'tremont': 3304, 'nadine': 3305, 'sherrie': 3306, '3/21/2018': 3307, '02:55:25': 3308, 'crazy=genius': 3309, 'alchemist': 3310, 'tullytown': 3311, 'constructs': 3312, 'juliana': 3313, '2nd': 3314, 'caleigh': 3315, 'peters': 3316, 'skies': 3317, '9th': 3318, 'jams': 3319, 'série': 3320, 'filmes': 3321, 'hobbit': 3322, 'alex': 3323, 'otaola': 3324, 'robbie': 3325, 'dear': 3326, 'blighty': 3327, 'sabah': 3328, 'shinya': 3329, 'yamada': 3330, '1962': 3331, 'lesotho': 3332, 'kirtley': 3333, 'covered': 3334, 'toad': 3335, 'gisela': 3336, 'monty’s': 3337, 'secunderabad': 3338, 'doe': 3339, 'scales': 3340, 'justice': 3341, 'milton-freewater': 3342, 'gamble': 3343, 'rogers': 3344, 'vichyssoise': 3345, 'already': 3346, 'pt': 3347, 'critic': 3348, 'sons': 3349, 'fires': 3350, 'azeroth': 3351, 'villa': 3352, 'inferno': 3353, 'between': 3354, 'del': 3355, 'españa': 3356, 'melcher-dallas': 3357, 'lu': 3358, 'bing': 3359, 'fusion': 3360, 'fest': 3361, 'vipers': 3362, 'dombey': 3363, 'submarine': 3364, 'caper': 3365, 'fairview': 3366, '9/3/2034': 3367, 'bridle': 3368, 'trails': 3369, 'glorious': 3370, 'die': 3371, 'åland': 3372, 'scoundrels': 3373, 'vue': 3374, 'tooh': 3375, 'eric': 3376, 'bazilian': 3377, 'netherlands': 3378, 'antilles': 3379, 'flats': 3380, 'april': 3381, 'railway': 3382, 'children': 3383, 'riddlesburg': 3384, 'bajo': 3385, 'las': 3386, 'estrellas': 3387, 'eighteen': 3388, 'sichuan': 3389, 'spyforce': 3390, 'cheat': 3391, 'fair:': 3392, 'maxwell': 3393, '2002': 3394, 'impractical': 3395, 'jokers': 3396, 'uk': 3397, 'casey': 3398, 'chavez': 3399, 'lucinda': 3400, 'aion': 3401, 'chaparral': 3402, 'stano': 3403, 'framed': 3404, 'ntc': 3405, 'studio': 3406, 'elbridge': 3407, 'bryant': 3408, 'inyección': 3409, 'musical': 3410, 'cooler': 3411, 'climate': 3412, 'solomon': 3413, 'then': 3414, 'came': 3415, 'congress': 3416, 'rambow': 3417, 'grisham': 3418, 'xsuie': 3419, 'olivet': 3420, 'anymore': 3421, 'suns': 3422, 'berghoff': 3423, 'sistersville': 3424, 'half-life': 3425, 'sierra': 3426, 'blanca': 3427, 'helen': 3428, 'ward': 3429, 'matrimony': 3430, 'accion': 3431, 'newspaper': 3432, 'trabajo': 3433, 'sep': 3434, '14th': 3435, 'pablo': 3436, 'gazer': 3437, 'r': 3438, 'rotem': 3439, 'singers': 3440, 'hardcastle': 3441, 'clear': 3442, 'whole': 3443, 'discipline': 3444, 'pulsions': 3445, 'guy-manuel': 3446, 'homem-christo': 3447, 'cynthia': 3448, 'crooked': 3449, 'windsor': 3450, 'angela': 3451, 'mercedes': 3452, 'cimarron': 3453, 'ballylickey': 3454, '7/16/2027': 3455, 'luck': 3456, '1967': 3457, 'entitled': 3458, 'i’ll': 3459, 'care': 3460, 'belinda': 3461, 'dena': 3462, 'close-by': 3463, 'syria': 3464, 'cleveland': 3465, 'round': 3466, 'gena': 3467, 'od': 3468, 'mene': 3469, 'se': 3470, 'odvikavaj': 3471, 'rakuen': 3472, 'tsuihou:': 3473, 'expelled': 3474, 'tubby': 3475, 'antero': 3476, 'manninen': 3477, 'dancefloor': 3478, 'expressive': 3479, 'processing': 3480, 'send': 3481, 'ann': 3482, 'lists': 3483, 'sir': 3484, 'winston': 3485, 'ono': 3486, 'lennon': 3487, 'her': 3488, 'mallett': 3489, 'tajikistan': 3490, 'wise': 3491, 'cafagna': 3492, 'tesoro': 3493, 'reggae': 3494, 'en': 3495, 'español': 3496, 'fujimoto': 3497, 'yae': 3498, 'suites': 3499, 'sweets': 3500, 'mf': 3501, 'doom': 3502, 'lea': 3503, 'generation': 3504, 'edm': 3505, 'thousand': 3506, 'dressing': 3507, 'ivory': 3508, 'coast': 3509, 'cambodia': 3510, '05:44:13': 3511, 'chapter': 3512, 'odessa': 3513, 'sure': 3514, 'ga': 3515, 'urmston': 3516, 'shinoda': 3517, 'seaman': 3518, 'opening': 3519, 'dicey': 3520, 'business': 3521, 'meze': 3522, 'situation': 3523, 'wide-eyed': 3524, 'ignorant': 3525, 'hanging': 3526, 'relaxing': 3527, 'madge': 3528, 'tami': 3529, 'sterling': 3530, 'divan': 3531, 'breasts': 3532, 'hips': 3533, 'driven': 3534, 'viral': 3535, 'semanal': 3536, 'fell': 3537, 'fallen': 3538, 'meast': 3539, 'sacred': 3540, 'caretaker': 3541, 'economics': 3542, 'sociology': 3543, 'carencro': 3544, 'closet': 3545, 'frank': 3546, 'portman': 3547, 'airto': 3548, 'moreira': 3549, 'rogues': 3550, 'interview:': 3551, 'documentary': 3552, 'lego': 3553, 'alte': 3554, 'kameraden': 3555, 'darkest': 3556, 'jennifer': 3557, 'lopez': 3558, '1957': 3559, 'screened': 3560, 'caribbean': 3561, 'racionais': 3562, 'mc': 3563, '10th': 3564, '2028': 3565, 'mating': 3566, 'lepond': 3567, 'bliss': 3568, 'harvey': 3569, 'resturant': 3570, 'mariem': 3571, 'hassan': 3572, 'leyoad': 3573, 'unreachable': 3574, 'wine': 3575, 'poems': 3576, 'tanque': 3577, 'awful': 3578, 'irish': 3579, 'bake': 3580, 'grandparents': 3581, 'helens': 3582, 'torch': 3583, 'build': 3584, 'engine': 3585, '1996': 3586, '1981': 3587, 'boaz': 3588, 'mauda': 3589, 'laarni': 3590, 'lozada': 3591, 'phera': 3592, 'vodka': 3593, 'kunal': 3594, 'ganjawala': 3595, 'le': 3596, 'profil': 3597, 'amina': 3598, 'carmella': 3599, '12:53': 3600, 'parc': 3601, 'kettle': 3602, 'thirteenth': 3603, '7even': 3604, '24': 3605, 'floor': 3606, 'rumba': 3607, 'más': 3608, 'renee': 3609, 'sanders': 3610, 'marlene': 3611, 'jewel': 3612, '13': 3613, 'july': 3614, 'dachigam-nationalpark': 3615, 'lono': 3616, 'natsu': 3617, 'mini': 3618, 'berryz': 3619, '02:22': 3620, 'abdel': 3621, 'halim': 3622, 'hafez': 3623, 'adelaide': 3624, 'restaurantin': 3625, 'perrytown': 3626, 'candice': 3627, 'jeannie': 3628, 'nichole': 3629, 'elba': 3630, 'corina': 3631, 'tron:': 3632, 'legacy': 3633, 'reconfigured': 3634, 'balkan': 3635, 'rhapsodies:': 3636, '78': 3637, 'measures': 3638, 'malco': 3639, 'intimate': 3640, 'bunny': 3641, 'ennis': 3642, 'screwed': 3643, 'quantum': 3644, 'thief': 3645, 'annunzio': 3646, 'paolo': 3647, 'mantovani': 3648, 'sentenced': 3649, 'prism': 3650, 'powers': 3651, 'izquierdo': 3652, 'status': 3653, 'quo': 3654, 'robb': 3655, 'scorpion': 3656, 'write': 3657, 'cavour': 3658, 'sri': 3659, 'lanka': 3660, 'dumplings': 3661, 'lift': 3662, 'dynasties': 3663, 'rhythmic': 3664, 'clubbing:': 3665, 'field': 3666, 'romantic': 3667, 'mexican': 3668, 'woodcliff': 3669, 'chorus': 3670, 'line': 3671, 'bunce': 3672, 'curacao': 3673, 'nerding': 3674, 'annet': 3675, 'artani': 3676, 'operation': 3677, 'thunderbolt': 3678, 'create': 3679, 'station': 3680, 'creeggan': 3681, 'records': 3682, 'collabs': 3683, 'winwood': 3684, '2037': 3685, 'hesston': 3686, 'enid': 3687, 'romántica': 3688, 'hamish': 3689, 'maccunn': 3690, 'enemies': 3691, 'marche': 3692, 'hostel': 3693, '2006': 3694, 'primavera': 3695, 'barcelona': 3696, 'darling': 3697, 'each': 3698, 'tailspin': 3699, 'air': 3700, '1998': 3701, 'frontalot': 3702, 'alan': 3703, 'sawtooth': 3704, 'recreation': 3705, 'druid': 3706, 'connee': 3707, 'boswell': 3708, 'ozma': 3709, 'ahmed': 3710, 'abdul': 3711, 'malik': 3712, 'wallis': 3713, 'futuna': 3714, 'lion': 3715, 'odd': 3716, 'nosdam': 3717, 'breckenridge': 3718, 'furnace': 3719, 'moon': 3720, 'baker': 3721, 'hiphop': 3722, 'defenestration': 3723, 'ermintrude': 3724, 'inch': 3725, 'cameo': 3726, 'souls': 3727, 'sparrow': 3728, 'maunabo': 3729, 'wayning': 3730, 'rabbit': 3731, 'brown': 3732, 'marilyn': 3733, 'carnik': 3734, 'stage': 3735, 'martinique': 3736, 'face': 3737, 'truth': 3738, 'portage': 3739, 'chin': 3740, '17:32:30': 3741, 'choice': 3742, 'shawn': 3743, 'soulful': 3744, 'tropical': 3745, 'sign': 3746, 'sparro': 3747, 'traffic': 3748, 'policeman': 3749, 'stadium': 3750, 'swordsman': 3751, 'singing': 3752, 'nun': 3753, 'spy': 3754, 'workplace': 3755, 'everywhere': 3756, 'hocus': 3757, 'bogus': 3758, 'swamp': 3759, 'water': 3760, 'suit': 3761, 'ler': 3762, 'lalonde': 3763, 'raleigh': 3764, 'kentucky': 3765, 'texas': 3766, 'secret': 3767, 'digging': 3768, '300:': 3769, 'sontha': 3770, 'ooru': 3771, 'aaron': 3772, 'lilacs': 3773, 'larry': 3774, 'gatlin': 3775, 'dirt': 3776, 'farmer': 3777, 'williams:': 3778, 'rocko': 3779, '10/24/2028': 3780, 'lauren': 3781, 'fondo': 3782, 'buio': 3783, 'sonntag': 3784, 'assassin': 3785, 'creed': 3786, 'socrates': 3787, 'allenton': 3788, 'croix': 3789, 'glittering': 3790, 'plain': 3791, 'chae': 3792, 'yeon': 3793, 'shaggy': 3794, 'brunswick': 3795, 'township': 3796, 'teo': 3797, 'macero': 3798, 'jun': 3799, '2032': 3800, 'dillard': 3801, 'putnam': 3802, 'wontons': 3803, 'leopold': 3804, 'sivamani': 3805, 'alain': 3806, 'caron': 3807, 'alla': 3808, 'pougatcheva': 3809, 'osmanthus': 3810, 'aflame': 3811, 'ribbon': 3812, 'krystal': 3813, 'cavalero': 3814, 'montenegro': 3815, 'statue': 3816, 'granite': 3817, 'killarney': 3818, 'pow/mia': 3819, 'recognition': 3820, 'writing': 3821, 'hearth': 3822, 'gravity': 3823, 'past': 3824, 'falco': 3825, 'clifton': 3826, 'ramy': 3827, 'ayach': 3828, 'league': 3829, 'tribute': 3830, 'cox': 3831, 'bennie': 3832, 'moten': 3833, 'maia': 3834, 'hirasawa': 3835, 'i’m': 3836, 'cyborg': 3837, 'but': 3838, 'that’s': 3839, 'gay': 3840, 'ramos': 3841, 'janice': 3842, 'gonzales': 3843, 'timbo': 3844, 'shenandoah': 3845, 'kuo': 3846, 'agent': 3847, 'hamilton:': 3848, 'concerns': 3849, 'hide': 3850, 'buffy': 3851, 'matters': 3852, 'straight': 3853, 'shooter': 3854, 'claudine': 3855, 'longet': 3856, 'palylist': 3857, 'martine': 3858, 'mccutcheon': 3859, 'original': 3860, 'jazzmasters': 3861, 'preferably': 3862, 'ritchey': 3863, 'reyna': 3864, 'maxine': 3865, 'monday': 3866, 'fonsi': 3867, 'tenth': 3868, 'nosh': 3869, 'healthy': 3870, 'sankertown': 3871, 'infusions': 3872, 'cream-trilogie': 3873, 'cenizo': 3874, 'minority': 3875, 'report': 3876, '23rd': 3877, 'norfolk': 3878, 'robinson': 3879, 'shoe': 3880, 'bonaire': 3881, 'orienta': 3882, 'phinizy': 3883, 'expect': 3884, 'bow': 3885, 'tie': 3886, 'barry': 3887, 'manilow': 3888, 'prince': 3889, 'howards': 3890, 'kool': 3891, 'keith': 3892, 'fillmore': 3893, '01:27': 3894, 'ludden': 3895, 'sonata': 3896, 'cruel': 3897, 'brunei': 3898, 'professional': 3899, 'roberto': 3900, 'carlos': 3901, 'braga': 3902, 'darude': 3903, '11:56': 3904, 'campus': 3905, 'shooby': 3906, 'tearing': 3907, 'charts': 3908, 'insult': 3909, 'injury': 3910, 'narayana': 3911, 'tirtha': 3912, '8th': 3913, 'australian': 3914, 'eclectic': 3915, 'batman:': 3916, 'return': 3917, 'woodmere': 3918, 'scrapple': 3919, 'harriett': 3920, 'deanne': 3921, 'reggaeton': 3922, 'baila': 3923, 'municipal': 3924, 'mitcham': 3925, 'silly': 3926, 'metalblood': 3927, 'chase': 3928, 'cause': 3929, 'effect': 3930, 'programming': 3931, 'keep': 3932, 'heads': 3933, 'ringin’': 3934, 'geoff': 3935, 'ryman': 3936, 'bibliography': 3937, 'monster': 3938, 'peace': 3939, 'cham': 3940, 'happiest': 3941, 'lives': 3942, 'emmanuel': 3943, 'flint': 3944, 'tony': 3945, 'rombola': 3946, 'ulterior': 3947, 'motive': 3948, 'oleg': 3949, 'anofriyev': 3950, 'feast': 3951, 'faint': 3952, 'bautista': 3953, 'woodport': 3954, 'mt': 3955, 'electrosafari': 3956, 'joseph': 3957, 'andrews': 3958, 'nona': 3959, 'gray': 3960, 'alison': 3961, 'ouzeri': 3962, 'strasburg': 3963, '10:41:51': 3964, 'every': 3965, 'heartache': 3966, 'abbott': 3967, 'sonu': 3968, 'niigaam': 3969, 'encyclopaedia': 3970, 'social': 3971, 'sciences': 3972, 'kentaro': 3973, 'karol:': 3974, 'pope': 3975, 'grace': 3976, 'phase': 3977, 'jara': 3978, 'bradbury': 3979, 'jona': 3980, 'bechtolt': 3981, 'elliotts': 3982, 'boo': 3983, 'winnie': 3984, 'pooh': 3985, 'accident': 3986, 'analysis': 3987, 'prevention': 3988, 'entity': 3989, 'por': 3990, 'una': 3991, 'cabeza': 3992, 'alone': 3993, 'decides': 3994, 'palying': 3995, 'nijinsky': 3996, 'plague': 3997, 'ruel': 3998, 'manufacturing': 3999, 'consent': 4000, 'apache': 4001, 'also': 4002, 'hardcore': 4003, 'olga': 4004, 'souza': 4005, 'femme': 4006, 'fatale': 4007, 'twitches': 4008, 'dickey': 4009, 'betts': 4010, 'thursday': 4011, 'miami': 4012, 'rodney': 4013, 'whitaker': 4014, 'riley': 4015, 'kaltag': 4016, 'pesotum': 4017, 'steele': 4018, 'vladimir': 4019, 'vysotski': 4020, 'faces': 4021, 'rio': 4022, 'grande': 4023, 'scenic': 4024, 'cairngorms-nationalpark': 4025, 'bonobo': 4026, 'innocence': 4027, 'contemporary': 4028, 'religious': 4029, 'satanism': 4030, 'careful': 4031, 'hate': 4032, 'masquerade': 4033, 'mel': 4034, 'draisey': 4035, 'belgian': 4036, 'macclenny': 4037, 'smelt': 4038, 'fried': 4039, 'mccoll': 4040, 'missing': 4041, 'japanese': 4042, 'lovesong': 4043, 'electronica': 4044, 'tourist': 4045, 'israel': 4046, 'golden': 4047, 'sandie': 4048, 'shaw': 4049, 'according': 4050, 'vertexguy': 4051, 'taskcracker': 4052, 'outlook': 4053, 'vaughn': 4054, 'salt': 4055, 'period': 4056, 'orson': 4057, 'malaysian': 4058, 'nattbuss': 4059, '807': 4060, 'hawaiian': 4061, 'nd': 4062, 'mascotte': 4063, 'jane': 4064, 'olivor': 4065, 'machine': 4066, 'waterscapes': 4067, 'aprite': 4068, 'finestre': 4069, 'marta': 4070, 'pesterminator:': 4071, 'western': 4072, 'exterminator': 4073, 'bellwood': 4074, 'spasmolytic': 4075, 'burkina': 4076, 'shavuot': 4077, 'moneta': 4078, 'invitation': 4079, 'waltz': 4080, 'mezzes': 4081, 'science': 4082, 'fiction': 4083, 'deer': 4084, 'padangnese': 4085, 'memoirs': 4086, 'fox-hunting': 4087, 'megaplex': 4088, 'penthouse': 4089, 'groundhog': 4090, 'slovenia': 4091, 'tschaikovsky': 4092, 'pioneers': 4093, 'landing': 4094, 'low': 4095, 'tide': 4096, 'seven-ups': 4097, 'horror': 4098, 'icac': 4099, 'investigators': 4100, 'guitar': 4101, 'gothic': 4102, 'exploring': 4103, 'reef': 4104, 'rob': 4105, 'campanella': 4106, 'unpleasantness': 4107, 'bellona': 4108, 'sold': 4109, 'dick': 4110, 'tracy': 4111, 'gas': 4112, 'misterioso': 4113, 'sandwich': 4114, 'ethridge': 4115, 'fiji': 4116, 'jimmy': 4117, 'two-shoes': 4118, 'reaches': 4119, 'best-of:': 4120, 'design': 4121, 'decade': 4122, '2003–2013': 4123, 'paula': 4124, 'campbell': 4125, 'a-z': 4126, 'guide': 4127, 'arranged': 4128, 'marriage': 4129, 'jocque': 4130, 'scriptures': 4131, 'eternity': 4132, 'preminchi': 4133, 'choodu': 4134, 'pinson': 4135, 'festival': 4136, 'eden': 4137, 'carne': 4138, 'pizzaiola': 4139, 'tamra': 4140, 'davis': 4141, 'dorothea': 4142, 'califon': 4143, 'tunisia': 4144, 'allan': 4145, 'michigantown': 4146, 'ks': 4147, 'corey': 4148, 'met': 4149, 'alejandro': 4150, 'fernández': 4151, 'noroi': 4152, 'curse': 4153, 'ajinoam': 4154, 'nini': 4155, 'frescura': 4156, 'nooks': 4157, 'throats': 4158, 'beckon': 4159, 'thaw': 4160, 'idaho': 4161, 'guanica': 4162, 'diamondville': 4163, 'niagara': 4164, 'murray': 4165, 'laughs': 4166, 'kaffir': 4167, '17th': 4168, 'sometimes': 4169, 'passing': 4170, 'dungeons': 4171, 'dragons:': 4172, 'mystara': 4173, 'jersey': 4174, 'ragged': 4175, 'curtain': 4176, 'decades': 4177, 'surprise': 4178, 'ladies': 4179, 'diplomat': 4180, 'secrets': 4181, 'alibi': 4182, 'molise': 4183, 'sohl': 4184, 'upbuilding': 4185, 'discourses': 4186, '1844': 4187, 'beaver': 4188, 'finding': 4189, 'chandra': 4190, 'testing': 4191, 'pocahontas': 4192, 'farnham': 4193, 'singles': 4194, 'oxford': 4195, 'known': 4196, 'bb': 4197, 'boyertown': 4198, 'timeless': 4199, 'bahamas': 4200, 'belle': 4201, 'yukon': 4202, 'pray': 4203, 'escondida': 4204, 'lampi': 4205, 'marine': 4206, 'conway': 4207, 'twitty': 4208, 'tchaikovsky': 4209, 'hou': 4210, 'jou': 4211, 'elena': 4212, 'temnikova': 4213, 'mozart': 4214, 'nana': 4215, 'mizuki': 4216, 'fighter': 4217, '-blue': 4218, 'side-': 4219, 'moved': 4220, 'cheese': 4221, 'freed': 4222, 'totowa': 4223, 'zambia': 4224, 'village': 4225, 'amityville': 4226, 'rats': 4227, 'hamelin': 4228, 'flex': 4229, 'tamagotchi': 4230, '64:': 4231, 'minna': 4232, 'in-birth': 4233, 'roseville': 4234, 'fl': 4235, 'meredith': 4236, 'louisa': 4237, 'corrine': 4238, 'skin': 4239, 'jess': 4240, 'stacy': 4241, 'maharashtrian': 4242, 'education:': 4243, 'experience': 4244, 'tarass': 4245, 'boulba': 4246, '1966': 4247, 'ren': 4248, 'valy': 4249, '1972': 4250, 'temple': 4251, 'gayle': 4252, 'apart': 4253, 'sanilac': 4254, 'petroglyphs': 4255, 'bahar': 4256, 'kizil': 4257, 'durbin': 4258, 'juju': 4259, 'mob': 4260, 'eucalyptus': 4261, '8/26/2022': 4262, 'oswego': 4263, 'fresh:': 4264, 'terror': 4265, 'airi': 4266, 'suzuki': 4267, 'blast': 4268, 'novelties': 4269, '1986': 4270, 'potato': 4271, 'salad': 4272, 'alabama': 4273, 'anti': 4274, 'grim': 4275, 'skunk': 4276, 'incomplete': 4277, 'trust': 4278, 'worship': 4279, 'moen': 4280, 're:': 4281, 'hamatora': 4282, 'episodes': 4283, 'shit': 4284, 'connie': 4285, 'earline': 4286, 'bacon': 4287, 'beauregard': 4288, 'edit': 4289, 'aux': 4290, 'cord': 4291, 'privileges': 4292, 'putting': 4293, 'cobain': 4294, 'harkins': 4295, 'eather': 4296, 'vegan': 4297, 'kailash': 4298, 'kher': 4299, 'croatan': 4300, 'afghanistan': 4301, 'carterville': 4302, 'diamond': 4303, 'executive': 4304, 'werner': 4305, 'ape-man': 4306, 'adding': 4307, 'smokefree': 4308, 'rockquest': 4309, 'goiano': 4310, 'springs': 4311, 'trinidad': 4312, 'tobago': 4313, 'pump': 4314, 'chicago': 4315, 'k': 4316, 'yesudas': 4317, 'windhorst': 4318, 'logic': 4319, 'sense': 4320, 'hand': 4321, 'head': 4322, 'berkley': 4323, 'apple': 4324, 'butter': 4325, 'bear': 4326, 'finsbury': 4327, 'woodchuck': 4328, 'chuck': 4329, 'craig': 4330, 'terrorists:': 4331, 'convicted': 4332, 'ghader': 4333, 'abdollahzadeh': 4334, 'waiting': 4335, 'havana': 4336, 'lorain': 4337, 'atticus': 4338, 'ross': 4339, 'miriam': 4340, 'hammer': 4341, 'lunch': 4342, 'press': 4343, 'atlantic': 4344, 'geriatric': 4345, 'psychiatry': 4346, 'neurology': 4347, 'boston': 4348, 'llegando': 4349, 'casa': 4350, 'temperature': 4351, 'sahara': 4352, 'nigeria': 4353, 'ut': 4354, 'jovanotti': 4355, 'rolls': 4356, '1979': 4357, 'ecology:': 4358, 'individuals': 4359, 'ecosystems': 4360, 'eighteenth': 4361, 'z': 4362, 'cars': 4363, 'mellor': 4364, 'entertaining': 4365, 'isaac': 4366, 'hayes': 4367, 'beer': 4368, 'rocks': 4369, '03:43': 4370, 'tianjin': 4371, 'news': 4372, 'yo': 4373, 'ho': 4374, 'pops': 4375, 'deloris': 4376, 'ester': 4377, 'petra': 4378, 'alvarez': 4379, 'brenda': 4380, 'kahn': 4381, 'rushall': 4382, 'gettysburg': 4383, 'duett': 4384, 'waffles': 4385, 'connor': 4386, 'satisfied': 4387, 'rockin': 4388, 'oldfield': 4389, 'para': 4390, 'tus': 4391, 'fiestas': 4392, 'sugarolly': 4393, 'tarte': 4394, 'tanisha': 4395, 'lorena': 4396, 'rupam': 4397, 'islam': 4398, '100%': 4399, 'te': 4400, 'ljubam': 4401, 'platnum': 4402, 'weathr': 4403, 'akin': 4404, 'jamaica': 4405, 'loup': 4406, 'tyrant': 4407, 'fleischmanns': 4408, '43': 4409, 'mogis': 4410, 'crate': 4411, 'diggers': 4412, 'anonymous': 4413, 'labor': 4414, 'notes': 4415, 'hound': 4416, 'dog': 4417, 'freak': 4418, 'incense': 4419, 'tarkan': 4420, 'madrugando': 4421, 'annunciation': 4422, 'draper': 4423, 'composer': 4424, 'weekly': 4425, 'pauline': 4426, 'oliveros': 4427, 'stomp': 4428, 'holler': 4429, 'memories': 4430, 'ford': 4431, 'administration': 4432, 'wenn': 4433, 'lucy': 4434, 'springt': 4435, 'vic': 4436, 'ruggiero': 4437, '2007': 4438, 'gaudi': 4439, 'forty': 4440, 'pelican': 4441, 'blandings': 4442, 'extremely': 4443, 'download': 4444, 'hood': 4445, 'diego': 4446, 'canal': 4447, 'fulton': 4448, 'white:': 4449, 'box': 4450, 'elder': 4451, 'catholic': 4452, 'education': 4453, 'boiling': 4454, 'purples': 4455, 'johnston': 4456, 'velvet': 4457, 'run': 4458, 'challenge': 4459, 'mg': 4460, 'visionary': 4461, 'hype': 4462, 'melodious': 4463, 'adrian': 4464, 'steak': 4465, 'alexia': 4466, 'gve': 4467, 'stinky': 4468, 'fairly': 4469, 'stupid': 4470, 'glarus': 4471, 'avantgarde': 4472, 'keren': 4473, 'peles': 4474, 'merle': 4475, 'haggard': 4476, 'presents': 4477, '30th': 4478, 'niko': 4479, 'getaway:': 4480, 'garfunkel': 4481, 'doing': 4482, 'epworth': 4483, 'yankee': 4484, 'doodle': 4485, 'shop': 4486, 'tmpgenc': 4487, 'darker': 4488, 'godslayer': 4489, '11:36:48': 4490, 'wolfenberger': 4491, 'amrithavaahini': 4492, 'top-fifty': 4493, 'ski': 4494, 'sauna': 4495, 'pride': 4496, 'prairie': 4497, 'burke': 4498, 'telemark': 4499, 'frontiers': 4500, 'ecology': 4501, 'environment': 4502, 'armstrong': 4503, 'adrenaline': 4504, 'whistler': 4505, '03:01:48': 4506, '2010s': 4507, 'swaziland': 4508, 'surfer': 4509, 'transformers:': 4510, 'patty': 4511, 'talks': 4512, 'kreator': 4513, 'nação': 4514, 'timerider:': 4515, 'lyle': 4516, 'swann': 4517, 'humour': 4518, 'arizona': 4519, 'italian-american': 4520, 'anarchy': 4521, 'tyresta': 4522, '7/18/2030': 4523, 'pane': 4524, 'wheatley': 4525, 'jil': 4526, 'yakima': 4527, 'observations': 4528, 'putrefactive': 4529, 'infestation': 4530, '10/2/2021': 4531, 'haines': 4532, 'origa': 4533, 'wow': 4534, 'kid': 4535, 'gang': 4536, 'bandits': 4537, 'beard': 4538, 'johan': 4539, 'larsson': 4540, 'travelers': 4541, 'thieves': 4542, 'gene': 4543, 'beroun': 4544, '26': 4545, 'baseball': 4546, 'rainforest': 4547, 'dew': 4548, 'were': 4549, 'had': 4550, 'hair…': 4551, 'they’re': 4552, 'content': 4553, 'wear': 4554, 'brows': 4555, 'shine': 4556, 'hawk': 4557, 'hayden': 4558, 'row': 4559, 'princes': 4560, 'treasure': 4561, 'common': 4562, 'cabin': 4563, 'dres': 4564, 'nefertiti': 4565, 'nile': 4566, 'belles': 4567, 'clements': 4568, 'genola': 4569, 'disorderly': 4570, 'conduct:': 4571, 'patrol': 4572, 'booking': 4573, 'metropolitan': 4574, 'museum': 4575, 'wylliesburg': 4576, 'acapella': 4577, 'concentration': 4578, 'entire': 4579, 'regulate…g': 4580, 'iouri': 4581, 'bachmet': 4582, 'blackberry': 4583, 'akers': 4584, 'faccetta': 4585, 'nera': 4586, 'handel': 4587, '00:17': 4588, '1983': 4589, 'ayaka': 4590, '308': 4591, 'pizzas': 4592, 'brookwood': 4593, 'fifteenth': 4594, 'bailey': 4595, '05:00:34': 4596, 'areas': 4597, 'estelle': 4598, 'maggie': 4599, 'mcgill': 4600, 'intrepid': 4601, 'pittsburgh': 4602, 'slim': 4603, 'gilluly': 4604, 'lobster': 4605, 'newberg': 4606, 'teddy': 4607, 'ruxpin': 4608, 'she:': 4609, 'reverence': 4610, 'aventuras': 4611, 'zachary': 4612, 'betty': 4613, 'erika': 4614, 'fran': 4615, 'building': 4616, 'gwenno': 4617, 'pipette': 4618, 'sexy': 4619, 'paducah': 4620, 'tesh': 4621, 'brokaw': 4622, 'couch': 4623, 'haystack': 4624, 'empanada': 4625, 'ii': 4626, 'schooltool': 4627, '61': 4628, 'fowler': 4629, 'khao': 4630, 'phanom': 4631, 'bencha': 4632, 'wastedagain': 4633, 'fathers': 4634, 'crows': 4635, 'perfecting': 4636, 'loneliness': 4637, 'bach': 4638, 'mcphee': 4639, 'picnic': 4640, 'cambodian': 4641, 'unite': 4642, 'win': 4643, 'lunchbox': 4644, 'heard': 4645, 'jarvis': 4646, 'cocker': 4647, 'philippines': 4648, 'spears': 4649, 'bowman': 4650, 'sanctuary': 4651, 'wabuska': 4652, 'psychopathic': 4653, 'screening': 4654, 'guy': 4655, 'cemil': 4656, 'bey': 4657, 'dutch': 4658, 'ode': 4659, 'angels': 4660, 'foie': 4661, 'gras': 4662, 'ireland': 4663, '02:02:30': 4664, 'fripp': 4665, 'tivington': 4666, 'nott': 4667, 'foreast': 4668, 'ellen': 4669, 'lentil': 4670, 'caribou': 4671, 'epic': 4672, 'downtempo': 4673, 'beats': 4674, 'schuyler': 4675, 'venezuela': 4676, 'wilderville': 4677, 'vybz': 4678, 'kartel': 4679, 'grizzled': 4680, 'squirrel': 4681, 'talking': 4682, 'ebony': 4683, 'yolanda': 4684, 'choptank': 4685, 'specialises': 4686, 'protein': 4687, 'kate': 4688, 'wizardry': 4689, 'cretan': 4690, 'wallington': 4691, 'puglia': 4692, 'jemez': 4693, 'mere': 4694, 'lapsed': 4695, 'moore': 4696, 'unicorn': 4697, 'mouse': 4698, 'noses': 4699, 'stamps': 4700, 'wonder': 4701, 'race': 4702, 'gurram': 4703, 'tequesta': 4704, 'shooting': 4705, 'silvio': 4706, 'sabo': 4707, 'deceive': 4708, 'avant': 4709, 'l’ombre': 4710, 'à': 4711, 'bercy': 4712, 'flame': 4713, 'fuca': 4714, 'sweden': 4715, 'steptoe': 4716, 'battlefield': 4717, 'bettye': 4718, 'kimberley': 4719, 'fanatic': 4720, 'underground': 4721, '006': 4722, 'sydney': 4723, 'democratic': 4724, 'rushton': 4725, 'moreve': 4726, 'nazad': 4727, 'kalino': 4728, 'mome': 4729, 'escapada': 4730, 'swain': 4731, 'rocky': 4732, 'tower': 4733, 'ware': 4734, 'shoals': 4735, 'cubby': 4736, 'luxor': 4737, 'chuckys': 4738, 'bonnie': 4739, 'nokio': 4740, 'tity': 4741, 'bathroom': 4742, 'sixth': 4743, '2024': 4744, 'blanco': 4745, 'gasconade': 4746, 'plaid': 4747, 'retina': 4748, '10:21:20': 4749, 'tolerance': 4750, 'tod': 4751, '1953': 4752, 'kiahsville': 4753, 'bound': 4754, '21:41:08': 4755, 'florewood': 4756, 'jiles': 4757, 'perry': 4758, 'richardson': 4759, 'guinea-bissau': 4760, 'residence': 4761, 'nicoleta': 4762, 'nicola': 4763, 'toms': 4764, 'frybread': 4765, 'huxley': 4766, 'woods': 4767, 'kingsman:': 4768, 'supply': 4769, 'chain': 4770, 'trouble': 4771, 'silvia': 4772, 'hickerson': 4773, 'crossings': 4774, 'garrix': 4775, 'soem': 4776, 'springside': 4777, 'wagner': 4778, 'black-body': 4779, 'discontinuity': 4780, 'signed': 4781, 'xoxo': 4782, 'carnegie': 4783, 'ball': 4784, 'somiedo': 4785, 'barbados': 4786, 'outta': 4787, 'hi': 4788, 'coney': 4789, 'chapel': 4790, 'tyrolean': 4791, 'crocker': 4792, 'chanson': 4793, 'hicks': 4794, 'saison': 4795, 'kiribati': 4796, 'sinfonía': 4797, 'hipster': 4798, 'piece': 4799, 'orchestra': 4800, 'cello': 4801, 'colors': 4802, 'santikos': 4803, 'frisbee:': 4804, 'hippie': 4805, 'preacher': 4806, 'lease': 4807, 'sand': 4808, 'captain': 4809, 'dangers': 4810, 'canadian': 4811, 'mounted': 4812, 'comedy': 4813, 'trail': 4814, 'lonesome': 4815, 'pine': 4816, 'chestnut': 4817, 'mare': 4818, 'ely': 4819, 'projections': 4820, '13th': 4821, 'kazakhstan': 4822, 'raney': 4823, 'kudai': 4824, 'twenty-sixth': 4825, 'kane': 4826, '17': 4827, 'teide': 4828, 'werewolf': 4829, 'pedro': 4830, 'navaja': 4831, '1963': 4832, 'mahalaxmi': 4833, 'iyer': 4834, 'fullerville': 4835, 'hornblower': 4836, 'indies': 4837, 'cabinet': 4838, 'statistical': 4839, 'association': 4840, 'temptation': 4841, 'odeon': 4842, 'treatment': 4843, '10/14/2026': 4844, 'stand': 4845, 'coorgs': 4846, 'roseau': 4847, 'infernal': 4848, 'devices': 4849, 'laurie': 4850, 'beechman': 4851, 'utah': 4852, 'kaanapali': 4853, 'curtains': 4854, 'orgánica': 4855, 'harbour': 4856, 'limbo': 4857, 'ooze': 4858, 'carol': 4859, 'wicked': 4860, 'canyon': 4861, 'prayer': 4862, 'cashel': 4863, 'lay': 4864, 'arms': 4865, 'wolcott': 4866, 'htoo': 4867, 'ein': 4868, 'thin': 4869, 'comics': 4870, 'taiwan': 4871, 'woodruff': 4872, 'walls': 4873, 'yummy': 4874, 'bingham': 4875, 'rosemary': 4876, 'holly': 4877, 'brittany': 4878, 'sardinian': 4879, 'co': 4880, 'training': 4881, 'joan': 4882, 'baez': 4883, 'alfred': 4884, 'ending': 4885, 'bonga': 4886, 'sabbath': 4887, 'dio': 4888, 'restaurnt': 4889, 'n9ne': 4890, 'loogootee': 4891, 'rachael': 4892, 'metallica': 4893, 'cobbler': 4894, 'newton': 4895, 'prefereably': 4896, 'religion': 4897, 'dharma': 4898, 'chamillionaire': 4899, 'lina': 4900, 'masala': 4901, 'bossa': 4902, 'nova': 4903, 'samba': 4904, 'jukebox': 4905, 'chile': 4906, 'sugar': 4907, 'adassa': 4908, 'vivian': 4909, 'stanshall': 4910, 'grainola': 4911, 'caught': 4912, 'submerged': 4913, 'terrorism:': 4914, 'preventable': 4915, 'catastrophe': 4916, 'meadowood': 4917, 'tapes': 4918, 'daniel': 4919, 'zueras': 4920, 'lush': 4921, 'cormorant': 4922, 'journals': 4923, 'kebab': 4924, 'johnstown': 4925, 'freud:': 4926, 'moralist': 4927, 'harmar': 4928, 'hardest': 4929, 'predicted': 4930, 'wells': 4931, 'siberian': 4932, 'khatru': 4933, 'cinnaminson': 4934, '06:59': 4935, 'hannah': 4936, 'montana': 4937, 'miley': 4938, 'cyrus:': 4939, 'both': 4940, 'licia': 4941, 'bryan': 4942, 'webb': 4943, 'sidnaw': 4944, 'shot': 4945, 'paint': 4946, 'masterpiece': 4947, 'barbecue': 4948, 'coleslaw': 4949, '19:44:58': 4950, 'justified': 4951, 'update': 4952, 'manhattan': 4953, 'historical': 4954, 'cougar': 4955, 'university': 4956, 'frewen': 4957, 'still': 4958, 'slave': 4959, 'massive': 4960, 'soca': 4961, 'praise': 4962, 'ammunition': 4963, 'pachangueo': 4964, 'haiti': 4965, 'hindert': 4966, '15:02': 4967, 'pinguicula': 4968, 'study': 4969, 'newsletter': 4970, 'honey': 4971, 'hush': 4972, 'claw': 4973, 'range': 4974, 'fabrice': 4975, 'morvan': 4976, 'transcending': 4977, 'siesta': 4978, 'plkay': 4979, 'liberty': 4980, 'rewind': 4981, 'film': 4982, 'manorama': 4983, 'feet': 4984, 'biology': 4985, 'today:': 4986, 'issues': 4987, 'approach': 4988, 'racing': 4989, 'tropic': 4990, 'capricorn': 4991, 'yuauea': 4992, 'faultline': 4993, 'jannie': 4994, 'moonlight': 4995, 'sombrero': 4996, 'fallout:': 4997, 'daimidaler:': 4998, 'vs': 4999, 'penguin': 5000, 'empire': 5001, 'mill': 5002, 'witchcraft': 5003, 'paganism': 5004, 'maid': 5005, 'amsterdam': 5006, '80s': 5007, 'gift': 5008, 'hornersville': 5009, 'eastville': 5010, 'rayvon': 5011, 'stripes': 5012, 'keys': 5013, 'pixley': 5014, 'fashion': 5015, 'simplest': 5016, 'words': 5017, 'ana': 5018, 'sports': 5019, 'medicine': 5020, 'hillary': 5021, 'clinton': 5022, 'letha': 5023, 'heinz': 5024, 'strobl': 5025, 'spoiler': 5026, 'crossett': 5027, 'luxembourg': 5028, 'crash': 5029, 'course': 5030, 'push': 5031, 'button': 5032, 'saori': 5033, 'atsumi': 5034, 'wins': 5035, 'stefon': 5036, 'matthew': 5037, 'helders': 5038, 'showstopper': 5039, 'pearson': 5040, 'soda': 5041, 'works': 5042, '7/27/2036': 5043, 'bedford': 5044, 'blvd-lehman': 5045, 'papeton': 5046, 'rhodes': 5047, 'laverne': 5048, 'rapcaviar': 5049, 'branded': 5050, 'wolseley': 5051, 'wolves': 5052, '1974': 5053, 'tanti': 5054, 'auguri': 5055, 'gilbert': 5056, 'taste': 5057, 'roc': 5058, 'executioner': 5059, 'boris': 5060, 'grebenchtchikov': 5061, 'frantz': 5062, 'carmel': 5063, 'lunchtime': 5064, 'chara': 5065, 'mirrorshades': 5066, 'lambertville': 5067, 'cape': 5068, 'verde': 5069, 'noone': 5070, 'darnell': 5071, 'digital': 5072, 'champ:': 5073, 'boxing': 5074, 'estado': 5075, 'ánimo': 5076, 'microsoft': 5077, 'scanner': 5078, 'lena': 5079, 'horne': 5080, 'refugio': 5081, 'guernsey': 5082, 'salade': 5083, 'banner': 5084, 'mafia:': 5085, 'curtis': 5086, 'enfield': 5087, 'rosie': 5088, 'tatin': 5089, 'wakelin': 5090, 'té': 5091, 'lis': 5092, 'among': 5093, 'apes': 5094, 'michelle': 5095, 'yeoh': 5096, 'fayette': 5097, 'masaki': 5098, 'aiba': 5099, 'danny': 5100, 'carey': 5101, 'roommate': 5102, 'bouvet': 5103, 'til': 5104, 'clinchco': 5105, 'madera': 5106, 'monk': 5107, 'comes': 5108, 'try': 5109, 'blogbridge': 5110, 'furious': 5111, 'cumberland': 5112, 'landmark': 5113, 'trauma': 5114, 'center:': 5115, 'beech': 5116, 'dermatology': 5117, 'tun': 5118, 'shawna': 5119, 'lizzie': 5120, 'burhøns': 5121, 'ernie': 5122, 'sinatra': 5123, 'sings': 5124, 'select': 5125, 'cahn': 5126, 'side': 5127, 'domingo': 5128, 'amanda': 5129, 'kingfisher': 5130, 'preaching': 5131, 'perverted': 5132, 'kleptones': 5133, 'rachelle': 5134, 'mande': 5135, 'studies': 5136, 'wipers': 5137, 'kind': 5138, 'bermuda': 5139, 'scarred': 5140, 'canaich': 5141, 'crowd': 5142, 'corinne': 5143, 'bob': 5144, 'hardy': 5145, 'aria': 5146, 'sync': 5147, 'yoakum': 5148, 'roars': 5149, 'sherlock': 5150, 'holmes': 5151, 'clem': 5152, 'well': 5153, 'remedial': 5154, 'depot': 5155, 'lomax': 5156, 'projectors': 5157, 'loveday': 5158, 'trials': 5159, '02:45': 5160, 'brumley': 5161, 'bobcat': 5162, 'bite': 5163, 'rage': 5164, 'radio': 5165, 'lobby': 5166, 'loyde': 5167, 'pictures': 5168, 'outback': 5169, 'bedroom': 5170, 'party’s': 5171, 'blag': 5172, 'dahlia': 5173, 'andrea': 5174, 'bocelli': 5175, 'skyfall:': 5176, 'motion': 5177, 'turtle': 5178, 'encounters': 5179, 'strongest': 5180, 'instinct': 5181, 'trip-hop': 5182, 'native': 5183, 'clerk': 5184, 'henlopen': 5185, 'acres': 5186, 'diarios': 5187, 'bicicleta': 5188, 'pause': 5189, 'días': 5190, 'frío': 5191, 'siavash': 5192, 'ghomayshi': 5193, 'reager': 5194, 'indocumentado': 5195, 'gaslight': 5196, 'café': 5197, 'marty': 5198, 'friedman': 5199, 'higher': 5200, 'mohammed': 5201, 'abdu': 5202, 'goodland': 5203, 'montreal': 5204, 'morganville': 5205, 'vampires': 5206, 'donuts': 5207, 'gyrls': 5208, 'holla-day': 5209, 'benedict': 5210, 'swords': 5211, 'milas': 5212, 'poli': 5213, 'randy': 5214, 'travis': 5215, 'deep': 5216, 'purdy': 5217, 'maher': 5218, 'moment': 5219, '175': 5220, 'golconda': 5221, 'vt': 5222, 'method': 5223, 'covering:': 5224, 'hidden': 5225, 'rights': 5226, 'farian': 5227, 'showings': 5228, 'innocent': 5229, '2:': 5230, 'guilty': 5231, 'sad': 5232, 'gareth': 5233, 'atop': 5234, 'underwood:': 5235, 'writings': 5236, 'arlene': 5237, 'watsons': 5238, 'beyonders:': 5239, 'artifacts': 5240, 'conrey': 5241, 'madeleine': 5242, 'keisha': 5243, 'clara': 5244, '1950': 5245, '12/13/2025': 5246, 'haugan': 5247, 'lemonade': 5248, 'poetry': 5249, 'hebbronville': 5250, 'encyclopedia': 5251, 'magica': 5252, 'phantom': 5253, 'horse': 5254, 'drifting': 5255, 'count': 5256, 'suryavanshi': 5257, 'xyy': 5258, 'destiny': 5259, 'ristigouche': 5260, 'ecological': 5261, 'manson': 5262, 'anthems': 5263, 'cita': 5264, 'radar': 5265, 'owlet': 5266, 'provider': 5267, 'perseo': 5268, 'miranda': 5269, 'theodore': 5270, 'roosevelt': 5271, 'inaugural': 5272, 'koontz': 5273, 'watauga': 5274, 'aunt': 5275, 'firehouse': 5276, 'miles': 5277, 'iroquois': 5278, 'quick': 5279, 'society': 5280, 'roel': 5281, 'velzen': 5282, 'completely': 5283, 'barbara': 5284, 'xplorer': 5285, 'billboard': 5286, 'hits:': 5287, 'lochearn': 5288, 'tombstone': 5289, '00:37': 5290, 'nib': 5291, 'fay': 5292, 'gil': 5293, 'parris': 5294, 'whitby': 5295, 'africana': 5296, 'altyn-emel-nationalpark': 5297, 'thale': 5298, 'landers': 5299, 'cidade': 5300, 'árvore': 5301, 'daughters': 5302, 'skillman': 5303, 'lloyd': 5304, 'ready': 5305, 'frankenstein': 5306, 'drag': 5307, 'queens': 5308, 'tibetan': 5309, 'hodges': 5310, 'jeremy': 5311, 'dormi': 5312, 'amore': 5313, 'situazione': 5314, 'non': 5315, 'è': 5316, 'buona': 5317, 'parthenon': 5318, 'jerry': 5319, 'xandee': 5320, 'market': 5321, 'fairness': 5322, 'holidays': 5323, 'yarra': 5324, 'leonid': 5325, 'soybelman': 5326, 'annabella': 5327, 'lwin': 5328, 'alternativa': 5329, 'collector': 5330, 'zos': 5331, 'kia': 5332, 'cultus': 5333, 'paraguay': 5334, 'maryanne': 5335, 'per': 5336, 'yngve': 5337, 'ohlin': 5338, 'clay': 5339, 'aiken': 5340, 'bonny': 5341, 'hind': 5342, 'wits': 5343, 'politics': 5344, 'falkland': 5345, 'wolin': 5346, 'harassed': 5347, 'mali': 5348, 'hallwood': 5349, 'napoleon': 5350, 'xiv': 5351, 'sharlene': 5352, 'transatlantic': 5353, 'lullaby': 5354, 'cathedral': 5355, 'madeline': 5356, 'stella': 5357, 'heroquest': 5358, 'sorasil': 5359, 'eagle': 5360, 'harbor': 5361, 'beckley': 5362, 'alexander': 5363, 'workin’': 5364, 'quintet': 5365, 'jeanette': 5366, 'extreme': 5367, 'berowra': 5368, 'waters': 5369, 'esquivando': 5370, 'charcos': 5371, 'sells': 5372, 'cupcake': 5373, 'lumpkin': 5374, 'saudi': 5375, 'arabia': 5376, 'thelma': 5377, 'aoyama': 5378, 'murph': 5379, 'nuts': 5380, 'irvington': 5381, 'dre': 5382, 'westlake': 5383, 'weathervane': 5384, 'fencing': 5385, 'katharine': 5386, 'soheila': 5387, 'zaland': 5388, 'thenaruvi': 5389, 'steven': 5390, 'harwell': 5391, 'sheikh': 5392, 'chilli': 5393, 'uproar': 5394, 'piperton': 5395, 'rwanda': 5396, 'cordell': 5397, 'mosson': 5398, 'neo': 5399, 'bean': 5400, 'slow': 5401, 'topton': 5402, 'handful': 5403, 'rocketeer': 5404, 'gibraltar:': 5405, 'britain': 5406, 'bt': 5407, 'independent': 5408, 'imposter': 5409, 'mummy': 5410, 'cortelyou': 5411, 'rd': 5412, 'hugh': 5413, 'masekela': 5414, 'fludd': 5415, 'beastologist': 5416, 'jenners': 5417, 'panama': 5418, 'feelin': 5419, 'mai': 5420, 'selim': 5421, 'hurry': 5422, 'sundown': 5423, 'reverie': 5424, 'squad': 5425, 'avalon': 5426, 'pain': 5427, 'abrar': 5428, 'ul': 5429, 'haq': 5430, 'confidence': 5431, 'boost': 5432, 'nikolajewna': 5433, 'jessipowa': 5434, 'olmitz': 5435, 'bugs': 5436, 'nips': 5437, 'fro': 5438, 'nas': 5439, 'victor': 5440, 'kunonga': 5441, 'mom': 5442, 'shadows': 5443, 'moris': 5444, 'tepper': 5445, 'frisell': 5446, 'alternative': 5447, 'toll': 5448, 'ven': 5449, 'granite-steppe': 5450, 'buh': 5451, 'rimsky-korsakoffee': 5452, 'mackville': 5453, 'mouse:': 5454, 'finland': 5455, 'counter': 5456, 'ribbons': 5457, 'fragile': 5458, 'frontiers:': 5459, 'mumbai': 5460, 'attacks': 5461, 'twas': 5462, 'tanimura': 5463, 'mediodía': 5464, 'acústico': 5465, 'madden': 5466, 'nfl': 5467, 'hext': 5468, 'saracens': 5469, 'willits': 5470, 'dobinson': 5471, 'calientes': 5472, 'descanso': 5473, 'infinito': 5474, 'leroi': 5475, 'inlet': 5476, 'thrills': 5477, 'lora': 5478, 'boonton': 5479, '18': 5480, 'bâton': 5481, '07:03:43': 5482, 'pirates': 5483, 'bet': 5484, 'awards': 5485, 'erik': 5486, 'santos': 5487, 'takuro': 5488, 'titanic': 5489, 'palm': 5490, 'seminary': 5491, 'augusta': 5492, 'bhutto': 5493, 'mausoleum': 5494, 'blackbox': 5495, 'generations': 5496, 'joelia': 5497, 'savitsjeva': 5498, '88': 5499, 'hallucinations': 5500, 'despair': 5501, 'songz': 5502, 'phoenix:': 5503, 'videogames': 5504, 'dynamite': 5505, 'warrior': 5506, 'edison': 5507, 'given': 5508, 'sissieretta': 5509, 'gertrude': 5510, 'petrified': 5511, 'jungo': 5512, 'mh': 5513, 'gears': 5514, 'tramp': 5515, 'timour': 5516, 'moutsouraev': 5517, 'pasta': 5518, '1987': 5519, 'edie': 5520, 'brickell': 5521, 'peace-maker': 5522, 'pho': 5523, '1969': 5524, 'sicilian': 5525, 'impostors': 5526, 'jkt48': 5527, 'henry': 5528, 'hwang': 5529, 'geddes': 5530, 'maid-rite': 5531, 'gardens': 5532, 'together': 5533, 'maritime': 5534, 'harsh': 5535, 'cleaning': 5536, 'flipper': 5537, 'gryphon': 5538, 'colic:': 5539, 'weird': 5540, 'mosses': 5541, 'manse': 5542, 'whitewood': 5543, 'temperance': 5544, 'realization': 5545, 'jackson': 5546, 'stern': 5547, 'image': 5548, 'storm:': 5549, 'disasters': 5550, 'changed': 5551, 'nimble': 5552, 'bombastic': 5553, 'labyrinthe': 5554, 'darnestown': 5555, 'case': 5556, 'jennie': 5557, 'brice': 5558, 'baking': 5559, 'brookneal': 5560, 'aragon': 5561, 'ballroom': 5562, 'pattie': 5563, 'joshua': 5564, 'radin': 5565, 'futuros': 5566, 'josh': 5567, 'gracin': 5568, 'yuna': 5569, 'ito': 5570, 'rods': 5571, 'shows': 5572, 'antigua': 5573, 'barbuda': 5574, 'yet': 5575, 'bioruby': 5576, 'steinway': 5577, 'wentworth': 5578, 'greg': 5579, 'raposo': 5580, 'ugliness': 5581, 'basaseachic': 5582, 'worthington': 5583, 'formby': 5584, 'jr': 5585, 'widow': 5586, 'saint-pierre': 5587, 'suite': 5588, 'sudarmoricaine': 5589, 'afi': 5590, 'mood': 5591, 'meditative': 5592, '01:50': 5593, 'rosario': 5594, 'monterey': 5595, 'labyrinth': 5596, 'heterocycles': 5597, 'intensity': 5598, 'dresbach': 5599, 'distrowatch': 5600, 'det': 5601, 'kimer': 5602, 'julefest': 5603, 'technical&brutal': 5604, 'junior': 5605, 'obama': 5606, 'syndrome': 5607, 'thomson': 5608, 'iparty': 5609, 'victorious': 5610, '2021': 5611, 'bathgate': 5612, 'seamus': 5613, 'heaney': 5614, 'collected': 5615, 'edward': 5616, 'l': 5617, 'ryerson': 5618, 'student': 5619, 'generator': 5620, 'icon': 5621, 'tn': 5622, 'removers': 5623, 'forêt': 5624, 'nationale': 5625, 'davy': 5626, 'crockett': 5627, 'yury': 5628, 'chernavsky': 5629, 'route': 5630, 'doomsters': 5631, 'dressmaker': 5632, 'colette': 5633, 'rod': 5634, 'parts': 5635, 'sci-fi': 5636, 'crimes': 5637, 'wash': 5638, 'deeyah': 5639, 'khan': 5640, 'scampi': 5641, 'maurice': 5642, 'om': 5643, 'johnnie': 5644, 'activity': 5645, 'shorty': 5646, 'fir': 5647, '103rd': 5648, 'yangtze': 5649, 'retrowave': 5650, 'outrun': 5651, 'vanishing': 5652, 'porch': 5653, 'spirituals': 5654, 'shinehead': 5655, 'kj': 5656, '52': 5657, 'quiero': 5658, 'everett': 5659, 'resurrection': 5660, 'sleepy': 5661, 'celtic': 5662, 'silvers': 5663, 'madman': 5664, 'janamanchi': 5665, 'seshadri': 5666, 'sarma': 5667, 'main-travelled': 5668, 'roads': 5669, 'fit': 5670, 'prescription': 5671, 'pianist': 5672, 'yeah': 5673, 'cactus': 5674, 'heartbeat': 5675, 'pay': 5676, 'dvd': 5677, 'cale': 5678, 'gamer': 5679, 'symphonic': 5680, 'colorless': 5681, 'tsukuru': 5682, 'tazaki': 5683, 'pilgrimage': 5684, 'tight': 5685, '12/14/2023': 5686, 'beyond': 5687, 'reach': 5688, 'bridge-city': 5689, 'ryuichi': 5690, 'kawamura': 5691, 'eim': 5692, 'morgan': 5693, 'suitable': 5694, '11/1/2033': 5695, 'marit': 5696, 'bergman': 5697, 'enkitta': 5698, 'mothathe': 5699, '2010': 5700, 'grohl': 5701, 'lakeisha': 5702, 'jimenez': 5703, 'szahram': 5704, 'nazeri': 5705, 'text': 5706, 'finnish': 5707, 'grammar': 5708, 'seasons:': 5709, 'skid': 5710, 'cartwright': 5711, 'fry': 5712, 'sauce': 5713, 'barthélemy': 5714, 'otis': 5715, 'saki': 5716, 'nakajima': 5717, 'vanlose': 5718, 'stairway': 5719, 'janove': 5720, 'ottesen': 5721, 'macgregor': 5722, 'rare': 5723, 'birds': 5724, 'blackpool': 5725, 'texola': 5726, 'noctámbulo': 5727, 'pl': 5728, 'harel': 5729, 'skaat': 5730, 'beloved': 5731, 'duane': 5732, 'allman': 5733, 'bunker': 5734, 'spätzle': 5735, 'censored': 5736, 'shack': 5737, '101': 5738, 'crying': 5739, 'hoping': 5740, 'buzz': 5741, 'simplescreenrecorder': 5742, '27': 5743, 'cracking': 5744, 'contraptions': 5745, 'mezes': 5746, 'understanding': 5747, 'lenny': 5748, 'kaye': 5749, 'rivers': 5750, 'pattillo': 5751, 'avery': 5752, 'manuelita': 5753, 'tortuga': 5754, 'nevada': 5755, 'jason': 5756, 'donovan': 5757, 'donut': 5758, 'matter': 5759, 'tembe': 5760, 'czarna': 5761, 'dziewczyna': 5762, 'madness': 5763, 'orthodox': 5764, 'prophecy': 5765, 'bernie': 5766, 'bloodstained': 5767, 'mettawa': 5768, 'kelley': 5769, 'suzette': 5770, 'curious': 5771, 'chair': 5772, 'ettrick': 5773, 'culdesac': 5774, 'beatmania': 5775, 'iidx': 5776, 'object': 5777, 'falling': 5778, 'upstairs': 5779, 'diplo': 5780, 'flamingo': 5781, 'jonathan': 5782, 'arons': 5783, 'rie': 5784, 'tomosaka': 5785, 'deadly': 5786, 'beijing': 5787, 'huanying': 5788, 'ni': 5789, 'cant': 5790, 'dels': 5791, 'ocells': 5792, 'vini': 5793, 'job': 5794, 'inversion': 5795, 'maximilian': 5796, 'mutzke': 5797, 'myself': 5798, 'peacefulness': 5799, 'tenerife': 5800, 'salomon': 5801, 'must': 5802, 'dorothy': 5803, 'ashby': 5804, 'tal': 5805, 'chhapar': 5806, 'makers': 5807, 'abominations': 5808, 'recorder': 5809, 'randsell': 5810, 'gd&top': 5811, '2009': 5812, 'hughie': 5813, 'graham': 5814, 'vidyadhar': 5815, 'vyas': 5816, 'ronnie': 5817, 'president': 5818, 'alive': 5819, 'roach': 5820, 'badmeaningood': 5821, 'volume4': 5822, 'jaime': 5823, '5/17/2037': 5824, 'accesss': 5825, 'stain': 5826, 'sebastian': 5827, 'donnie': 5828, 'gorilla': 5829, 'morrison': 5830, 'libby': 5831, 'crook': 5832, 'nanny': 5833, 'rivalry:': 5834, 'v': 5835, 'indestructible': 5836, 'portland': 5837, 'waffle': 5838, 'tgif': 5839, 'switching': 5840, 'channels': 5841, 'briarwood': 5842, 'rides': 5843, 'dread': 5844, 'legion': 5845, '2022': 5846, 'poncha': 5847, '00:32': 5848, 'carny': 5849, 'bock': 5850, 'dina': 5851, 'alexis': 5852, 'fantastic': 5853, 'dances': 5854, 'of:': 5855, 'idols': 5856, 'reynolds': 5857, 'jonny': 5858, 'buckland': 5859, 'milagros:': 5860, 'mandela:': 5861, 'authorised': 5862, 'brass': 5863, 'rail': 5864, 'shirts': 5865, 'alchemyst:': 5866, 'immortal': 5867, 'nicholas': 5868, 'flamel': 5869, 'stares': 5870, 'whispers': 5871, 'sólo': 5872, 'dos': 5873, 'torrey': 5874, 'pines': 5875, 'companion': 5876, 'heroic': 5877, 'failures': 5878, 'germany': 5879, 'wants': 5880, 'yogurt': 5881, 'slick': 5882, 'hickory': 5883, 'elisabeth': 5884, 'd-day': 5885, 'dodgers': 5886, 'kd': 5887, 'lang': 5888, 'accidentally': 5889, 'fork': 5890, 'nanana': 5891, 'massimo': 5892, 'altomare': 5893, 'profile': 5894, 'brasil': 5895, 'glove': 5896, 'thee': 5897, 'undatakerz': 5898, 'mccrea': 5899, 'saucisse': 5900, 'rachel': 5901, 'orion': 5902, 'details': 5903, 'collide': 5904, 'chamber': 5905, 'rak': 5906, 'biszewilo': 5907, 'tarts': 5908, 'astor': 5909, 'piazzolla': 5910, 'forward': 5911, 'tightrope': 5912, 'dancer': 5913, 'armenia': 5914, 'voyage': 5915, 'adele': 5916, 'giodi': 5917, 'piper': 5918, 'shōnen': 5919, 'toppa': 5920, 'bashin': 5921, 'wilma': 5922, 'gowanus': 5923, 'yacht': 5924, 'got': 5925, 'peyroux': 5926, 'gregory': 5927, 'douglass': 5928, 'racketeers': 5929, 'exit': 5930, 'ankimo': 5931, '1/11/2030': 5932, 'catahoula': 5933, 'meet': 5934, 'vogues': 5935, 'literary': 5936, 'peel': 5937, 'pie': 5938, 'pruntytown': 5939, 'somi': 5940, 'sadface': 5941, 'birta': 5942, 'snuffy': 5943, 'walden': 5944, 'finalists': 5945, 'comer': 5946, 'tha': 5947, 'funkee': 5948, 'homosapien': 5949, 'mission': 5950, 'retrovisor': 5951, 'advise': 5952, '07:31:32': 5953, 'tu': 5954, 'hamedi': 5955, 'alloway': 5956, 'scream': 5957, 'whisper': 5958, 'arcadian': 5959, 'dougan': 5960, 'kenedy': 5961, 'marx': 5962, 'southwest': 5963, 'riders': 5964, 'shelter': 5965, 'seeley': 5966, 'fourteenth': 5967, 'demolition': 5968, '11:09': 5969, 'pies': 5970, 'plandome': 5971, 'manor': 5972, 'gouden': 5973, 'roos': 5974, 'daedelus': 5975, 'nj': 5976, 'cahoots': 5977, 'alejandra': 5978, 'lemonheads': 5979, 'tailwind': 5980, 'tomy': 5981, 'leena': 5982, 'peisa': 5983, 'nathan': 5984, 'clint': 5985, 'mansell': 5986, 'otsego': 5987, 'rag': 5988, 'covers': 5989, 'mash': 5990, 'ups': 5991, 'jordan': 5992, 'inez': 5993, 'facility': 5994, 'gillespie': 5995, 'tremonti': 5996, 'lest': 5997, 'forget:': 5998, 'bslade': 5999, 'hale': 6000, '7/22/2030': 6001, 'emerald': 6002, 'maybe': 6003, 'som': 6004, 'tam': 6005, 'todays': 6006, 'pure': 6007, 'seduction': 6008, 'bride': 6009, 'wore': 6010, 'albertson': 6011, 'kanwar': 6012, 'catch': 6013, 'mir': 6014, 'pier': 6015, 'cliff': 6016, 'rathinirvedam': 6017, 'lunacy': 6018, 'sonya': 6019, 'valarie': 6020, 'mari': 6021, 'phish': 6022, '7/16/2032': 6023, 'dominican': 6024, 'janeane': 6025, 'des': 6026, 'moines': 6027, 'hattiesburg': 6028, 'sins': 6029, 'cities': 6030, 'antarctica': 6031, 'live:': 6032, 'save': 6033, 'fink': 6034, 'overload': 6035, 'korea': 6036, 'milk': 6037, 'mister': 6038, '138th': 6039, 'rockabilly': 6040, 'mania': 6041, 'snowball': 6042, 'mad': 6043, 'scientist': 6044, 'fame': 6045, 'hoggard': 6046, 'elberta': 6047, 'alma': 6048, '18:49:20': 6049, 'burger': 6050, 'ove': 6051, 'trac': 6052, 'patricia': 6053, 'vandalia': 6054, 'salvador': 6055, 'musica': 6056, 'española': 6057, 'batuecas': 6058, 'yamma': 6059, 'slut': 6060, 'backyard': 6061, 'cedarburg': 6062, 'brooke': 6063, 'fraser': 6064, 'wwe': 6065, 'legends': 6066, 'wrestlemania': 6067, 'gie': 6068, 'candlelight': 6069, 'supernatural': 6070, 'events': 6071, 'naughty': 6072, 'boudreaux': 6073, 'wren': 6074, 'lankan': 6075, 'tues': 6076, 'solveig': 6077, 'le-aqua-na': 6078, 'burrito': 6079, 'rim': 6080, 'mix': 6081, 'tobias': 6082, 'sammet': 6083, 'bring': 6084, 'ida': 6085, 'monica': 6086, 'etta': 6087, 'max': 6088, 'dune': 6089, 'lineage': 6090, '12:06': 6091, 'holladay': 6092, 'incredible': 6093, 'hulk': 6094, 'returns': 6095, 'creator': 6096, 'trancers': 6097, 'aerial': 6098, 'joy': 6099, 'dark:': 6100, 'ferret': 6101, 'gipsy-gordon': 6102, 'wildland': 6103, 'campanian': 6104, 'compleat': 6105, 'housewife': 6106, 'compact': 6107, 'proposal': 6108, 'gabrial': 6109, 'mcnair': 6110, 'chisholm': 6111, 'marc': 6112, 'quantity': 6113, 'insanity': 6114, 'sky:': 6115, 'godlike': 6116, 'genius': 6117, 'brenham': 6118, 'jackass': 6119, 'investing': 6120, 'krieg': 6121, 'chinatown': 6122, 'conrad': 6123, 'rosebud': 6124, 'incite': 6125, 'goan': 6126, 'butterfly': 6127, 'maximum': 6128, 'shangri-la': 6129, '911': 6130, 'peja': 6131, 'licorice': 6132, 'mckechnie': 6133, 'aftercluv': 6134, 'stretch': 6135, 'djibouti': 6136, 'serenata': 6137, 'southtown': 6138, 'pinecliffe': 6139, 'osgood': 6140, 'kan': 6141, 'gifta': 6142, 'sig': 6143, 'jeans': 6144, 'penuelas': 6145, 'pavo': 6146, 'dustin': 6147, 'viajes': 6148, 'ivan': 6149, 'mane': 6150, 'jarnowick': 6151, 'yoshiki': 6152, 'countdown:': 6153, 'savoy': 6154, 'sessions': 6155, 'carry': 6156, 'sandworms': 6157, 'pearblossom': 6158, 'deception': 6159, 'anstruther': 6160, 'iwers': 6161, 'gym': 6162, 'strong': 6163, 'champion': 6164, 'chichi': 6165, 'picasso': 6166, 'martyr': 6167, 'change': 6168, 'underneath': 6169, 'mizell': 6170, 'beltsville': 6171, 'nephew': 6172, 'alton': 6173, 'loretta': 6174, 'lynn': 6175, 'grey': 6176, 'scarecrow': 6177, 'army': 6178, 'fernando': 6179, 'mclaurin': 6180, 'trivial': 6181, 'pursuit:': 6182, 'america': 6183, 'friona': 6184, 'kikas': 6185, 'bank': 6186, 'medal': 6187, 'nepal': 6188, 'cameroon': 6189, 'conducting': 6190, 'grave': 6191, 'lexington-fayette': 6192, 'top-ten': 6193, 'doda': 6194, 'trick': 6195, 'treats': 6196, 'naguabo': 6197, 'breath': 6198, 'outpost': 6199, 'potter': 6200, 'deathly': 6201, 'hallows': 6202, 'landscape': 6203, 'baltic': 6204, 'hardcover': 6205, 'intangibles': 6206, 'leadership': 6207, 'chips': 6208, 'susumu': 6209, 'showtunes': 6210, 'reader': 6211, 'warned': 6212, 'q': 6213, 'swindlers': 6214, 'treasures': 6215, 'complete': 6216, 'unholy': 6217, 'confessions': 6218, 'sympathy': 6219, 'nicaragua': 6220, 'searsport': 6221, 'ritchie': 6222, 'valens': 6223, 'virales': 6224, 'siempre': 6225, 'yokoyama': 6226, 'bag': 6227, 'careless': 6228, 'consume': 6229, 'gilmer': 6230, 'keeling': 6231, 'daewon': 6232, 'vallecito': 6233, 'nubians': 6234, 'plutonia': 6235, 'canciones': 6236, 'recuerdo': 6237, 'fern': 6238, 'rockholds': 6239, 'tarzan': 6240, 'stuffed': 6241, 'peppers': 6242, 'woodsfield': 6243, '06:30:26': 6244, 'kim': 6245, 'kibum': 6246, '17:43': 6247, 'lualualei': 6248, 'wimpy': 6249, 'mohsen': 6250, 'chavoshi': 6251, 'balance': 6252, 'nik': 6253, 'kershaw': 6254, 'eighth': 6255, 'rillettes': 6256, 'dimitri': 6257, 'fampas': 6258, 'borrowed': 6259, 'technicolor': 6260, 'cierra': 6261, 'puerta': 6262, 'questions': 6263, 'answers': 6264, 'sugarville': 6265, 'rank': 6266, 'pelahatchie': 6267, 'bonnaroo': 6268, 'der': 6269, 'und': 6270, 'kalypso': 6271, 'aus': 6272, 'wien': 6273, 'vonda': 6274, 'everytime': 6275, 'glace': 6276, 'atmosphere': 6277, 'mulvane': 6278, 'ratings': 6279, 'solange': 6280, 'exile': 6281, 'challenges': 6282, 'chemistry': 6283, 'arrows': 6284, 'hercules': 6285, 'lorenzo': 6286, 'palacios': 6287, 'quispe': 6288, '1955': 6289, 'solromar': 6290, 'competitors': 6291, 'kickass': 6292, 'porcupine': 6293, 'gospel': 6294, 'drawa': 6295, 'torn': 6296, 'emptiness': 6297, 'julie': 6298, 'driscoll': 6299, 'gold': 6300, 'breezy': 6301, 'gucci': 6302, 'seek': 6303, 'destroy': 6304, 'sin': 6305, 'angel': 6306, 'female': 6307, 'hamlet': 6308, 'cajah': 6309, 'universum': 6310, 'travelling': 6311, 'set': 6312, 'isthmus': 6313, 'hundred-year': 6314, 'bhoomi': 6315, 'geetha': 6316, 'infrared': 6317, 'riding': 6318, 'longest': 6319, 'ace': 6320, 'cozy': 6321, 'drive': 6322, 'geek': 6323, 'chic': 6324, 'pero': 6325, 'broadway-lafayette': 6326, 'crocus': 6327, 'glenda': 6328, 'lois': 6329, 'sheriff': 6330, 'crucible': 6331, 'sze': 6332, 'ludowici': 6333, 'denial': 6334, 'wannadies': 6335, 'andorra': 6336, 'wartime': 6337, 'inform': 6338, 'abdication': 6339, '1956': 6340, 'bishop': 6341, 'hereford': 6342, 'mayer': 6343, 'basic': 6344, 'utsler': 6345, 'full': 6346, 'divorced': 6347, 'ocilla': 6348, 'orgy': 6349, 'leather': 6350, 'less': 6351, 'candles': 6352, 'susana': 6353, 'dogs': 6354, 'warfare': 6355, 'eternally': 6356, 'apartment': 6357, 'hunting': 6358, 'hindus:': 6359, 'servidor': 6360, 'utatsuki': 6361, 'carpet': 6362, 'nishi': 6363, 'sonogi': 6364, 'hantō': 6365, 'keine': 6366, 'grenzen': 6367, 'territories': 6368, 'highland': 6369, 'wuthering': 6370, 'rita': 6371, 'hurley': 6372, 'valentyne': 6373, 'lee:': 6374, 'knew': 6375, 'halal': 6376, 'brigitte': 6377, 'katelyn': 6378, 'natalie': 6379, 'astonishing': 6380, 'octavian': 6381, 'mashed': 6382, 'pumpkin': 6383, 'tina': 6384, 'cousins': 6385, 'offerman': 6386, 'yemen': 6387, 'naches': 6388, 'leone': 6389, 'methuen': 6390, 'doyle': 6391, 'tailor': 6392, 'maschi': 6393, 'altri': 6394, 'pappu': 6395, 'venugopala': 6396, 'rao': 6397, 'mama': 6398, 'thornton': 6399, 'hippocratic': 6400, 'oath': 6401, 'grow': 6402, 'chloe': 6403, 'lattanzi': 6404, 'francis': 6405, 'caucasian': 6406, 'exploits': 6407, 'juan': 6408, 'moped': 6409, 'chrome-plated': 6410, 'handlebars': 6411, 'yard': 6412, 'sot': 6413, 'taggart': 6414, 'reservtion': 6415, 'kellnersville': 6416, 'lotus': 6417, 'andy': 6418, 'lafe': 6419, 'beast': 6420, 'blowfly': 6421, 'pig': 6422, 'scrolls': 6423, 'stonewood': 6424, 'quebeck': 6425, 'woburn': 6426, 'chrome': 6427, 'restaraunt': 6428, 'wickersham': 6429, 'hostile': 6430, 'fleetwood': 6431, 'deli': 6432, 'railroad': 6433, 'model': 6434, 'craftsman': 6435, 'riddim': 6436, '54': 6437, 'humanity': 6438, 'townes': 6439, 'zandt': 6440, 'whatever': 6441, 'turns': 6442, 'tate': 6443, 'homo': 6444, 'handbook': 6445, 'act': 6446, 'kolkheti': 6447, 'playslist': 6448, 'fabulosos': 6449, 'cadillacs': 6450, 'smolan': 6451, 'dictionary': 6452, 'language': 6453, 'scribblings': 6454, 'upcoming': 6455, 'dormir': 6456, 'savannah': 6457, 'lauderdale': 6458, 'henniker': 6459, 'miso': 6460, 'soup': 6461, 'helena': 6462, 'papoose': 6463, 'wikipedia': 6464, 'cd': 6465, 'selection': 6466, 'directions': 6467, 'curl': 6468, 'papers': 6469, 'wakarusa': 6470, 'tourte': 6471, 'yamhill': 6472, 'terminator': 6473, 'morrisonville': 6474, 'eerste': 6475, 'keer': 6476, 'caiafa': 6477, 'plau': 6478, 'chef': 6479, 'jolley': 6480, 'cardin': 6481, 'hoc': 6482, 'maldeamores': 6483, 'wynnedale': 6484, 'grandmaster': 6485, 'flash': 6486, 'unleashed': 6487, '06:31:22': 6488, 'forza': 6489, 'nations': 6490, 'cantautor': 6491, 'orange': 6492, 'éxitos': 6493, 'necessary': 6494, 'halley': 6495, 'ucolo': 6496, 'stubborn': 6497, 'kinda': 6498, 'fellow': 6499, 'amott': 6500, 'potje': 6501, 'vet': 6502, 'apbl98': 6503, 'alden': 6504, 'penner': 6505, 'bottom': 6506, 'playa': 6507, 'fly': 6508, 'freight': 6509, 'lila': 6510, 'reyes': 6511, 'ruby': 6512, 'jigs': 6513, 'reels': 6514, 'dante’s': 6515, 'superior': 6516, 'magical': 6517, 'lightning': 6518, 'vernon': 6519, 'smiles': 6520, 'cary': 6521, 'becharof': 6522, 'daigo': 6523, 'indietronic': 6524, 'sonntagskind': 6525, 'system': 6526, 'bloodhounds': 6527, 'freckled': 6528, '00:47:43': 6529, 'half-formed': 6530, 'lukasz': 6531, 'gottwald': 6532, 'descendants': 6533, 'noreen': 6534, 'strings': 6535, 'setting': 6536, 'bears': 6537, 'czechia': 6538, 'brookland': 6539, 'terrace': 6540, 'tei': 6541, 'closer': 6542, 'glade': 6543, 'twenty-fifth': 6544, 'hariprasad': 6545, 'chaurasia': 6546, 'westbam': 6547, 'alumb': 6548, 'allergic': 6549, 'rockwell': 6550, 'muppet': 6551, 'deserve': 6552, 'sequoyah': 6553, 'playstation官方杂志': 6554, 'greyest': 6555, 'nigga': 6556, 'piety': 6557, 'saratoga': 6558, 'hellacopters': 6559, 'teen': 6560, 'lowest': 6561, 'reprise:': 6562, 'scattered': 6563, 'bodies': 6564, 'gobler': 6565, 'kinder': 6566, 'ari': 6567, 'herstand': 6568, 'dragon': 6569, 'z:': 6570, 'selections': 6571, 'republic:': 6572, 'revan': 6573, 'troy': 6574, 'allardt': 6575, 'aruba': 6576, 'goldy': 6577, 'mcjohn': 6578, 'elsewhere': 6579, 'ironing': 6580, 'loved': 6581, 'ones': 6582, 'dixon': 6583, 'hans': 6584, 'nilsson': 6585, 'utopia': 6586, 'macaroni': 6587, 'cash-cash': 6588, 'nightmares': 6589, 'shallow': 6590, 'playcanvas': 6591, 'vicky': 6592, 'leandros': 6593, 'judge': 6594, 'jules': 6595, 'atrocity': 6596, 'exhibition': 6597, 'duson': 6598, '20th': 6599, 'mohammad': 6600, 'reza': 6601, 'lotfi': 6602, 'giovanni': 6603, 'battista': 6604, 'guadagnini': 6605, '1982': 6606, 'annie': 6607, 'herring': 6608, 'nineteenth': 6609, 'elsmore': 6610, 'liechtenstein': 6611, '10:15': 6612, 'guard': 6613, 'tobymac': 6614, 'jiro': 6615, 'slane': 6616, 'haifa': 6617, 'wehbe': 6618, 'heritage': 6619, 'shubuta': 6620, 'prospect': 6621, 'blaine': 6622, 'ivy': 6623, 'belknap': 6624, 'gina': 6625, 'schock': 6626, 'jonas': 6627, 'waits': 6628, 'uncharted': 6629, 'drake': 6630, 'tehama': 6631, 'phoebe': 6632, 'zahn': 6633, 'thomas': 6634, 'rhett': 6635, 'archive': 6636, 'domestic': 6637, 'animation': 6638, 'beverley': 6639, 'martyn': 6640, 'nerves': 6641, 'rileyville': 6642, 'those': 6643, 'leningrad': 6644, 'cowboys': 6645, 'published': 6646, 'maison': 6647, 'parthenais-perrault': 6648, 'fabio': 6649, 'gibassier': 6650, 'armistead': 6651, 'burwell': 6652, 'iv': 6653, 'masters': 6654, 'catchphrase': 6655, 'happen': 6656, 'lawrence': 6657, 'stuck': 6658, 'sax': 6659, 'rum': 6660, 'varieties': 6661, 'scientific': 6662, 'ranger': 6663, 'harry’s': 6664, 'benin': 6665, 'receipt': 6666, 'firewall': 6667, 'pro': 6668, 'sleeps': 6669, 'aretha': 6670, 'franklin': 6671, 'organization': 6672, 'grisly': 6673, 'wolfe': 6674, 'bees': 6675, 'ceca': 6676, 'ghosts': 6677, 'machinery': 6678, 'spector': 6679, 'whether': 6680, '04:34:15': 6681, 'frightened': 6682, 'dummy': 6683, 'budayeen': 6684, 'nights': 6685, 'kaakai': 6686, 'egoist': 6687, 'bread': 6688, 'olive': 6689, 'monie': 6690, 'paper': 6691, 'patetown': 6692, 'andrés': 6693, 'calamaro': 6694, 'timeline': 6695, 'chicago:': 6696, 'sifow': 6697, 'roger': 6698, 'whittaker': 6699, 'bronislau': 6700, 'kaper': 6701, 'ennarukil': 6702, 'nee': 6703, 'irunthal': 6704, 'colony': 6705, 'cookie': 6706, 'sherry': 6707, 'concepcion': 6708, 'nunam': 6709, 'iqua': 6710, 'leaf': 6711, 'rookantha': 6712, 'gunathilake': 6713, 'days:': 6714, 'activists': 6715, 'barberville': 6716, 'tatico': 6717, 'henriquez': 6718, 'bleeps': 6719, 'bloops': 6720, 'wannabe:': 6721, 'spice': 6722, 'reinvented': 6723, 'manassa': 6724, 'baroque': 6725, 'thibaults': 6726, 'dunbrody': 6727, 'kitchin': 6728, 'mabel’s': 6729, 'dramatic': 6730, 'career': 6731, '1/11/2040': 6732, 'mann': 6733, 'digimon': 6734, 'costello': 6735, 'kidd': 6736, 'forth': 6737, 'noodle': 6738, '2/21/2021': 6739, 'iw': 6740, 'atch': 6741, 'balls': 6742, 'vampate': 6743, 'fuoco': 6744, 'bond': 6745, '003½': 6746, 'harlem': 6747, 'incident': 6748, 'costs': 6749, 'accidents': 6750, 'cardinal': 6751, 'izuna': 6752, 'unemployed': 6753, 'ninja': 6754, 'homestead': 6755, 'meadows': 6756, 'marci': 6757, 'marylou': 6758, 'amelia': 6759, 'mode': 6760, 'cheerful': 6761, 'flash:': 6762, 'guatemala': 6763, 'deasy': 6764, 'pretty': 6765, 'costa': 6766, 'rica': 6767, 'yorkston': 6768, 'wayside': 6769, 'farmerville': 6770, 'seed': 6771, 'chucky': 6772, 'bhutan': 6773, 'bettles': 6774, 'chilled': 6775, 'nicholaus': 6776, 'arson': 6777, 'wanna': 6778, 'denniz': 6779, 'used': 6780, 'pledge': 6781, 'markus': 6782, 'grosskopf': 6783, 'molecular': 6784, 'gastronomy': 6785, 'saddle': 6786, 'aira': 6787, 'yuhki': 6788, 'tuomas': 6789, 'holopainen': 6790, 'sean': 6791, 'yseult': 6792, 'kaitlin': 6793, 'walla': 6794, 'patagonia': 6795, 'beatles': 6796, 'redacted': 6797, 'immortals': 6798, 'dolly': 6799, 'parton': 6800, 'priest': 6801, 'bethnal': 6802, 'stuff': 6803, 'nike': 6804, 'tempo': 6805, 'gregoletto': 6806, 'sanibel': 6807, 'thorn': 6808, 'graduates': 6809, 'malibu': 6810, 'narew': 6811, 'toto': 6812, 'sorrow': 6813, 'ultimatum': 6814, 'calder': 6815, 'roseland': 6816, 'foros': 6817, 'timis': 6818, 'ston': 6819, 'greco': 6820, 'bal': 6821, 'ganesh': 6822, 'you:': 6823, 'bitten': 6824, 'twice': 6825, 'bobbie': 6826, 'lookout': 6827, 'felicity': 6828, 'mauritania': 6829, 'marching': 6830, 'band': 6831, 'techno': 6832, 'hossein': 6833, 'alizadeh': 6834, 'relentless': 6835, 'rosanna': 6836, 'ejercicio': 6837, 'midfield': 6838, 'princesas': 6839, 'tracyton': 6840, 'hears': 6841, 'emre': 6842, 'aydin': 6843, 'tera:': 6844, 'exiled': 6845, 'realm': 6846, 'arborea': 6847, 'folk-rock': 6848, 'elizaveta': 6849, 'khripounova': 6850, 'stereophonics': 6851, 'cebu': 6852, 'protected': 6853, 'phoenix': 6854, 'williamsport': 6855, 'elizeth': 6856, 'cardoso': 6857, 'money': 6858, 'mokena': 6859, 'lbc': 6860, 'crew': 6861, 'argentino': 6862, 'vol': 6863, 'moravian': 6864, 'salvation': 6865, 'top-20': 6866, 'macneil': 6867, 'klaus': 6868, 'badelt': 6869, 'release': 6870, 'va': 6871, 'thicket': 6872, 'preserve': 6873, 'ochopee': 6874, 'labonte': 6875, 'lecanto': 6876, 'ghana': 6877, 'anders': 6878, 'crossroad': 6879, 'lied': 6880, 'airport': 6881, 'sealed': 6882, 'pidcoke': 6883, 'faithless': 6884, 'fire:': 6885, 'soundscape': 6886, 'none': 6887, 'above': 6888, 'amour:': 6889, 'shesher': 6890, 'kobita': 6891, 'revisited': 6892, 'oates': 6893, 'plylist': 6894, '07:07': 6895, 'delhi': 6896, 'rebbe:': 6897, 'teachings': 6898, 'menachem': 6899, 'schneerson': 6900, 'influential': 6901, 'rabbi': 6902, 'grant': 6903, 'turning': 6904, 'countess': 6905, 'overton': 6906, 'chippewa': 6907, 'zena': 6908, 'passover': 6909, 'frayser': 6910, 'breed': 6911, 'brook': 6912, 'sabin': 6913, 'rai': 6914, 'simply': 6915, 'lying': 6916, 'mcguire': 6917, 'laugh': 6918, 'minestra': 6919, 'magnifico': 6920, 'fereydoun': 6921, 'farrokhzad': 6922, 'sergei': 6923, 'chatschatrjan': 6924, 'harutyunyan': 6925, 'jose': 6926, 'pasillas': 6927, 'confusion': 6928, 'argentinian': 6929, 'mahwah': 6930, 'domoto': 6931, 'ali': 6932, 'bed': 6933, 'roses': 6934, 'sitek': 6935, 'mozambique': 6936, 'metalcore': 6937, 'written': 6938, 'iberville': 6939, 'spatial': 6940, 'query': 6941, 'server': 6942, 'sixpence': 6943, '1964': 6944, 'cliffs': 6945, 'dooneen': 6946, 'experiment': 6947, 'spaceball': 6948, 'trek:': 6949, 'hoyt': 6950, 'holtwood': 6951, 'monique': 6952, 'stewart': 6953, 'jami': 6954, 'millinocket': 6955, 'shara': 6956, 'worden': 6957, 'bachand': 6958, 'klute': 6959, 'meduza': 6960, 'wed': 6961, 'athol': 6962, 'osborne': 6963, 'victory': 6964, 'unsettled': 6965, 'selmont': 6966, 'junkies:': 6967, 'chained': 6968, 'furano-ashibetsu': 6969, 'ths': 6970, 'beedeville': 6971, 'edwards': 6972, 'mine': 6973, 'beyblade:': 6974, 'fierce': 6975, 'snake': 6976, 'thousands': 6977, 'carpenterville': 6978, 'infantil': 6979, 'augustine': 6980, '3rd': 6981, 'bahrain': 6982, 'gods': 6983, 'skeets': 6984, 'saxophone': 6985, 'supremacy': 6986, 'ofelia': 6987, 'italian': 6988, 'directive': 6989, '51': 6990, 'phish:': 6991, 'vegas': 6992, 'booked': 6993, 'sandstone': 6994, 'michel': 6995, 'strogoff': 6996, 'frog': 6997, 'continued': 6998, 'prabha': 6999, 'atre': 7000, 'choclair': 7001, 'bso': 7002, 'galactic': 7003, 'pot-healer': 7004, 'cassidy': 7005, 'stereo': 7006, 'shavo': 7007, 'odadjian': 7008, 'ringlestone': 7009, 'grenada': 7010, 'bret': 7011, 'mckenzie': 7012, 'commute': 7013, 'greensburg': 7014, 'wrong': 7015, 'murone': 7016, 'kōgen': 7017, 'nightdress': 7018, 'photoscape': 7019, 'spooky': 7020, 'teitur': 7021, 'lassen': 7022, 'maliau-basin-conservation-area': 7023, 'aki': 7024, 'nawaz': 7025, 'weekend': 7026, 'join': 7027, 'dots:': 7028, 'b-sides': 7029, 'rarities': 7030, 'hitchita': 7031, '25th': 7032, 'momy': 7033, 'flossmoor': 7034, 'são': 7035, 'tomé': 7036, 'príncipe': 7037, 'mattawan': 7038, 'dominica': 7039, 'emperors:': 7040, 'thyatis': 7041, 'alphatia': 7042, 'dallesport': 7043, 'went': 7044, 'falmouth': 7045, 'hungary': 7046, 'devils': 7047, 'den': 7048, 'minidoka': 7049, 'eviatar': 7050, 'banai': 7051, 'lovex': 7052, 'cab': 7053, 'darwin': 7054, 'peru': 7055, 'cool': 7056, 'stephanie': 7057, 'biddle': 7058, 'powder': 7059, 'puff': 7060, 'mirror': 7061, 'follow': 7062, 'camel': 7063, 'cappella': 7064, '45': 7065, 'moron': 7066, 'gathering': 7067, 'valverde': 7068, 'arch': 7069, 'you’re': 7070, 'winning': 7071, 'melon': 7072, 'baruch': 7073, 'chait': 7074, 'manuela': 7075, 'yvonne': 7076, 'paulette': 7077, 'sergeants': 7078, 'lolita': 7079, 'mandaean': 7080, '01:48:35': 7081, 'moroccan': 7082, 'greenville': 7083, 'berigan': 7084, 'noble': 7085, 'bitter': 7086, 'moa': 7087, 'anbessa': 7088, 'merengue': 7089, 'felix': 7090, 'kubin': 7091, 'kronos': 7092, 'vampire': 7093, 'dame': 7094, 'ethiopian': 7095, 'sholes': 7096, 'tisha': 7097, 'hooker': 7098, 'kearneysville': 7099, 'daphne': 7100, 'asha': 7101, 'bhosle': 7102, 'armik': 7103, 'mcentee': 7104, 'armour': 7105, 'chapin': 7106, 'clash': 7107, 'codes': 7108, 'inniswold': 7109, 'concise': 7110, 'treatise': 7111, 'angling': 7112, 'debby': 7113, 'garin': 7114, 'desmond': 7115, 'dekker': 7116, 'linger': 7117, 'awhile:': 7118, 'newport': 7119, 'worms': 7120, 'clan': 7121, 'emile': 7122, 'reproductions': 7123, 'chief': 7124, 'cook': 7125, 'yacoubian': 7126, '08:39': 7127, 'tata': 7128, 'trunk': 7129, 'minestrone': 7130, 'mongolian': 7131, 'northway': 7132, 'filipp': 7133, 'bedrossowitsch': 7134, 'kirkorow': 7135, 'journeyman': 7136, 'survive': 7137, 'regional': 7138, 'testament': 7139, 'gideon': 7140, 'mack': 7141, 'peking': 7142, 'piskies:': 7143, 'cornish': 7144, 'palmer': 7145, 'odetta': 7146, 'cissy': 7147, 'doi': 7148, 'suthep-pui': 7149, '4/15/2034': 7150, 'sai': 7151, 'thong': 7152, '02:59': 7153, 'myths': 7154, 'hindus': 7155, 'buddhists': 7156, 'shanghai': 7157, 'diaz': 7158, 'heyy': 7159, 'babyy': 7160, 'sonny': 7161, 'stitt': 7162, 'crimson': 7163, 'g-men': 7164, 'bim': 7165, 'ear': 7166, 'tupac': 7167, 'sarban': 7168, 'sealy': 7169, 'trattoria': 7170, 'hadar': 7171, 'nastya': 7172, 'kamenskih': 7173, 'priscilla': 7174, 'ballet': 7175, 'beam:': 7176, 'atari': 7177, 'salmon': 7178, 'ric': 7179, 'fierabracci': 7180, '135th': 7181, 'thrones': 7182, 'boomtown:': 7183, 'trina': 7184, 'latoya': 7185, 'tuvalu': 7186, 'expresión': 7187, 'ariston': 7188, 'dutchess': 7189, 'abstinence': 7190, 'lampoon': 7191, 'anniversary': 7192, '1970–1980': 7193, 'poverty': 7194, 'nobility': 7195, 'returned': 7196, 'ryan': 7197, 'brat': 7198, 'stump': 7199, 'maritza': 7200, 'keene': 7201, 'paly': 7202, 'banker': 7203, 'superman:': 7204, 'topock': 7205, 'jacksons': 7206, 'cameia': 7207, 'rosanne': 7208, 'rough': 7209, 'diamonds': 7210, 'cotton': 7211, 'meyer': 7212, 'cia': 7213, 'factbook': 7214, 'patiala': 7215, 'rajinikanth:': 7216, 'definitive': 7217, 'sreekumar': 7218, 'laidback': 7219, 'ramakadha': 7220, 'karl': 7221, 'davydov': 7222, 'storia': 7223, 'natale': 7224, 'strabane': 7225, 'wedlock': 7226, 'birdland': 7227, 'spain': 7228, 'spade': 7229, 'garden': 7230, 'lille': 7231, 'nichols': 7232, 'mariah…': 7233, 'elusive': 7234, 'chanteuse': 7235, 'crabfish': 7236, '13:22:09': 7237, 'fingers': 7238, 'spells': 7239, 'philtres': 7240, 'romanian': 7241, 'rixford': 7242, 'xquery': 7243, 'api': 7244, 'java': 7245, 'honor': 7246, 'culver': 7247, 'camille': 7248, 'antebellum': 7249, 'sunil': 7250, 'santha': 7251, 'jacksboro': 7252, 'mauritius': 7253, 'bearmouth': 7254, 'that:': 7255, 'creamed': 7256, 'eggs': 7257, 'territory': 7258, 'anweshaa': 7259, 'wes': 7260, 'scantlin': 7261, 'bouchée': 7262, 'genocide': 7263, 'front': 7264, 'jacksonville': 7265, 'progress': 7266, 'flanagan': 7267, 'pleasures': 7268, 'proof': 7269, 'post-grunge': 7270, 'sunnybrook': 7271, 'cherry': 7272, 'pink': 7273, 'trapp': 7274, 'mendoza': 7275, 'alok': 7276, 'laurelhurst': 7277, 'connorville': 7278, 'sewickley': 7279, 'klamath': 7280, 'chillin': 7281, 'susanne': 7282, 'pricedale': 7283, 'faget': 7284, 'darlene': 7285, 'tessa': 7286, '09:58:27': 7287, 'chet': 7288, 'lam': 7289, 'musketeers': 7290, 'horseshoe': 7291, 'bangladesh': 7292, 'genaro': 7293, 'dangerous': 7294, 'liberator': 7295, 'yonder': 7296, 'orleans': 7297, 'appreciation': 7298, 'folksy': 7299, 'filthy': 7300, 'lucre': 7301, 'sulle': 7302, 'sathya': 7303, 'cohn': 7304, 'ricardo': 7305, 'villalobos': 7306, 'dukes': 7307, 'foreign': 7308, 'affair': 7309, 'hoffman': 7310, 'flake': 7311, 'hearted': 7312, 'slippery': 7313, 'gober': 7314, 'supernaut': 7315, 'armand': 7316, 'helden': 7317, 'crawlspace': 7318, 'eunice': 7319, 'elisa': 7320, 'towel': 7321, 'fins': 7322, 'severe': 7323, 'ealing': 7324, 'helianthushof': 7325, 'hurffville': 7326, 'fools': 7327, 'chalkyitsik': 7328, 'pirate': 7329, 'everson': 7330, 'conchiglie': 7331, 'calipuy': 7332, 'spenard': 7333, 'stars:': 7334, 'co-operative': 7335, 'block': 7336, 'scandinavian': 7337, 'shohola': 7338, 'saturn': 7339, '15:26:11': 7340, 'keyes': 7341, 'summit': 7342, 'courtney': 7343, 'meatball': 7344, 'erica': 7345, 'necromancer': 7346, 'she-devil': 7347, 'shout': 7348, 'andrew': 7349, 'everything': 7350, 'amirbai': 7351, 'karnataki': 7352, 'chamberlain': 7353, 'personality': 7354, 'bhoot': 7355, 'deidre': 7356, 'rosa': 7357, 'oakey': 7358, 'outlaws': 7359, 'sherwood': 7360, 'spinnin': 7361, 'sha': 7362, 'xl': 7363, 'matinee': 7364, 'idol': 7365, '06:30': 7366, 'ambition': 7367, 'catherine': 7368, 'moving': 7369, 'shamrock': 7370, 'handicap': 7371, 'hayvoronsky': 7372, 'powell': 7373, 'equal': 7374, 'affections': 7375, 'seabrook': 7376, 'swiss': 7377, 'ruwanga': 7378, 'samath': 7379, 'blaydon': 7380, 'races': 7381, 'henrieville': 7382, 'jingle': 7383, 'jillian': 7384, 'built': 7385, 'mucho': 7386, 'maltby': 7387, 'automator': 7388, 'unwelcome': 7389, 'rope': 7390, 'device': 7391, 'laurel': 7392, 'aitken': 7393, 'chee': 7394, 'hun': 7395, '4813': 7396, 'hollidaysburg': 7397, 'lambeth': 7398, 'portions': 7399, 'wine-stained': 7400, 'notebook:': 7401, 'essays': 7402, 'baby-sittor': 7403, 'scoop': 7404, 'mediterranean': 7405, 'confederate': 7406, 'denali': 7407, 'ham': 7408, 'isn': 7409, 'canarsie': 7410, 'rockaway': 7411, 'parkway': 7412, 'bennington': 7413, 'varenyky': 7414, 'westernport': 7415, 'pease': 7416, 'porridge': 7417, 'vicious': 7418, 'cottageville': 7419, 'salads': 7420, 'cisco': 7421, 'adler': 7422, 'remains': 7423, '79': 7424, 'dragons': 7425, 'dawning': 7426, 'pillow': 7427, 'boring': 7428, 'sparks': 7429, 'mile': 7430, 'roselle': 7431, 'man:': 7432, 'neil': 7433, 'abode': 7434, 'assassination': 7435, 'jesse': 7436, 'coward': 7437, 'christie': 7438, 'kowanek': 7439, 'pearl': 7440, 'verna': 7441, 'slated': 7442, 'ash': 7443, 'wednesday': 7444, 'hogs': 7445, 'deviled': 7446, 'crab': 7447, 'palmview': 7448, 'plot': 7449, 'scarface': 7450, 'davies': 7451, 'else': 7452, 'balzary': 7453, 'northcote': 7454, 'deathcore': 7455, 'avatar': 7456, 'orchard': 7457, 'greek': 7458, 'madawaska': 7459, 'labworth': 7460, 'ethiopia': 7461, 'louella': 7462, 'goss': 7463, 'kelso': 7464, 'farmington': 7465, 'match': 7466, '07:43:21': 7467, 'concrete': 7468, 'restasurant': 7469, 'pohick': 7470, 'reality:': 7471, 'laws': 7472, 'gulfport': 7473, 'pôchouse': 7474, 'rocksprings': 7475, 'date': 7476, 'cohesive': 7477, 'bellamy': 7478, 'contributed': 7479, 'secondary': 7480, 'ohear': 7481, 'ahbez': 7482, 'shopsins': 7483, 'spartan:': 7484, 'noko': 7485, 'rocca': 7486, 'bidoup': 7487, 'núi': 7488, 'bà': 7489, 'watson': 7490, 'drowning': 7491, 'libros': 7492, 'conflict': 7493, 'sawai': 7494, 'gandharva': 7495, 'sehlabathebe-nationalpark': 7496, '11/18/2018': 7497, 'charming': 7498, 'attractive': 7499, 'priority': 7500, 'techno-industrial': 7501, 'udupi': 7502, 'rave': 7503, 'bourne': 7504, 'findon': 7505, 'chu': 7506, 'philly': 7507, 'weissberg': 7508, 'divine': 7509, 'vinnie': 7510, 'roslin': 7511, 'guts': 7512, 'chopin': 7513, 'iconic:': 7514, 'photographer': 7515, 'dennis': 7516, 'stock': 7517, 'tommie': 7518, 'sunshine': 7519, 'folklore': 7520, 'fields': 7521, 'jtr': 7522, '6/1/2027': 7523, 'lanta': 7524, '97:': 7525, 'desert': 7526, 'legendary': 7527, 'solos': 7528, 'killers': 7529, 'savior': 7530, 'leads': 7531, 'migration': 7532, 'resevation': 7533, 'stle': 7534, '6/21/2035': 7535, 'clarice': 7536, 'charleston': 7537, 'revolutions': 7538, 'doctors': 7539, 'timbers': 7540, 'thug': 7541, 'lordz': 7542, 'trilogy': 7543, 'zamiast': 7544, 'burzy': 7545, 'phunkadelic': 7546, 'mutlu': 7547, 'outside': 7548, 'syndicate': 7549, 'millicent': 7550, 'tad': 7551, 'kinchla': 7552, 'entrevistas': 7553, 'gormenghast': 7554, 'yusef': 7555, 'lateef': 7556, 'ava': 7557, 'raquel': 7558, 'hainesville': 7559, 'brixton': 7560, 'academy': 7561, 'chowder': 7562, 'later': 7563, 'fabri': 7564, 'fibra': 7565, 'aquariums': 7566, 'pyongyang': 7567, 'roches': 7568, 'floating': 7569, 'rambler': 7570, 'coach': 7571, 'cousin': 7572, 'burundi': 7573, 'emmy': 7574, 'rossum': 7575, 'noi': 7576, 'lohan': 7577, 'pleasant': 7578, 'dinnertime': 7579, 'acoustics': 7580, 'admiralty': 7581, 'leigh': 7582, 'nash': 7583, 'reineke': 7584, 'weight': 7585, 'kernersville': 7586, 'powerhouses': 7587, 'orchestrion': 7588, 'triumph': 7589, 'tartine': 7590, 'teleform': 7591, 'ussr': 7592, 'bomb': 7593, 'salami': 7594, 'bastian': 7595, 'collectors': 7596, 'lahore': 7597, 'vega': 7598, 'alta': 7599, 'slender': 7600, 'thread': 7601, 'sligo': 7602, 'industrial': 7603, 'messed': 7604, 'fries': 7605, 'frozen': 7606, 'fabes': 7607, 'ithkar': 7608, 'budapest': 7609, 'beacon': 7610, 'harveys': 7611, 'secretary': 7612, 'interesting': 7613, 'times:': 7614, 'success': 7615, 'geschwisterliebe': 7616, 'chinese': 7617, 'coverage': 7618, 'crepes': 7619, 'tripp': 7620, 'eisen': 7621, 'canta': 7622, 'ducha': 7623, 'emil': 7624, 'gilels': 7625, 'sylvia': 7626, 'plath': 7627, 'deron': 7628, 'fridays': 7629, 'kick': 7630, 'traces': 7631, 'viktor': 7632, 'merjanov': 7633, 'plalist': 7634, 'visjoner': 7635, 'post-punk': 7636, 'vanished': 7637, 'perfume:': 7638, 'murderer': 7639, 'richfield': 7640, 'kenneth': 7641, '\"jethro\"': 7642, 'burns': 7643, 'soundscapes': 7644, '2gether': 7645, 'jade': 7646, 'puget': 7647, 'shrunk': 7648, 'baker’s': 7649, 'keyboard': 7650, 'selma': 7651, 'mcsherrystown': 7652, '21:05:17': 7653, 'tortano': 7654, 'isabella': 7655, 'carly': 7656, 'standard': 7657, 'dawns': 7658, 'merz': 7659, 'pet': 7660, 'cairo': 7661, 'zoo': 7662, 'sandman': 7663, 'neylandville': 7664, 'petree': 7665, 'itsu': 7666, 'capistrano': 7667, 'croquembouche': 7668, 'ayumi': 7669, 'hamasaki': 7670, 'arena': 7671, 'level': 7672, 'tarja': 7673, 'turunen': 7674, 'features': 7675, 'yuvan': 7676, 'shankar': 7677, 'raja': 7678, 'shadowchaser': 7679, 'citizen': 7680, 'edda': 7681, 'semenovich': 7682, 'evolution': 7683, 'mary:': 7684, 'garcia': 7685, 'lot': 7686, 'vinci': 7687, 'code': 7688, 'ircle': 7689, '4/19/2030': 7690, 'elephants': 7691, 'alien': 7692, 'continues': 7693, '1989': 7694, '8/8/2039': 7695, 'ulen': 7696, 'hokendauqua': 7697, 'mongolia': 7698, 'there:': 7699, 'licensed': 7700, 'proud': 7701, 'bigger': 7702, 'beardslee': 7703, 'lanes': 7704, 'jamie': 7705, 'hallie': 7706, 'lavern': 7707, 'nickelsville': 7708, 'geographic': 7709, 'dinosaurs': 7710, 'stanford': 7711, '6/15/2025': 7712, 'onward': 7713, 'onion': 7714, 'sportsdome': 7715, 'bachata': 7716, 'spectres': 7717, 'cuan': 7718, 'dubh': 7719, 'drilseach': 7720, 'robbe': 7721, 'saba': 7722, 'sat': 7723, 'refugee': 7724, 'busco': 7725, 'un': 7726, 'pueblo': 7727, 'shingleton': 7728, 'carlisle': 7729, 'grunge': 7730, 'cleopatra': 7731, 'stratan': 7732, 'masterworks': 7733, 'teenagers': 7734, 'hola': 7735, 'lou:': 7736, 'prom': 7737, 'bowers': 7738, '4/17/2033': 7739, 'ryō': 7740, 'cholame': 7741, 'rebirth': 7742, 'kirk': 7743, 'clásica': 7744, 'todos': 7745, 'dells': 7746, 'tenacious': 7747, 'in:': 7748, 'pick': 7749, 'maalaea': 7750, 'navy': 7751, '31': 7752, 'minutos': 7753, 'porter': 7754, 'germania': 7755, 'porphyry': 7756, 'enough': 7757, 'wrestling': 7758, 'ismol': 7759, '20:44': 7760, 'ryohei': 7761, 'yamamoto': 7762, 'bordertown': 7763, 'potée': 7764, 'ally': 7765, 'kerr': 7766, 'thornville': 7767, 'terrie': 7768, 'hypoluxo': 7769, 'evangeline': 7770, 'medieval': 7771, 'bert': 7772, 'aphex': 7773, 'ira': 7774, 'losco': 7775, 'jethro': 7776, 'timer': 7777, 'augustus': 7778, 'utamaro': 7779, 'intense': 7780, 'studying': 7781, 'prediction': 7782, 'camdeboo-nationalpark': 7783, 'freshwater': 7784, 'liza': 7785, 'oumarova': 7786, 'casting': 7787, 'crowns': 7788, 'spades': 7789, 'hurts': 7790, 'acta': 7791, 'mathematicae': 7792, 'applicatae': 7793, 'sinica': 7794, 'sonic': 7795, 'saintly': 7796, 'switch': 7797, 'butch': 7798, 'trucks': 7799, 'tanintharyi': 7800, 'cuisines': 7801, 'khujo': 7802, 'keachi': 7803, 'fondue': 7804, 'thompsontown': 7805, 'karen': 7806, 'datil': 7807, 'minnie': 7808, 'riperton': 7809, '05:51:52': 7810, 'millions': 7811, 'mythology': 7812, 'wiggs': 7813, 'skystone': 7814, 'milwaukee': 7815, 'ever': 7816, 'bennett': 7817, 'mothstorm': 7818, 'vintage': 7819, '74': 7820, '345': 7821, 'clue': 7822, 'chance': 7823, 'lifetime': 7824, 'melba': 7825, 'bullets': 7826, 'defense': 7827, 'hubbell': 7828, 'baconton': 7829, 'smith-9th': 7830, 'conspiracy': 7831, 'mina': 7832, 'caputo': 7833, 'brotherly': 7834, 'verdi': 7835, 'becomes': 7836, 'punishment': 7837, 'suburbia': 7838, 'wilde': 7839, 'stansbury': 7840, 'kokhanok': 7841, 'tsubasa': 7842, 'imai': 7843, 'stu': 7844, 'troops': 7845, 'crossover': 7846, 'battlement': 7847, 'mesa': 7848, 'wxhexeditor': 7849, 'ansonia': 7850, 'chymical': 7851, 'laura': 7852, 'wrigley': 7853, 'viaje': 7854, 'copperpot': 7855, 'cartel': 7856, 'rascals': 7857, 'spooks': 7858, 'liang': 7859, 'wern': 7860, 'fook': 7861, 'frampton': 7862, 'wall': 7863, 'lifelong': 7864, 'ambitions': 7865, 'leo': 7866, 'impressions': 7867, 'bless': 7868, 'adeline': 7869, 'opium': 7870, 'gone': 7871, 'stracke': 7872, 'jefferson': 7873, 'expansion': 7874, 'a-hunting': 7875, 'stat': 7876, 'guru': 7877, 'osage': 7878, 'infidels': 7879, 'learning': 7880, 'rev-raptor': 7881, 'lothian': 7882, 'anatoljewitsch': 7883, 'kurjochin': 7884, 'cracked': 7885, 'fruit': 7886, 'olpe': 7887, 'column': 7888, 'strolghino': 7889, 'pilson': 7890, 'cope': 7891, 'loyalhanna': 7892, '7/13/2036': 7893, 'stefanie': 7894, 'space:': 7895, 'blob': 7896, 'climax': 7897, 'voice': 7898, 'kiara': 7899, 'manual': 7900, 'adams': 7901, 'vice': 7902, 'loathing': 7903, 'campaign': 7904, '’72': 7905, 'jarbidge': 7906, 'topinabee': 7907, 'housemaid': 7908, 'jardine': 7909, 'burr': 7910, 'corcovado': 7911, 'goof': 7912, 'tsūzetsu': 7913, 'commitments': 7914, 'layhigh': 7915, 'runkaus': 7916, 'leong': 7917, 'emanuel': 7918, 'kiriakou': 7919, 'kisaki': 7920, 'generación': 7921, 'rbd': 7922, 'vivo': 7923, 'magician': 7924, 'zahir': 7925, 'howaida': 7926, 'sting': 7927, 'elf': 7928, 'emoji': 7929, '10/4/2021': 7930, 'heartland': 7931, 'on-line': 7932, 'integer': 7933, 'sequences': 7934, 'jaula': 7935, 'oro': 7936, 'phineas': 7937, 'redux': 7938, 'ce': 7939, 'cher': 7940, 'intrus': 7941, 'cheaper': 7942, 'dozen': 7943, 'mimi': 7944, 'biscuit': 7945, 'factory': 7946, 'hendthighelbedi': 7947, 'postman': 7948, 'rings': 7949, 'fennesz': 7950, 'wrote': 7951, 'yang': 7952, 'hyun': 7953, 'seok': 7954, 'deersville': 7955, 'utley': 7956, 'tsongas': 7957, 'norma': 7958, 'jean': 7959, 'hasan': 7960, 'saltik': 7961, 'reflection': 7962, 'lindas': 7963, 'mundo': 7964, 'raytown': 7965, 'casserole': 7966, 'karin': 7967, 'dreijer': 7968, 'andersson': 7969, 'hendley': 7970, 'boone': 7971, '10:24': 7972, 'stalinism': 7973, 'bohemia': 7974, 'epiphany': 7975, 'marguerite': 7976, 'della': 7977, 'iene': 7978, 'miene': 7979, 'mutte': 7980, 'screaming': 7981, 'staircase': 7982, 'time:': 7983, 'nameless': 7984, 'payette': 7985, 'maxime': 7986, '105th': 7987, 'dresden': 7988, 'takei': 7989, 'empires': 7990, 'faerûn': 7991, 'pendleton': 7992, 'pepe': 7993, 'aguilar': 7994, 'tropézienne': 7995, 'exiles': 7996, 'rest': 7997, 'nearly': 7998, 'nashville': 7999, 'listening': 8000, 'mutation': 8001, 'deathsmiles': 8002, 'hooven': 8003, 'lithuania': 8004, 'strike': 8005, 'geminism': 8006, 'sara': 8007, 'ortiz': 8008, 'dickinsonian': 8009, 'male': 8010, 'pornography:': 8011, 'discrimination': 8012, 'eve': 8013, 'ejigayehu': 8014, 'shibabaw': 8015, 'keita': 8016, 'tachibana': 8017, 'howling': 8018, 'jamesedition': 8019, 'classified': 8020, 'fertile': 8021, 'ground': 8022, 'dalles': 8023, 'kathleen': 8024, 'brianna': 8025, 'miguelito': 8026, 'charting': 8027, 'hollows': 8028, 'boogaloo': 8029, 'vegetarian': 8030, 'petar': 8031, 'exell': 8032, 'shanghaï': 8033, 'almost': 8034, 'toxic': 8035, 'avenger': 8036, 'dared': 8037, 'tapper': 8038, 'zukie': 8039, 'belongs': 8040, 'eyota': 8041, 'bg': 8042, 'knocc': 8043, 'sundown:': 8044, 'retreat': 8045, 'cinderella': 8046, 'trevor': 8047, 'mcnevan': 8048, 'honduras': 8049, 'daddy': 8050, 'myth': 8051, 'si': 8052, 'hubiera': 8053, 'conocido': 8054, 'haidar': 8055, 'salim': 8056, 'punta': 8057, 'gorda': 8058, 'orlovista': 8059, 'armen': 8060, 'movsessian': 8061, 'skepta': 8062, 'baden': 8063, 'jesper': 8064, 'kyd': 8065, 'grime': 8066, 'instrumentals': 8067, 'psychologist': 8068, 'myers': 8069, 'marva': 8070, 'biscay': 8071, 'needmore': 8072, 'maisry': 8073, 'heaven:': 8074, 'santana': 8075, 'performs': 8076, 'jes': 8077, 'brieden': 8078, 'eudaemonic': 8079, 'abby': 8080, 'jip': 8081, 'quiet': 8082, 'kamen': 8083, 'rider': 8084, 'ooo': 8085, 'wonderful:': 8086, 'shogun': 8087, 'core': 8088, 'medals': 8089, 'streaming': 8090, 'leoti': 8091, '09:32:06': 8092, 'moncove': 8093, 'highest': 8094, 'bastards': 8095, 'seagraves': 8096, 'rome': 8097, 'hawkins': 8098, 'barchetta': 8099, 'lemon': 8100, 'jared': 8101, 'hasselhoff': 8102, 'halfbreed': 8103, 'cindy': 8104, 'munia': 8105, 'hotline': 8106, 'jarreau': 8107, 'nicer': 8108, 'pages': 8109, 'shame': 8110, 'blasko': 8111, 'neffs': 8112, 'hitchland': 8113, 'fahl': 8114, 'angelita': 8115, 'susan': 8116, 'ashlee': 8117, 'argumentative': 8118, 'penalty': 8119, 'tawakoni': 8120, 'italy': 8121, 'thy': 8122, 'neighbor': 8123, 'druss': 8124, 'muireann': 8125, 'nic': 8126, 'amhlaoibh': 8127, 'team': 8128, 'cover': 8129, 'ammonia': 8130, 'volga': 8131, 'lots': 8132, 'asian': 8133, 'bradford': 8134, '8/4/2024': 8135, 'cevin': 8136, 'masada': 8137, 'unknown': 8138, 'whiskers:': 8139, 'favourite': 8140, 'nursery': 8141, 'rhymes': 8142, 'sturgis': 8143, 'operación': 8144, 'bikini': 8145, 'hynes': 8146, 'mercenary': 8147, '04:36:28': 8148, 'jermaine': 8149, 'fagan': 8150, 'vaughan': 8151, 'creamery': 8152, 'carnot': 8153, '2112': 8154, 'owen': 8155, 'ashland': 8156, 'brilliant': 8157, 'tragic': 8158, 'hog': 8159, 'nordland': 8160, 'swing': 8161, '99': 8162, 'snobs': 8163, 'daisy': 8164, 'voisin': 8165, 'gutting': 8166, 'couffignal': 8167, 'didn': 8168, 'nobody': 8169, 'structured': 8170, 'fax': 8171, 'file': 8172, 'chickens': 8173, 'rocket': 8174, 'chowchilla': 8175, 'durant': 8176, 'zen:': 8177, 'katz': 8178, 'pot': 8179, 'doughnuts': 8180, 'tukaram': 8181, 'winnfield': 8182, 'fei': 8183, 'yu': 8184, 'ching': 8185, 'ben': 8186, 'seeing': 8187, 'mccartney': 8188, 'salinas': 8189, 'mandino': 8190, 'hey': 8191, 'ye': 8192, 'waking': 8193, 'muddy': 8194, 'fisn': 8195, 'timberville': 8196, 'saviour': 8197, 'fortus': 8198, '2/25/2025': 8199, 'holstein': 8200, 'peaceful': 8201, 'ultra': 8202, 'turks': 8203, 'caicos': 8204, 'keystone': 8205, 'kops': 8206, '04:08:11': 8207, 'forks': 8208, 'mailroom:': 8209, 'strange': 8210, 'civilization': 8211, 'engadget': 8212, 'regis': 8213, 'turkmenistan': 8214, 'vermicelli': 8215, 'tar:': 8216, 'midwest': 8217, 'childhood': 8218, 'jono': 8219, 'morton': 8220, 'feldman': 8221, 'quartet': 8222, 'croissant': 8223, 'russel': 8224, 'walder': 8225, 'principle': 8226, 'hope': 8227, 'fare': 8228, 'well:': 8229, 'celebrating': 8230, 'grateful': 8231, 'gem': 8232, 'gamaliel': 8233, 'melly': 8234, 'warheart': 8235, 'mole': 8236, 'roxy': 8237, 'drum': 8238, 'mayya': 8239, '28th': 8240, 'everlast': 8241, 'yumi': 8242, 'matsuzawa': 8243, 'shawnna': 8244, 'trifecta': 8245, 'webber': 8246, 'raphael': 8247, 'rabello': 8248, 'cornelia': 8249, 'austin': 8250, '09:42': 8251, 'encino': 8252, 'meatcake': 8253, 'santa': 8254, 'claus': 8255, 'caddo': 8256, 'willie': 8257, 'corrina': 8258, 'envoy': 8259, 'lucifer': 8260, 'friendship': 8261, 'panther': 8262, 'yuki': 8263, 'koyanagi': 8264, 'ashford': 8265, 'eastport': 8266, '2001': 8267, 'dungeonmaster': 8268, 'whispering': 8269, 'willows': 8270, 'josefa': 8271, 'branford': 8272, 'vicki': 8273, 'lousy': 8274, 'stehekin': 8275, '1/1/2018': 8276, 'victoria': 8277, 'banks': 8278, 'edge': 8279, 'alice:': 8280, 'true': 8281, 'wilko': 8282, 'attic': 8283, 'format': 8284, 'maze': 8285, 'looks': 8286, 'primus': 8287, 'solitude': 8288, 'districts': 8289, 'cyclists': 8290, 'aransas': 8291, 'false': 8292, 'lamar': 8293, 'hoonah': 8294, 'thrash': 8295, 'bamboccioni': 8296, 'maki': 8297, 'onaga': 8298, 'maksim': 8299, 'firebrand': 8300, 'richards': 8301, 'kerry': 8302, 'zorro': 8303, '3/26/2023': 8304, 'toward': 8305, 'nba': 8306, 'ahmad': 8307, 'rashad': 8308, 'revived': 8309, 'visual': 8310, 'sensory': 8311, 'owl': 8312, 'mtv:': 8313, 'uncensored': 8314, 'revolution': 8315, 'jang': 8316, 'nara': 8317, 'samira': 8318, 'said': 8319, 'badass': 8320, 'voyages': 8321, 'pressure': 8322, 'cracks': 8323, 'cali': 8324, 'juanes': 8325, 'xena:': 8326, 'olympus': 8327, 'scarabaeus': 8328, 'donna': 8329, 'millvale': 8330, 'valery': 8331, 'kipelov': 8332, 'apparatus': 8333, 'halibut': 8334, 'nightcall': 8335, 'fever:': 8336, '07:08:00': 8337, 'kunnon': 8338, 'syy': 8339, 'kakko': 8340, 'nightwork': 8341, 'hilliard': 8342, 'tsingy': 8343, 'bemaraha': 8344, 'kingsley': 8345, 'letty': 8346, 'fox:': 8347, 'breakers': 8348, 'roar': 8349, 'tolmatschowa': 8350, 'schwestern': 8351, 'tube': 8352, 'teriazume': 8353, 'sixty': 8354, 'abhijeet': 8355, 'bhattacharya': 8356, 'thorns': 8357, 'spell': 8358, 'jenifer': 8359, 'somis': 8360, 'cena': 8361, 'elegante': 8362, 'frl': 8363, 'menke': 8364, 'lure': 8365, 'mask': 8366, 'lily': 8367, 'deaf': 8368, 'murphy': 8369, 'meltdown': 8370, 'destruction': 8371, 'coti': 8372, 'agincourt': 8373, 'gurdas': 8374, 'maan': 8375, 'peaks': 8376, 'layne': 8377, 'staley': 8378, 'dhafer': 8379, 'youssef': 8380, 'vans': 8381, 'compilation': 8382, 'cosby': 8383, 'cosnarati:': 8384, 'emergency': 8385, 'investigating': 8386, 'afterlife': 8387, 'neidich': 8388, 'soldier': 8389, 'gardot': 8390, 'mcguinness': 8391, 'contigo': 8392, 'distancia': 8393, 'eddie’s': 8394, 'fats': 8395, 'waller': 8396, 'kitchener': 8397, 'soudan': 8398, 'histoire': 8399, 'dico': 8400, 'doc': 8401, 'savage:': 8402, 'bronze': 8403, 'ken': 8404, 'zwanzig': 8405, 'zwölf': 8406, 'rapid': 8407, 'muscle': 8408, 'dekalb': 8409, 'knocked': 8410, 'loaded': 8411, 'pickled': 8412, 'cucumber': 8413, 'movietimes': 8414, 'nao': 8415, 'kawakita': 8416, '7/10/2023': 8417, 'documents': 8418, 'bickler': 8419, 'prophet': 8420, 'life:': 8421, 'kill': 8422, 'parent': 8423, 'iv:': 8424, 'pimpernel': 8425, 'muffuletta': 8426, 'shada': 8427, 'hassoun': 8428, 'oriel': 8429, 'allison': 8430, 'hungarian': 8431, 'exorcising': 8432, 'amityville:': 8433, 'escapes': 8434, 'revelations': 8435, 'least': 8436, 'comeback': 8437, 'willow': 8438, 'chatyrkul': 8439, 'shoots': 8440, 'maimi': 8441, 'yajima': 8442, 'thesis': 8443, 'choper': 8444, 'gilson': 8445, 'tactics': 8446, 'easel': 8447, 'william': 8448, 'estonia': 8449, 'currents': 8450, 'editions': 8451, 'christianity': 8452, 'sanjeev': 8453, 'abhyankar': 8454, 'cara': 8455, 'dios': 8456, 'wooly': 8457, 'apollo': 8458, 'branch': 8459, 'cherwell': 8460, 'boathouse': 8461, 'unarchigal': 8462, 'madlib': 8463, 'invazion': 8464, 'prog': 8465, 'monsters': 8466, 'transmission': 8467, 'wadsworth': 8468, 'janie': 8469, 'rat': 8470, 'trips:': 8471, 'treasury': 8472, 'geir': 8473, 'jenssen': 8474, 'chart': 8475, 'throb': 8476, 'katherine': 8477, 'pokémon:': 8478, 'mastermind': 8479, 'mirage': 8480, 'othappu': 8481, 'tsidii': 8482, 'loka': 8483, 'reasons': 8484, 'coersion': 8485, 'parable': 8486, 'sower': 8487, 'govere': 8488, 'anochecer': 8489, 'urbano': 8490, 'kearney': 8491, 'gad': 8492, 'elbaz': 8493, 'borys': 8494, 'ljatoschynskyj': 8495, 'aroostook': 8496, 'alfonzo': 8497, 'larrain': 8498, '1995': 8499, 'scouse': 8500, 'git': 8501, 'contre': 8502, 'arsène': 8503, 'lupin': 8504, 'desire': 8505, 'creeper': 8506, 'laid': 8507, 'yukiko': 8508, 'iwai': 8509, 'violet': 8510, 'dianne': 8511, 'ripper': 8512, 'park-beach': 8513, '116th': 8514, 'soupe': 8515, 'outer': 8516, 'licence': 8517, 'renewed': 8518, 'martha': 8519, 'unalaska': 8520, 'bebob': 8521, 'actrices': 8522, 'ruffin': 8523, 'cannelloni': 8524, 'bynum': 8525, '09:59': 8526, 'kjetil': 8527, 'vidar': 8528, 'haraldstad': 8529, 'listas': 8530, 'hahntown': 8531, 'annette': 8532, 'lower': 8533, 'hundred-foot': 8534, 'wanda': 8535, 'hydration': 8536, 'majesty': 8537, 'lakeview': 8538, 'flesh': 8539, 'addicted': 8540, 'hanna': 8541, 'sjedokowa': 8542, 'lenin': 8543, 'savage': 8544, 'herbie': 8545, 'hangtown': 8546, 'jagual': 8547, 'fool': 8548, 'khwaja': 8549, 'ghulam': 8550, 'farid': 8551, 'knierim': 8552, 'insert': 8553, 'command': 8554, 'koi': 8555, 'senkyo': 8556, 'kristina': 8557, 'teresa': 8558, 'delta': 8559, '42': 8560, 'marcia': 8561, 'carolus': 8562, 'oregonia': 8563, 'alexandrovich': 8564, 'courting': 8565, 'squall': 8566, 'latina': 8567, 'kabhi': 8568, 'jo': 8569, 'baadal': 8570, 'barse': 8571, 'ruth': 8572, 'begums': 8573, 'thugs': 8574, 'mughals': 8575, 'favoretta': 8576, 'soapsuds': 8577, 'sapheads': 8578, 'lydia': 8579, 'mixtape': 8580, 'brando': 8581, '19th': 8582, 'ruins': 8583, 'addition': 8584, 'barre': 8585, 'chettathi': 8586, 'manning': 8587, 'wynonna:': 8588, 'mea': 8589, 'culpa': 8590, 'rahim': 8591, 'shah': 8592, 'bumble': 8593, 'bee': 8594, 'stoddard': 8595, 'olton': 8596, 'het': 8597, 'liefde': 8598, 'gaat': 8599, 'brush': 8600, 'hilt': 8601, 'belhaven': 8602, 'sonning': 8603, 'conflicts': 8604, 'carman': 8605, 'whitebrook': 8606, 'harper': 8607, 'seattle': 8608, 'rakim': 8609, '1980': 8610, 'deed': 8611, 'paksenarrion': 8612, '12\"': 8613, 'mixes': 8614, 'weapon': 8615, 'telepathic': 8616, 'experiences': 8617, 'baladas': 8618, 'románticas': 8619, 'breathless': 8620, 'atlas': 8621, 'noveskey': 8622, 'dara': 8623, 'edwyn': 8624, 'gladiators': 8625, 'kavanaughs': 8626, 'britpop': 8627, 'etc': 8628, 'begonias': 8629, 'entrenar': 8630, 'aaliyah': 8631, 'ina': 8632, 'eulogy': 8633, 'stray': 8634, 'rock:': 8635, 'jumbo': 8636, 'ayr': 8637, 'glamour:': 8638, 'unexpected': 8639, 'mikami': 8640, 'cyclone': 8641, 'demi-gods': 8642, 'semi-devils': 8643, 'rejoicing': 8644, 'anson': 8645, 'hu': 8646, 'sippie': 8647, 'wallace': 8648, 'showtime': 8649, 'spinna': 8650, '03:44': 8651, 'demotte': 8652, '1914–1918': 8653, 'liubi': 8654, 'farah': 8655, 'asyikin': 8656, 'binti': 8657, 'zulkifli': 8658, 'totsuzen': 8659, 'falomir': 8660, 'perez': 8661, 'prado': 8662, 'banana': 8663, 'ewen': 8664, 'brittney': 8665, 'belgium': 8666, 'twins': 8667, 'ours': 8668, 'bf': 8669, 'perdu': 8670, 'prosser': 8671, 'mrs': 8672, 'woodward': 8673, 'atlantis': 8674, 'terre': 8675, 'engloutie': 8676, 'paddy': 8677, 'reilly': 8678, 'occoquan': 8679, 'mineola': 8680, 'willi': 8681, 'tall': 8682, 'stranger': 8683, 'downey': 8684, 'barnum': 8685, 'humphrey': 8686, 'windber': 8687, '365': 8688, 'tranquility': 8689, 'mantler': 8690, 'smear': 8691, 'putesky': 8692, 'drama': 8693, 'repeating': 8694, 'ledger:': 8695, 'beautiful': 8696, 'choucroute': 8697, 'ruskin': 8698, 'jetta': 8699, 'lottery': 8700, 'nokko': 8701, 'opération': 8702, 'tooth': 8703, 'skaggs': 8704, 'coxs': 8705, 'vatican': 8706, 'checkmate': 8707, 'homme': 8708, 'ambler': 8709, '01:19:00': 8710, 'revolución': 8711, 'burst': 8712, 'benjamin': 8713, 'darvill': 8714, 'booker': 8715, 'kanon': 8716, 'wakeshima': 8717, 'scottish': 8718, 'rencor': 8719, 'terrors': 8720, 'lit': 8721, 'teahouse': 8722, 'defined': 8723, 'mahatma': 8724, 'lomas': 8725, 'ledbury': 8726, 'ajoy': 8727, 'chakrabarty': 8728, 'papa': 8729, 'bue': 8730, 'chelsea': 8731, 'aj': 8732, 'carothers': 8733, 'lodge': 8734, 'alkabli': 8735, 'brusly': 8736, 'limberlost': 8737, 'knows': 8738, 'grigory': 8739, 'leps': 8740, 'vegetables': 8741, 'pharrell': 8742, 'glacier': 8743, 'linda': 8744, 'strawberry': 8745, 'vera': 8746, 'session': 8747, 'elements': 8748, 'remixed': 8749, 'apostolos': 8750, 'nikolaidis': 8751, 'colt': 8752, 'winchester': 8753, 'gould': 8754, 'capicollo': 8755, 'kit': 8756, 'carson': 8757, 'ilene': 8758, 'clarke': 8759, 'harms': 8760, 'judas': 8761, 'banc': 8762, 'd’arguin': 8763, 'runaljod': 8764, 'gap': 8765, 'var': 8766, 'ginnunga': 8767, 'ak-suu': 8768, 'complex': 8769, 'beth': 8770, 'nielsen': 8771, 'thirayum': 8772, 'theeravum': 8773, 'strays': 8774, 'parkers': 8775, '07:08:02': 8776, 'jarzombek': 8777, 'dedicated': 8778, 'nimal': 8779, 'mendis': 8780, 'nothin': 8781, 'dahmer': 8782, 'jonathon': 8783, 'pembina': 8784, 'gorge': 8785, 'manatee': 8786, 'conehatta': 8787, 'sutphin': 8788, 'blvd': 8789, 'ballantrae': 8790, 'inning': 8791, 'waxhaw': 8792, 'daltrey': 8793, '08:56:29': 8794, 'brief': 8795, 'funtwo': 8796, 'rileys': 8797, 'premiering': 8798, 'slang': 8799, 'unconventional': 8800, 'worthy': 8801, 'schultz': 8802, 'brats': 8803, 'battalions': 8804, 'arista': 8805, 'connick': 8806, 'brasileiro': 8807, 'wyandotte': 8808, 'vikki': 8809, 'fat': 8810, 'duck': 8811, 'goddess': 8812, 'rollins': 8813, 'pillars': 8814, 'wisdom': 8815, 'verano': 8816, 'jour': 8817, 'dans': 8818, 'notre': 8819, 'vie': 8820, 'trapaholics': 8821, 'dakus': 8822, 'vinson': 8823, 'graniteville': 8824, 'abolition': 8825, 'edinburgh': 8826, 'adriana': 8827, 'hallowell': 8828, 'ichibyōgoto': 8829, 'scorpio': 8830, 'illusion': 8831, 'novena': 8832, 'nocturn': 8833, 'custar': 8834, 'luray': 8835, 'uruguay': 8836, 'amir': 8837, 'boating': 8838, 'epte': 8839, 'freddie': 8840, 'freeloader': 8841, 'doris': 8842, 'tulsa': 8843, 'shown': 8844, 'iran': 8845, 'sleepytime': 8846, 'thames': 8847, 'shutdown': 8848, 'paedophilia:': 8849, 'georgetown': 8850, 'mater': 8851, 'ottumwa': 8852, 'limits': 8853, 'commit': 8854, 'wauregan': 8855, 'plpay': 8856, 'collision': 8857, 'umbrellas': 8858, 'cherbourg': 8859, 'alberton': 8860, 'stallion': 8861, 'rockies': 8862, 'bellechester': 8863, 'derose': 8864, 'nicholasville': 8865, 'milian': 8866, 'johto': 8867, 'journeys': 8868, 'xiang': 8869, 'crossgenesis': 8870, 'julia': 8871, 'fordham': 8872, 'cannabis': 8873, 'schlitt': 8874, 'doves': 8875, 'pythons': 8876, 'indifferent': 8877, 'henrie': 8878, 'mutuku': 8879, 'entfesselt': 8880, 'glimpses': 8881, 'patriot': 8882, 'pencil': 8883, 'mustache': 8884, 'moribund': 8885, 'burgermeister': 8886, 'shades': 8887, 'fascility': 8888, 'philosopher’s': 8889, 'war:': 8890, 'kentuckians': 8891, 'mamie': 8892, 'maria': 8893, 'fisk': 8894, 'av-69th': 8895, 'gilgamesh': 8896, 'bagnell': 8897, '5th': 8898, 'manhasset': 8899, 'heresy': 8900, 'choir': 8901, '12:26': 8902, 'presskopf': 8903, 'choate': 8904, '16th': 8905, 'twenty-first': 8906, 'beatrice': 8907, 'letters': 8908, 'demon': 8909, 'invasion': 8910, 'mojave': 8911, 'phone': 8912, 'booth': 8913, 'iceland': 8914, 'danville': 8915, 'suitcase': 8916, 'toby': 8917, 'nemiciamici': 8918, 'trunes': 8919, 'soultaker': 8920, 'ridel': 8921, 'congeniality': 8922, 'borland': 8923, 'noel': 8924, 'frost': 8925, 'robyn': 8926, 'martinez': 8927, 'maude': 8928, 'yameen': 8929, 'keke': 8930, 'wyatt': 8931, 'lolo': 8932, 'dock': 8933, 'fogata': 8934, 'sandoval': 8935, 'kamil': 8936, 'rustam': 8937, 'flow': 8938, 'morgan’s': 8939, 'balko': 8940, 'livingston': 8941, 'goéland': 8942, '12/9/2039': 8943, 'caverns': 8944, 'sappho': 8945, 'craft': 8946, 'northvale': 8947, 'masashi': 8948, 'hamauzu': 8949, 'actress': 8950, 'janet': 8951, 'paschal': 8952, 'personal': 8953, 'dido': 8954, '“chirping”': 8955, 'crickets': 8956, 'foreclosure': 8957, 'walpole': 8958, 'econfina': 8959, 'whitehouse': 8960, 'lauryn': 8961, 'web': 8962, 'waipio': 8963, 'enduser': 8964, 'badonviller': 8965, 'marsch': 8966, 'bertha': 8967, 'neurotoxicology': 8968, 'principii': 8969, 'evangelikum': 8970, 'liquor': 8971, 'manos': 8972, 'hadjidakis': 8973, 'ifind': 8974, 'tatar': 8975, 'bunky': 8976, 'ide': 8977, 'since': 8978, 'leaves': 8979, 'i:': 8980, 'jeffrey': 8981, 'pagosa': 8982, 'cusine': 8983, '12:': 8984, 'managing': 8985, 'anston': 8986, 'kaaawa': 8987, 'merlin': 8988, 'maiden': 8989, 'danced': 8990, 'schools': 8991, 'ringold': 8992, 'ducas': 8993, 'ringo': 8994, 'sheena': 8995, 'krondor': 8996, 'double': 8997, 'shiina': 8998, 'pitch': 8999, 'brigade': 9000, 'ruled': 9001, 'britannia': 9002, 'deacon': 9003, 'vasilis': 9004, 'tsitsanis': 9005, 'lipstick': 9006, 'vogue': 9007, 'opus': 9008, 'hadon': 9009, 'opar': 9010, 'detroit': 9011, 'mulligan': 9012, 'stew': 9013, 'fisher': 9014, 'changes:': 9015, 'trentwood': 9016, 'honourable': 9017, 'band-e': 9018, 'chan': 9019, 'whee': 9020, 'cottondale': 9021, 'monks': 9022, 'thelema': 9023, 'rumyantsev': 9024, 'beatmaster': 9025, 'dubach': 9026, 'sandra': 9027, 'kay': 9028, 'slay': 9029, 'strumpet': 9030, 'douthat': 9031, 'crowd:': 9032, 'seduced': 9033, 'crosswind': 9034, 'pee': 9035, 'wee': 9036, 'steward': 9037, 'adieu': 9038, 'arsenault': 9039, 'couple': 9040, 'teeth': 9041, 'paloma': 9042, 'negra': 9043, 'varney': 9044, 'rudolf': 9045, 'schenker': 9046, 'lamp': 9047, 'inspector': 9048, 'undressed': 9049, 'cure': 9050, 'bandas': 9051, 'sonoras': 9052, 'battlestations:': 9053, 'rainelle': 9054, 'chattahoochee': 9055, 'annihilated': 9056, 'steamboat': 9057, 'zec': 9058, 'mitchinamecus': 9059, 'caroline': 9060, '56': 9061, 'pond': 9062, 'inventions': 9063, 'bleed': 9064, 'ishmon': 9065, 'bracey': 9066, 'mum': 9067, 'nets': 9068, 'spine': 9069, 'surfs': 9070, 'psycho': 9071, 'renaldo': 9072, 'lapuz': 9073, 'mccready': 9074, 'prentice': 9075, 'did': 9076, 'highs': 9077, 'mid-sixties': 9078, 'repeat': 9079, 'matilda': 9080, 'gibbs': 9081, 'calistoga': 9082, 'side:': 9083, 'lou': 9084, 'stunt': 9085, 'citadel': 9086, 'purcell': 9087, 'tenderfoot': 9088, 'morrow': 9089, 'even': 9090, 'jebel': 9091, '4/4/2036': 9092, 'nichiren': 9093, 'mōko': 9094, 'daishūrai': 9095, 'zombieland': 9096, 'ah': 9097, 'searchlights': 9098, 'natasja': 9099, 'giant': 9100, 'energic': 9101, 'trottole': 9102, 'based': 9103, 'fidel': 9104, 'nadal': 9105, 'hows': 9106, 'kendall': 9107, 'villotta': 9108, 'award': 9109, 'charlene': 9110, 'hagar': 9111, 'resistance': 9112, 'kegs': 9113, '37': 9114, 'switzer': 9115, 'breaux': 9116, 'nikolayev': 9117, 'elnora': 9118, 'katina': 9119, 'josefina': 9120, 'percy': 9121, 'winfield': 9122, 'chariot': 9123, 'halifax': 9124, 'disaster': 9125, 'wauseon': 9126, 'division': 9127, 'bbc': 9128, 'recordings': 9129, 'clafoutis': 9130, 'selinsgrove': 9131, 'louse': 9132, 'elise': 9133, 'ravensdale': 9134, 'nails': 9135, 'hermaphrodite': 9136, '20:38': 9137, 'holi': 9138, 'frankfort': 9139, 'lollipop': 9140, 'balinese': 9141, 'comunas': 9142, 'honigberger': 9143, 'desserts': 9144, 'ashmore': 9145, 'burn': 9146, 'lace': 9147, 'whiskey': 9148, 'unnaturals': 9149, '213': 9150, 'pasqual': 9151, 'ngola': 9152, 'ritmos': 9153, 'li': 9154, 'yuchun': 9155, 'glaring': 9156, 'oblivion': 9157, 'garrochales': 9158, 'thick': 9159, 'phrazes': 9160, 'conduct': 9161, 'major': 9162, 'maxim': 9163, 'loyalty': 9164, 'fernwood': 9165, 'offers': 9166, 'certainty': 9167, 'shirley': 9168, 'aviatrice': 9169, 'dwarf': 9170, 'cosmos': 9171, 'inquiry': 9172, 'horn': 9173, 'musgrave': 9174, 'barnard': 9175, 'ora': 9176, 'floors': 9177, 'noche': 9178, 'chicas': 9179, 'pe': 9180, 'jboss': 9181, 'enterprise': 9182, 'soa': 9183, 'platform': 9184, 'tingley': 9185, 'angelus': 9186, 'provinciale': 9187, 'peninsula': 9188, 'chab': 9189, 'welch': 9190, 'dales': 9191, 'sanger': 9192, 'tire': 9193, 'lofgreen': 9194, 'blau': 9195, 'mindy': 9196, 'liégeois': 9197, 'is:': 9198, 'marxism': 9199, 'oppression': 9200, 'fra': 9201, 'mols': 9202, 'skagen': 9203, 'iii:': 9204, 'drop': 9205, 'joi': 9206, 'chua': 9207, 'teterville': 9208, 'georgiev': 9209, 'kalica': 9210, 'bio': 9211, 'carrousel': 9212, 'blobby': 9213, 'judgment': 9214, 'day:': 9215, 'farragut': 9216, 'show-ya': 9217, 'imogen': 9218, 'heap': 9219, 'crush': 9220, 'blush': 9221, 'dust': 9222, 'sheehan': 9223, 'tallgrass': 9224, 'unfinished': 9225, 'bradner': 9226, 'bonita': 9227, 'voce': 9228, 'photographic': 9229, 'aioli': 9230, 'geese': 9231, 'joeri': 9232, 'basjmet': 9233, 'wrightstown': 9234, 'stairs': 9235, 'mowrystown': 9236, 'informix': 9237, 'wingz': 9238, 'estela': 9239, 'split': 9240, 'difference': 9241, 'hammett': 9242, 'garrison': 9243, 'morten': 9244, 'harket': 9245, 'coon': 9246, 'malcom': 9247, 'satanas': 9248, 'legions': 9249, 'minto': 9250, 'barrett': 9251, 'news-press': 9252, 'ek': 9253, 'boond': 9254, 'ishq': 9255, 'phenomenological': 9256, 'brew': 9257, 'graveyard': 9258, 'moon:': 9259, 'yellowstone': 9260, '4-hour': 9261, 'workweek': 9262, 'orwell': 9263, 'mustoe': 9264, 'cienega': 9265, 'vyechnyy': 9266, 'strannik': 9267, 'age:': 9268, 'stolen': 9269, 'throne': 9270, 'riverfront': 9271, 'banking': 9272, 'violence': 9273, 'inner': 9274, 'pagan': 9275, 'dinosaur': 9276, 'harder': 9277, 'orgullo': 9278, 'guyana': 9279, 'tabor': 9280, 'gratin': 9281, 'sahuarita': 9282, 'solution': 9283, 'polka': 9284, 'medley': 9285, 'whisperer': 9286, 'horton': 9287, 'preston': 9288, 'sample': 9289, 'inca': 9290, 'beside': 9291, 'arkport': 9292, 'antelope': 9293, 'spots': 9294, 'urbanette': 9295, 'crow:': 9296, 'gaudino': 9297, 'phinally': 9298, 'phamous': 9299, 'maisonette': 9300, 'cotati': 9301, 'shell:': 9302, 'godmusic': 9303, 'aguila': 9304, 'jessica': 9305, 'delfino': 9306, 'complex:': 9307, 'invades': 9308, 'everyday': 9309, 'introducing': 9310, 'rahman': 9311, 'jacobsburg': 9312, 'po': 9313, 'tofu': 9314, 'bretton': 9315, 'history:': 9316, 'survey': 9317, 'gn': 9318, 'pontypool': 9319, 'changes': 9320, 'stops': 9321, 'springtime': 9322, 'amnicon': 9323, 'chingy': 9324, 'espen': 9325, 'lind': 9326, 'a-myin-thit': 9327, 'owes': 9328, 'educational': 9329, 'decoration': 9330, 'houses': 9331, 'lick': 9332, 'eurythmics': 9333, 'eckstine': 9334, 'scotland': 9335, 'nashville:': 9336, 'punjabi': 9337, 'vilma': 9338, 'forever:': 9339, 'brit': 9340, 'growth': 9341, 'fetish': 9342, 'diwali': 9343, 'doughnut': 9344, 'mommy': 9345, 'decaturville': 9346, 'woodston': 9347, 'aubrey': 9348, 'armageddon': 9349, 'cock': 9350, 'bull': 9351, 'elderton': 9352, 'winger': 9353, 'leonor': 9354, 'imogene': 9355, 'sanchez': 9356, 'greenfoot': 9357, 'quarry': 9358, 'recent': 9359, 'songlines': 9360, 'convoy': 9361, 'busters': 9362, 'bonn': 9363, 'engelchen': 9364, 'bazan': 9365, 'louder': 9366, 'bombs': 9367, 'twisted': 9368, 'dovre-nationalpark': 9369, 'bystrzyca': 9370, '01:51:47': 9371, 'kowalewicz': 9372, 'ronski': 9373, 'chillout': 9374, 'hawking': 9375, 'babylon': 9376, 'toynbee': 9377, 'convector': 9378, 'reminderville': 9379, 'nico': 9380, 'farnworth': 9381, 'wing': 9382, 'marcel': 9383, 'khalife': 9384, 'hickman': 9385, 'grits': 9386, 'haigler': 9387, 'halid': 9388, '08': 9389, 'castillo': 9390, 'parempi': 9391, 'mies': 9392, 'comprehensive': 9393, 'network': 9394, 'jackal': 9395, 'crazysexycool': 9396, 'harmony': 9397, 'chatmoss': 9398, 'jean-georges': 9399, 'mcpherson': 9400, 'niney': 9401, 'observer': 9402, 'ballard': 9403, 'looney': 9404, 'ripley': 9405, 'lone': 9406, 'joyal': 9407, 'blodgett': 9408, 'novels:': 9409, 'angeline': 9410, 'krizz': 9411, 'kaliko': 9412, 'shakti': 9413, 'believer': 9414, 'antonella': 9415, 'barba': 9416, 'bath': 9417, 'ibiza': 9418, 'maureen': 9419, 'mcgovern': 9420, 'snows': 9421, 'kilimanjaro': 9422, 'monroe': 9423, 'kettleman': 9424, 'qbert': 9425, 'dalbello': 9426, 'cma': 9427, 'nominees': 9428, 'bodyguard': 9429, 'festoni': 9430, 'kelsey': 9431, 'shelley': 9432, 'englishman': 9433, 'introspective': 9434, 'sacrifice': 9435, 'exmore': 9436, 'wheesung': 9437, 'im': 9438, 'cerebellum': 9439, 'damien': 9440, 'eylem': 9441, 'hagigat': 9442, 'rzayeva': 9443, 'antisleep': 9444, '04': 9445, 'waar': 9446, 'zon': 9447, 'michiru': 9448, 'yamane': 9449, 'converging': 9450, 'conspiracies': 9451, 'conan:': 9452, 'dimensional': 9453, 'sniper': 9454, 'strandburg': 9455, 'arcola': 9456, 'burnside': 9457, 'roscoff': 9458, 'synth': 9459, 'tenbrooks': 9460, 'barbary': 9461, 'subroc': 9462, 'ziwa': 9463, 'rhino': 9464, 'terminal': 9465, 'birdsong': 9466, 'spotat': 9467, 'lorraine': 9468, 'lampa': 9469, 'meriton': 9470, 'tallinn': 9471, 'stumble': 9472, 'cancer': 9473, 'sailing': 9474, 'seas': 9475, 'jamal': 9476, 'dee': 9477, 'peddling': 9478, 'prosperity': 9479, 'mighty': 9480, 'fortress': 9481, 'maclean': 9482, 'fimd': 9483, 'maylay': 9484, 'radnor': 9485, '13:22:34': 9486, 'chemdex': 9487, 'offa': 9488, 'doseone': 9489, 'boom': 9490, 'bust': 9491, 'haruka': 9492, 'shimotsuki': 9493, 'petit': 9494, 'manan': 9495, 'lyons': 9496, 'ferry': 9497, 'suicide': 9498, 'neutral': 9499, 'experienced': 9500, 'embrace': 9501, 'budokan': 9502, 'joni': 9503, 'brenda’s': 9504, 'ai': 9505, 'kago': 9506, 'glam': 9507, 'hohenfriedberger': 9508, 'monahan': 9509, 'vertically': 9510, 'challenged': 9511, 'older': 9512, 'lady:': 9513, 'seductive': 9514, 'tongue': 9515, 'becker': 9516, 'whip': 9517, 'snowman': 9518, 'yui': 9519, 'poet': 9520, 'cyber': 9521, 'offroad': 9522, 'mansion': 9523, 'archie': 9524, 'whitney': 9525, 'masaharu': 9526, 'fukuyama': 9527, 'deepwater': 9528, 'jansen': 9529, 'confidence-man': 9530, 'graphics': 9531, 'emmons': 9532, 'antoinette': 9533, 'christine': 9534, 'venetian': 9535, 'snares': 9536, 'fourth': 9537, 'jain': 9538, 'lock': 9539, 'clontarf': 9540, 'absolutely': 9541, 'marie': 9542, 'burkettsville': 9543, 'rhoda': 9544, 'roxanne': 9545, 'resort': 9546, 'display': 9547, 'manager': 9548, 'sencha': 9549, 'nhl': 9550, 'silveria': 9551, 'rules': 9552, 'presence': 9553, 'seung': 9554, 'gi': 9555, 'cafe:': 9556, 'tape': 9557, 'luisa': 9558, 'bloody': 9559, 'microphone': 9560, 'tarpon': 9561, 'arnett': 9562, 'irvin': 9563, 'mayfield': 9564, 'verenikina': 9565, 'peggy': 9566, 'sue': 9567, 'patrica': 9568, 'flowers': 9569, 'grandson': 9570, 'tasher': 9571, 'desh': 9572, 'mclagan': 9573, 'beardyman': 9574, 'kenmore': 9575, 'kenova': 9576, 'nannie': 9577, '14:41': 9578, 'dreamstone': 9579, 'montverde': 9580, 'wittig': 9581, 'mancos': 9582, 'bevilacqua': 9583, 'rosales': 9584, 'bonneville': 9585, 'salmonella': 9586, 'mario': 9587, 'rubalcaba': 9588, 'katiejane': 9589, 'garside': 9590, 'gearhart': 9591, 'choose': 9592, 'lyrical': 9593, 'nanoha': 9594, 'strikers': 9595, 'lamentable': 9596, 'omaha': 9597, 'bigelow': 9598, 'impenetrable': 9599, 'loisaida': 9600, 'jungle': 9601, 'ginsburg': 9602, 'winbush': 9603, 'salaam-e-ishq:': 9604, 'gloria': 9605, 'frederick': 9606, 'fenton': 9607, 'krzysztof': 9608, 'penderecki': 9609, 'hardin': 9610, 'toy': 9611, 'dishyum': 9612, 'freund': 9613, 'spiderman': 9614, 'domino': 9615, 'luca': 9616, 'turilli': 9617, 'circleville': 9618, 'dna': 9619, 'repair': 9620, 'mutagenesis': 9621, 'cawker': 9622, 'grisdale': 9623, 'teh': 9624, 'sit': 9625, 'carpathian': 9626, 'seeger': 9627, 'pan': 9628, 'reva': 9629, 'bernadine': 9630, 'benkelman': 9631, 'hopatcong': 9632, 'skip': 9633, 'raheem': 9634, 'devaughn': 9635, 'plankinton': 9636, 'practical': 9637, 'gleed': 9638, 'oldham': 9639, 'waretown': 9640, 'freakbeat': 9641, 'elsa': 9642, 'westhampton': 9643, 'veneto': 9644, 'antietam': 9645, 'ihsahn': 9646, 'autry': 9647, 'laserlight': 9648, 'venice': 9649, 'todesfalle': 9650, 'highlands': 9651, '14:40': 9652, 'karobar': 9653, 'economic': 9654, 'stripped': 9655, 'von': 9656, 'cosels': 9657, 'obsession': 9658, 'rainwater': 9659, 'lp': 9660, 'cage': 9661, 'renewable': 9662, 'electricity': 9663, 'grid': 9664, 'parazaider': 9665, 'private': 9666, 'affairs': 9667, 'bel': 9668, 'vazquez': 9669, 'penermon': 9670, 'phalcon': 9671, 'scratchy': 9672, 'porcaro': 9673, 'unreleased:': 9674, 'fromthe': 9675, 'nobuo': 9676, 'uematsu': 9677, 'bowling': 9678, 'maya': 9679, 'kaira': 9680, 'kwong': 9681, 'trotamundos': 9682, 'redbreast': 9683, 'ronald': 9684, 'isley': 9685, 'wheel': 9686, 'softly': 9687, 'verden': 9688, 'maggot': 9689, 'albano': 9690, 'carrisi': 9691, 'valor': 9692, 'lance': 9693, 'anatone': 9694, 'stepmother': 9695, 'antonito': 9696, 'irvine': 9697, 'sinclair': 9698, 'killer': 9699, 'instinkt': 9700, '08:05': 9701, 'snaith': 9702, 'nimba': 9703, 'hunters': 9704, 'graf': 9705, 'scale': 9706, 'foucault': 9707, 'ringside': 9708, 'standing': 9709, 'tillicum': 9710, 'agnew': 9711, 'acworth': 9712, 'elastic': 9713, 'stormzy': 9714, 'karlsson': 9715, 'gotye': 9716, 'packed': 9717, 'rafters': 9718, 'sweeney': 9719, 'toaster': 9720, 'rescue': 9721, 'mullen': 9722, 'treader': 9723, 'fifa': 9724, 'starcross': 9725, 'wesley': 9726, 'lictor': 9727, 'pocket': 9728, 'boners': 9729, 'wendell': 9730, 'zion': 9731, 'golan': 9732, 'highways': 9733, 'hiding': 9734, 'hyun-joong': 9735, 'fairchild': 9736, 'dolls': 9737, 'harding': 9738, 'wintersong': 9739, 'munawar': 9740, 'sanford': 9741, 'herald': 9742, 'whaling': 9743, 'junun': 9744, 'noam': 9745, 'kaniel': 9746, 'boundary': 9747, 'madwoman': 9748, 'albarn': 9749, 'pointe-heath': 9750, 'ila': 9751, 'manera': 9752, 'recopilatorio': 9753, 'stood': 9754, 'positively': 9755, 'epleys': 9756, 'daring': 9757, 'dobermans': 9758, 'clapton': 9759, 'kindness': 9760, 'bothwell': 9761, 'apples': 9762, 'estrés': 9763, 'meatballs': 9764, 'collaborators': 9765, 'calico': 9766, 'feinstein': 9767, 'skylar': 9768, 'diggins': 9769, 'manassas': 9770, 'floyd': 9771, 'continue': 9772, 'dixie': 9773, 'lullaby:': 9774, 'beginnings': 9775, 'kwuggerbug': 9776, 'grandview': 9777, 'policemen': 9778, 'wickens': 9779, 'tioga': 9780, 'americans': 9781, 'bra': 9782, 'vibrationer': 9783, 'meeres-nationalpark': 9784, 'insel': 9785, 'bastimentos': 9786, 'elvis’': 9787, 'jpop': 9788, 'xenomania': 9789, 'allah': 9790, 'wade': 9791, 'mainer': 9792, 'nostalgic': 9793, 'tameka': 9794, 'hackett': 9795, 'manuel': 9796, 'scene': 9797, 'muncie': 9798, 'jetmore': 9799, 'jenny': 9800, 'moffett': 9801, 'chompa': 9802, 'toung': 9803, 'watcher': 9804, 'warriors': 9805, 'airbnb': 9806, '00:55': 9807, 'variation': 9808, 'plants': 9809, 'domestication': 9810, 'whit': 9811, 'candi': 9812, 'staton': 9813, 'flic': 9814, 'beverly': 9815, 'matching': 9816, 'bette': 9817, 'fairouz': 9818, 'shell': 9819, 'coulee': 9820, 'meers': 9821, 'looked': 9822, 'tragedy': 9823, 'playmaker': 9824, 'whiteman': 9825, 'hut': 9826, 'mckenna': 9827, 'shakira': 9828, 'kingdoms': 9829, 'emo': 9830, 'specialist': 9831, '180': 9832, 'countdown': 9833, '2007–2008': 9834, 'uetoaya': 9835, '11:12': 9836, 'twist': 9837, 'marble': 9838, 'gougoush': 9839, 'nicole': 9840, 'mitchell': 9841, 'afdlin': 9842, 'shauki': 9843, 'salemburg': 9844, 'bibb': 9845, 'doll': 9846, 'sheila': 9847, 'scotia:': 9848, 'speculative': 9849, 'premiere': 9850, 'eletro': 9851, 'br': 9852, 'tanana': 9853, 'lionheart:': 9854, 'rebellion': 9855, 'otselic': 9856, 'likely': 9857, 'metabolights': 9858, 'dobie': 9859, 'gillis': 9860, 'breathtaking': 9861, 'abel': 9862, 'sánchez:': 9863, 'axis2': 9864, 'mondovi': 9865, 'grabsteinland': 9866, 'chicane': 9867, 'crazy': 9868, 'keytesville': 9869, 'tender': 9870, 'bertine': 9871, 'zetlitz': 9872, 'paranormal': 9873, 'activity:': 9874, 'dimension': 9875, '188': 9876, 'lambert': 9877, '10/21/2024': 9878, 'metamora': 9879, 'boat': 9880, 'sinful': 9881, 'unnikrishnante': 9882, 'adyathe': 9883, 'boreas': 9884, 'wetumpka': 9885, 'inheritors': 9886, 'guys': 9887, 'coltrane': 9888, 'refrain': 9889, 'lari': 9890, 'bitty': 9891, 'top-10': 9892, 'coolio': 9893, 'rented': 9894, 'wahhabi': 9895, 'islam:': 9896, 'reform': 9897, 'jihad': 9898, 'montgomery': 9899, 'shuffle': 9900, 'thayer': 9901, 'lafitte': 9902, 'isham': 9903, 'sher': 9904, 'persson': 9905, 'wildwood': 9906, 'patmos': 9907, 'kasey': 9908, 'chambers': 9909, 'lebanese': 9910, 'gypsy': 9911, 'innovations': 9912, 'kokia': 9913, 'scenes': 9914, 'rmx': 9915, 'ayu': 9916, 'judy': 9917, 'sophisticated': 9918, 'vanessa': 9919, 'canción': 9920, 'día': 9921, 'homer': 9922, 'obama:': 9923, 'promise': 9924, 'lihula': 9925, 'medeiros': 9926, 'thinking': 9927, 'flag': 9928, 'splendido': 9929, 'mandrake': 9930, 'kryptonite': 9931, 'borrow': 9932, 'born': 9933, 'won': 9934, 'brandy': 9935, 'stroll': 9936, 'pork': 9937, 'nellie': 9938, 'mckay': 9939, 'rhames': 9940, 'shining': 9941, 'tsukiko': 9942, 'amano': 9943, 'holtville': 9944, 'intelligence': 9945, 'stookey': 9946, 'joplin': 9947, 'cretu': 9948, 'bombshells': 9949, 'tory': 9950, 'innocents': 9951, 'kenia': 9952, 'arias': 9953, 'ohguro': 9954, 'bosnia': 9955, 'herzegovina': 9956, 'chavez:': 9957, 'coup': 9958, 'scorching': 9959, 'mentioned': 9960, 'giv': 9961, 'vegard': 9962, 'sverre': 9963, 'tveitan': 9964, 'wiktor': 9965, 'coj': 9966, 'starr': 9967, 'redington': 9968, 'hutchings': 9969, 'bethany': 9970, 'breeze': 9971, 'edna': 9972, 'bachman': 9973, 'ice:': 9974, 'isobel': 9975, 'elysium': 9976, 'cayabyab': 9977, 'khaled:': 9978, 'phnom': 9979, 'sankos': 9980, 'calpella': 9981, 'amor:': 9982, 'exclusive': 9983, 'chantal': 9984, 'kreviazuk': 9985, 'doolittle': 9986, 'elites': 9987, 'luambe-nationalpark': 9988, 'irene': 9989, 'rosella': 9990, 'robinette': 9991, 'cadogan': 9992, 'scheudle': 9993, 'akira': 9994, 'kellerton': 9995, 'ares': 9996, 'ideas': 9997, 'crugers': 9998, 'marlton': 9999, 'circle': 10000, 'zaleski': 10001, 'decoded:': 10002, 'exuma': 10003, 'deal': 10004, 'selected': 10005, 'lovecraft': 10006, 'subliminal': 10007, 'cone': 10008, 'diners': 10009, 'allentown': 10010, 'purim': 10011, 'taktloss': 10012, 'winnie-the-pooh': 10013, 'edgemoor': 10014, 'kitade': 10015, 'psychedelia': 10016, 'crouch': 10017, 'burnout:': 10018, 'rodgers': 10019, 'hammerstein': 10020, 'elica': 10021, 'mckinley': 10022, 'nudity': 10023, 'punished': 10024, 'prurient': 10025, 'laguna': 10026, 'talbot': 10027, 'mundy:': 10028, 'messenger': 10029, 'panic': 10030, 'zenda': 10031, 'baldur’s': 10032, 'bhaal': 10033, 'sentimental': 10034, 'bloke': 10035, 'nightbirds': 10036, 'nantucket': 10037, 'irreconcilable': 10038, 'differences': 10039, 'earls': 10040, 'lucille': 10041, 'riverview': 10042, 'narodowy': 10043, 'kushiro-shitsugen': 10044, 'rss': 10045, 'tracking': 10046, 'poor': 10047, 'tuna': 10048, 'morgan–monroe': 10049, 'gladys': 10050, 'barometer': 10051, 'share': 10052, 'stays': 10053, 'walks': 10054, 'limit': 10055, 'booty': 10056, 'f-1': 10057, 'prix': 10058, 'eliza': 10059, 'carthy': 10060, 'hineston': 10061, 'orpheus': 10062, 'hybla': 10063, 'almighty': 10064, 'johnsons': 10065, 'powersville': 10066, 'bashkirsky': 10067, 'delft': 10068, 'polymer': 10069, 'canfield': 10070, '22:23:22': 10071, 'magdalena': 10072, 'brady': 10073, 'aired': 10074, 'halls': 10075, 'garner': 10076, 'its': 10077, 'phoebus': 10078, 'friesland': 10079, 'dongola': 10080, 'dressed': 10081, 'dorsey': 10082, 'tieghem': 10083, 'forge': 10084, 'princeton': 10085, 'chili': 10086, 'bestiary': 10087, 'tetsuya': 10088, 'ogawa': 10089, 'gwen': 10090, 'turnt': 10091, 'ghostly': 10092, 'swim': 10093, 'teri': 10094, 'meri': 10095, 'loudon': 10096, 'naseer': 10097, 'shamma': 10098, 'ocelot': 10099, 'resource': 10100, 'moldy': 10101, 'povel': 10102, 'ramel': 10103, 'irv': 10104, 'gotti': 10105, 'presents:': 10106, 'murderers': 10107, 'cityzen': 10108, 'wyndorf': 10109, 'alternativo': 10110, 'lighthouse': 10111, 'riceboro': 10112, 'blink': 10113, 'em4jay': 10114, 'tallahassee-st': 10115, 'marks': 10116, 'gloryhole': 10117, 'mani': 10118, 'somewhee': 10119, 'hollenberg': 10120, 'carl': 10121, 'masayoshi': 10122, 'vache': 10123, 'iren': 10124, 'michaelsen': 10125, 'reuben': 10126, 'chas': 10127, 'zephyrhills': 10128, 'tsoi': 10129, '00:00': 10130, 'putrid': 10131, 'sorcery': 10132, 'prints': 10133, 'baylor': 10134, 'unborn': 10135, 'forgotten': 10136, 'milladore': 10137, 'someday': 10138, 'soon': 10139, 'fiona': 10140, 'wholehearted': 10141, 'bonnet': 10142, 'clifford': 10143, '12/5/2032': 10144, 'liberation': 10145, 'fu': 10146, 'lynne': 10147, 'linn': 10148, 'berggren': 10149, 'branton': 10150, 'dschiwan': 10151, 'gasparjan': 10152, '59th': 10153, 'grammy': 10154, 'hopeless': 10155, 'benson-meditation': 10156, 'luther': 10157, 'tomohisa': 10158, 'yamashita': 10159, 'satisfaction': 10160, 'virtue': 10161, 'nauseam': 10162, 'nokia': 10163, 'jalal': 10164, 'zolfonun': 10165, 'chemical': 10166, 'engineers': 10167, 'jewell': 10168, 'cemetery': 10169, 'lilly': 10170, 'witch:': 10171, 'cats': 10172, 'friend:': 10173, 'schuster': 10174, 'prehistoric': 10175, 'noah': 10176, 'wuv': 10177, 'bernardo': 10178, 'humor': 10179, 'notebook': 10180, 'trigorin': 10181, 'wather': 10182, 'coleville': 10183, 'miracle': 10184, 'rhoads': 10185, 'trapper': 10186, '32': 10187, 'kear': 10188, 'myra': 10189, 'ines': 10190, 'kano': 10191, 'luxury': 10192, 'liner': 10193, 'hackney': 10194, 'ahead': 10195, 'schubert': 10196, 'public': 10197, 'toilet': 10198, 'slemp': 10199, 'cin': 10200, 'ramone': 10201, 'lavender': 10202, 'omega': 10203, 'fusil': 10204, 'contra': 10205, 'tschetter': 10206, 'ascension': 10207, 'portales': 10208, '129': 10209, 'canon': 10210, 'ding': 10211, 'dong': 10212, 'having': 10213, 'spent': 10214, 'horses': 10215, 'twinkler': 10216, 'soviet': 10217, 'tankmen': 10218, 'gaither': 10219, 'albums': 10220, 'sailor': 10221, 'supers:': 10222, 're': 10223, 'greenport': 10224, 'alasdair': 10225, 'roberts': 10226, 'vanlue': 10227, 'zei': 10228, 'boys:': 10229, 'violent': 10230, '163': 10231, 'moye': 10232, 'tuolumne': 10233, '12/10/2035': 10234, 'counting': 10235, 'rosaries': 10236, 'supercop': 10237, 'sukkot': 10238, 'tribeca': 10239, 'jacklyn': 10240, 'okay': 10241, 'luzon': 10242, 'certification': 10243, 'citrus': 10244, 'lenzburg': 10245, 'action': 10246, 'bernard': 10247, 'jem': 10248, 'godfrey': 10249, 'noew': 10250, 'dundee': 10251, 'tira': 10252, 'kotoko': 10253, 'norman': 10254, 'touchdown': 10255, 'sompio': 10256, 'kremmling': 10257, 'baotianman': 10258, 'botanical': 10259, 'camden': 10260, 'langdon': 10261, 'agua': 10262, 'sal': 10263, 'fey': 10264, 'index': 10265, 'elizabethville': 10266, 'mcgee': 10267, 'melbourne': 10268, 'redding': 10269, 'ufc': 10270, 'grantsburg': 10271, 'hull': 10272, 'sale': 10273, 'illness': 10274, 'metaphor': 10275, 'mcisaac': 10276, 'whitewater': 10277, 'japan': 10278, 'malin': 10279, 'tonopah': 10280, 'brightman': 10281, 'osyka': 10282, 'titanic:': 10283, 'foundling': 10284, 'grae': 10285, 'anila': 10286, 'mirza': 10287, '10:47:15': 10288, 'viroqua': 10289, 'mondamin': 10290, 'bullfeathers': 10291, 'trussville': 10292, 'thyme': 10293, 'spaulding': 10294, 'morocco': 10295, 'freestyle': 10296, 'akb48': 10297, 'pumping': 10298, 'moose': 10299, '1634:': 10300, 'ram': 10301, 'wildreservaat': 10302, 'ithala': 10303, 'sp': 10304, 'balasubrahmanyam': 10305, 'infernus': 10306, 'marsha': 10307, 'love:': 10308, 'tiffany': 10309, 'sondra': 10310, 'hanksville': 10311, 'rui': 10312, 'silva': 10313, 'happiness': 10314, 'duty:': 10315, 'macmaster': 10316, 'asiate': 10317, 'sturgeon': 10318, 'janne': 10319, 'puurtinen': 10320, 'chick': 10321, 'corea': 10322, 'his-story': 10323, 'leviathan': 10324, 'meadow': 10325, 'vale': 10326, 'fatty': 10327, 'haskell': 10328, 'traverse': 10329, 'bottomland': 10330, 'liked': 10331, 'headed': 10332, 'eifel': 10333, 'manifesto': 10334, 'nevermore': 10335, 'arnauld': 10336, 'raven': 10337, 'eugene': 10338, 'mahoney': 10339, 'jappeloup': 10340, 'valerij': 10341, 'awakened': 10342, 'appalachian': 10343, 'josiah': 10344, 'leming': 10345, 'rosetta': 10346, 'tharpe': 10347, 'polite': 10348, 'raffaele': 10349, 'riefoli': 10350, 'lockwood': 10351, 'lesley': 10352, 'childersburg': 10353, 'germfask': 10354, 'holiday': 10355, 'mae': 10356, 'restless': 10357, 'natives': 10358, 'heavenly': 10359, 'hiromitsu': 10360, 'agatsuma': 10361, 'valenciano': 10362, 'amii': 10363, 'development': 10364, 'perspectives': 10365, 'yearbook': 10366, 'honeysuckle': 10367, 'chér': 10368, 'creola': 10369, 'grab': 10370, 'lacassine': 10371, 'lateness': 10372, 'deathlord': 10373, 'ixia': 10374, 'parks': 10375, 'carina': 10376, 'sport': 10377, 'pastime': 10378, 'valle': 10379, 'jarama': 10380, 'working': 10381, 'kelloe': 10382, 'vineyard': 10383, 'haven': 10384, 'candace': 10385, 'debbie': 10386, 'pop-folk': 10387, 'kraken:': 10388, 'tentacles': 10389, 'marvin': 10390, '6/14/2035': 10391, 'paella': 10392, 'negerpunk': 10393, 'grew': 10394, 'wafah': 10395, 'dufour': 10396, 'jeeves': 10397, 'wooster': 10398, 'nonsense': 10399, 'weed': 10400, 'turbulence': 10401, 'streetdanz': 10402, 'buckley': 10403, 'colfax': 10404, '1/1/2031': 10405, 'champagne': 10406, 'showers': 10407, 'ice-cream': 10408, 'gentle': 10409, 'compton': 10410, 'economy': 10411, 'ives': 10412, 'omnipresent': 10413, 'cabbage': 10414, 'keiji': 10415, 'haino': 10416, 'terri': 10417, 'whiteside': 10418, 'inverness': 10419, 'niggers': 10420, 'neuroscience': 10421, 'corsten': 10422, 'advances': 10423, 'mortem': 10424, 'mornings': 10425, 'rescuing': 10426, 'squires': 10427, 'bhupinder': 10428, 'singh': 10429, 'octagon': 10430, 'christchurch': 10431, 'feud': 10432, 'moran': 10433, 'hamorton': 10434, 'becky': 10435, 'pearce': 10436, 'gamblers': 10437, 'pillar': 10438, 'lamentation': 10439, 'cloris': 10440, 'thieving': 10441, 'magpie': 10442, 'solo': 10443, 'bonaparte': 10444, 'scarab': 10445, 'vidal': 10446, 'neshanic': 10447, '06:18:13': 10448, 'farristown': 10449, 'maidens': 10450, 'mapa': 10451, 'amigos': 10452, 'applied': 10453, 'linguistics': 10454, 'niobrara': 10455, 'clean': 10456, 'sober': 10457, 'malese': 10458, 'jow': 10459, 'flow:': 10460, 'eighty': 10461, 'sierraville': 10462, 'venedig': 10463, 'regen': 10464, 'eleele': 10465, 'evocation': 10466, 'arcane': 10467, 'dominion': 10468, 'cass': 10469, 'elliot': 10470, 'root': 10471, 'cou': 10472, 'contesting': 10473, 'crucial': 10474, 'luquillo': 10475, 'winnebago': 10476, 'scaramouche': 10477, 'mccunn': 10478, 'tammi': 10479, 'nauru': 10480, 'needing': 10481, 'whitechapel': 10482, 'shamus': 10483, 'neutrons': 10484, 'seun': 10485, 'kuti': 10486, 'raices': 10487, 'antenas': 10488, 'llp': 10489, 'inwood': 10490, '207th': 10491, 'kentmore': 10492, 'candoli': 10493, 'attell': 10494, 'tashan': 10495, 'dorrsett': 10496, 'seven-thirty': 10497, 'minami': 10498, 'alps': 10499, 'koma': 10500, 'anacreon': 10501, 'gabber': 10502, 'meditations': 10503, 'deeds': 10504, 'maccool': 10505, 'yarbrough': 10506, 'bashful': 10507, 'oswald': 10508, 'starfleet': 10509, 'simulator': 10510, 'bayou': 10511, 'kawabata': 10512, 'makoto': 10513, 'nellieburg': 10514, '楽園追放': 10515, '-expelled': 10516, 'paradise-': 10517, 'sudol': 10518, 'ncaa': 10519, '2k3': 10520, 'celestial': 10521, 'beware': 10522, 'probes': 10523, 'deeth': 10524, 'destination': 10525, 'prague': 10526, 'xuefei': 10527, 'cropper': 10528, 'testifying': 10529, 'feed': 10530, 'kitty': 10531, 'psychadelic': 10532, 'salina': 10533, 'sholle': 10534, '02:53': 10535, 'slinger': 10536, 'shaolin': 10537, 'pinto': 10538, 'joyful': 10539, 'noise:': 10540, 'dumping': 10541, 'whistling': 10542, 'suwannee': 10543, 'sight': 10544, 'garrett': 10545, 'karoly': 10546, 'hatzidakis': 10547, 'behzad': 10548, 'mirkhani': 10549, 'aura': 10550, 'ecstatic': 10551, 'coronado': 10552, 'demolished': 10553, 'nora': 10554, 'ilse': 10555, 'delange': 10556, 'divided': 10557, 'serendipity': 10558, 'veyo': 10559, 'keeneland': 10560, 'goldimouse': 10561, 'require': 10562, 'roseburg': 10563, 'mansfield': 10564, 'prefer': 10565, 'marianne': 10566, 'faithfull': 10567, 'satan': 10568, 'conshohocken': 10569, 'tholireyi': 10570, 'gadichindi': 10571, 'bombay': 10572, 'spyro': 10573, 'bleach:': 10574, 'pershing': 10575, 'cypress': 10576, 'pmd': 10577, 'tabloid': 10578, 'rolf': 10579, 'shelby': 10580, 'tenor': 10581, 'tapshoes': 10582, 'shinji': 10583, 'miyazaki': 10584, 'zebra': 10585, '07:25': 10586, 'eu': 10587, 'pego': 10588, 'maestro': 10589, 'groucutt': 10590, 'oakes': 10591, 'north-west': 10592, 'passage': 10593, 'address': 10594, 'soonchild': 10595, 'vanquished': 10596, 'orford': 10597, 'vigilantes': 10598, 'effortless': 10599, 'mastery': 10600, 'spalding': 10601, 'abuja': 10602, 'coyote': 10603, 'space-age': 10604, 'madchild': 10605, 'choclo': 10606, 'auto': 10607, 'renouveau': 10608, 'nam': 10609, 'kading': 10610, 'senior': 10611, 'intersections': 10612, 'grilled': 10613, 'meat': 10614, 'vinyl': 10615, 'notebooks': 10616, 'tracie': 10617, 'noyack': 10618, 'layzie': 10619, 'mcclinton': 10620}\n",
            "{'AddToPlaylist': 0, 'GetWeather': 1, 'PlayMusic': 2, 'SearchScreeningEvent': 3, 'RateBook': 4, 'BookRestaurant': 5, 'SearchCreativeWork': 6}\n",
            "{'pad': 0, 'B-service': 1, 'I-facility': 2, 'B-movie_name': 3, 'I-sort': 4, 'I-artist': 5, 'I-city': 6, 'B-condition_description': 7, 'B-object_name': 8, 'I-poi': 9, 'B-current_location': 10, 'B-best_rating': 11, 'I-object_location_type': 12, 'I-object_name': 13, 'B-party_size_number': 14, 'B-artist': 15, 'B-entity_name': 16, 'I-object_part_of_series_type': 17, 'I-party_size_description': 18, 'I-genre': 19, 'I-playlist_owner': 20, 'B-party_size_description': 21, 'I-geographic_poi': 22, 'I-object_type': 23, 'I-object_select': 24, 'I-cuisine': 25, 'B-state': 26, 'O': 27, 'B-served_dish': 28, 'B-movie_type': 29, 'I-movie_name': 30, 'B-facility': 31, 'B-genre': 32, 'I-country': 33, 'B-track': 34, 'B-city': 35, 'B-music_item': 36, 'I-music_item': 37, 'I-track': 38, 'B-restaurant_type': 39, 'I-playlist': 40, 'B-playlist': 41, 'B-object_part_of_series_type': 42, 'B-poi': 43, 'I-served_dish': 44, 'B-sort': 45, 'I-restaurant_name': 46, 'B-rating_value': 47, 'B-object_location_type': 48, 'B-cuisine': 49, 'B-geographic_poi': 50, 'I-restaurant_type': 51, 'B-album': 52, 'I-current_location': 53, 'B-location_name': 54, 'I-entity_name': 55, 'I-location_name': 56, 'B-condition_temperature': 57, 'I-state': 58, 'B-year': 59, 'I-service': 60, 'B-playlist_owner': 61, 'B-object_select': 62, 'B-object_type': 63, 'I-spatial_relation': 64, 'I-album': 65, 'B-rating_unit': 66, 'I-timeRange': 67, 'B-timeRange': 68, 'I-movie_type': 69, 'B-restaurant_name': 70, 'B-spatial_relation': 71, 'B-country': 72}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Customize the Dataset class"
      ],
      "metadata": {
        "id": "QhYQ0Gkc8y8N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "01b4823f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.utils.data as data\n",
        "\n",
        "class IntentsAndSlots(data.Dataset):\n",
        "    # Mandatory methods are __init__, __len__ and __getitem__\n",
        "    def __init__(self, dataset, lang, unk='unk'):\n",
        "        self.utterances = []\n",
        "        self.intents = []\n",
        "        self.slots = []\n",
        "        self.unk = unk\n",
        "        \n",
        "        for x in dataset:\n",
        "            self.utterances.append(x['utterance'])\n",
        "            self.slots.append(x['slots'])\n",
        "            self.intents.append(x['intent'])\n",
        "\n",
        "#convert to numbers\n",
        "        self.utt_ids = self.mapping_seq(self.utterances, lang.word2id)\n",
        "        self.slot_ids = self.mapping_seq(self.slots, lang.slot2id)\n",
        "        self.intent_ids = self.mapping_lab(self.intents, lang.intent2id)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.utterances)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        utt = torch.Tensor(self.utt_ids[idx])\n",
        "        slots = torch.Tensor(self.slot_ids[idx])\n",
        "        intent = self.intent_ids[idx]\n",
        "        sample = {'utterance': utt, 'slots': slots, 'intent': intent}\n",
        "        return sample #dictionary with 3 keys\n",
        "    \n",
        "    # Auxiliary methods\n",
        "    \n",
        "    def mapping_lab(self, data, mapper):\n",
        "        return [mapper[x] if x in mapper else mapper[self.unk] for x in data]\n",
        "    \n",
        "    def mapping_seq(self, data, mapper): # Map sequences to number\n",
        "        res = []\n",
        "        for seq in data:\n",
        "            tmp_seq = []\n",
        "            for x in seq.split():\n",
        "                if x in mapper:\n",
        "                    tmp_seq.append(mapper[x])\n",
        "                else:\n",
        "                    tmp_seq.append(mapper[self.unk])\n",
        "            res.append(tmp_seq)\n",
        "        return res\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "845ab541"
      },
      "outputs": [],
      "source": [
        "# Create our ATIS datasets\n",
        "ATIS_train_dataset = IntentsAndSlots(ATIS_train_raw, ATIS_lang)\n",
        "ATIS_dev_dataset = IntentsAndSlots(ATIS_dev_raw, ATIS_lang)\n",
        "ATIS_test_dataset = IntentsAndSlots(ATIS_test_raw, ATIS_lang)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create our SNIPS datasets\n",
        "SNIPS_train_dataset = IntentsAndSlots(SNIPS_train_raw, SNIPS_lang)\n",
        "SNIPS_dev_dataset = IntentsAndSlots(SNIPS_dev_raw, SNIPS_lang)\n",
        "SNIPS_test_dataset = IntentsAndSlots(SNIPS_test_raw, SNIPS_lang)"
      ],
      "metadata": {
        "id": "3P82jGiT8dpr"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Dataloader"
      ],
      "metadata": {
        "id": "n_6w7o52PRsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def collate_fn(data):\n",
        "    def merge(sequences):\n",
        "        '''\n",
        "        merge from batch * sent_len to batch * max_len \n",
        "        '''\n",
        "        lengths = [len(seq) for seq in sequences]\n",
        "        max_len = 1 if max(lengths)==0 else max(lengths)\n",
        "        # Pad token is zero in our case\n",
        "        # So we create a matrix full of PAD_TOKEN (i.e. 0) with the shape \n",
        "        # batch_size X maximum length of a sequence\n",
        "        padded_seqs = torch.LongTensor(len(sequences), max_len).fill_(PAD_TOKEN)\n",
        "        for i, seq in enumerate(sequences):\n",
        "            end = lengths[i]\n",
        "            padded_seqs[i, :end] = seq # We copy each sequence into the matrix\n",
        "        # print(padded_seqs)\n",
        "        padded_seqs = padded_seqs.detach()  # We remove these tensors from the computational graph\n",
        "        return padded_seqs, lengths\n",
        "        \n",
        "    # Sort data by seq lengths\n",
        "    data.sort(key=lambda x: len(x['utterance']), reverse=True) \n",
        "    new_item = {}\n",
        "    for key in data[0].keys():\n",
        "        new_item[key] = [d[key] for d in data]\n",
        "    # We just need one length for packed pad seq, since len(utt) == len(slots)\n",
        "    src_utt, _ = merge(new_item['utterance'])\n",
        "    y_slots, y_lengths = merge(new_item[\"slots\"])\n",
        "    intent = torch.LongTensor(new_item[\"intent\"])\n",
        "    \n",
        "    src_utt = src_utt.to(device) # We load the Tensor on our seleceted device\n",
        "    y_slots = y_slots.to(device)\n",
        "    intent = intent.to(device)\n",
        "    y_lengths = torch.LongTensor(y_lengths).to(device)\n",
        "    \n",
        "    new_item[\"utterances\"] = src_utt\n",
        "    new_item[\"intents\"] = intent\n",
        "    new_item[\"y_slots\"] = y_slots\n",
        "    new_item[\"slots_len\"] = y_lengths\n",
        "    return new_item"
      ],
      "metadata": {
        "id": "5donDbuZL3UU"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader ATIS instantiation\n",
        "ATIS_train_loader = DataLoader(ATIS_train_dataset, batch_size=128, collate_fn=collate_fn,  shuffle=True)\n",
        "ATIS_dev_loader = DataLoader(ATIS_dev_dataset, batch_size=64, collate_fn=collate_fn)\n",
        "ATIS_test_loader = DataLoader(ATIS_test_dataset, batch_size=64, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "vp_YuNnPXkrp"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader SNIPS instantiation\n",
        "SNIPS_train_loader = DataLoader(SNIPS_train_dataset, batch_size=128, collate_fn=collate_fn,  shuffle=True)\n",
        "SNIPS_dev_loader = DataLoader(SNIPS_dev_dataset, batch_size=64, collate_fn=collate_fn)\n",
        "SNIPS_test_loader = DataLoader(SNIPS_test_dataset, batch_size=64, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "rF8RpJ_qXPyk"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ATIS_out_slot = len(ATIS_lang.slot2id)\n",
        "ATIS_out_int = len(ATIS_lang.intent2id)\n",
        "ATIS_vocab_len = len(ATIS_lang.word2id)\n",
        "print(\"ATIS vocabulary len: \", ATIS_vocab_len)"
      ],
      "metadata": {
        "id": "2WCFUEhVYWT0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc2f8e9b-8f74-4b9b-a5f7-e1925d237401"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ATIS vocabulary len:  863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SNIPS_out_slot = len(SNIPS_lang.slot2id)\n",
        "SNIPS_out_int = len(SNIPS_lang.intent2id)\n",
        "SNIPS_vocab_len = len(SNIPS_lang.word2id)\n",
        "print(\"SNIPS vocabulary len: \", SNIPS_vocab_len)"
      ],
      "metadata": {
        "id": "VuiO5cBZYfwz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f57eb13-4efe-4113-90c4-1eee4078deb8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SNIPS vocabulary len:  10621\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Auxiliary methods"
      ],
      "metadata": {
        "id": "aK-WPZXbAZQ_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "f47fe3fe"
      },
      "outputs": [],
      "source": [
        "def init_weights(mat): #randomly initialize weights\n",
        "    for m in mat.modules():\n",
        "        if type(m) in [nn.GRU, nn.LSTM, nn.RNN]:\n",
        "            for name, param in m.named_parameters():\n",
        "                if 'weight_ih' in name:\n",
        "                    for idx in range(4):\n",
        "                        mul = param.shape[0]//4\n",
        "                        torch.nn.init.xavier_uniform_(param[idx*mul:(idx+1)*mul])\n",
        "                elif 'weight_hh' in name:\n",
        "                    for idx in range(4):\n",
        "                        mul = param.shape[0]//4\n",
        "                        torch.nn.init.orthogonal_(param[idx*mul:(idx+1)*mul])\n",
        "                elif 'bias' in name:\n",
        "                    param.data.fill_(0)\n",
        "        else:\n",
        "            if type(m) in [nn.Linear]:\n",
        "                torch.nn.init.uniform_(m.weight, -0.01, 0.01)\n",
        "                if m.bias != None:\n",
        "                    m.bias.data.fill_(0.01)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses(sampled_epochs, loss_train, loss_dev):\n",
        "  plt.figure(num = 3, figsize=(12, 8)).patch.set_facecolor('white')\n",
        "  plt.title('Train and Dev Losses')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.plot(sampled_epochs, loss_train, label='Train loss')\n",
        "  plt.plot(sampled_epochs, loss_dev, label='Dev loss')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "nU_woEqaQgZM"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Baseline Model"
      ],
      "metadata": {
        "id": "taNjnJqsP4q8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4019e479"
      },
      "source": [
        "As baseline model I took the LSTM model seen in class"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model definition"
      ],
      "metadata": {
        "id": "e-yHvIzjAfzX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "93adc878"
      },
      "outputs": [],
      "source": [
        "class ModelIAS(nn.Module):\n",
        "#hidden size of rnn, embedding size (size of the vector that represent the word embedding)\n",
        "    def __init__(self, hid_size, out_slot, out_int, emb_size, vocab_len, n_layer=1, pad_index=0):\n",
        "        super(ModelIAS, self).__init__()\n",
        "        # hid_size = Hidden size\n",
        "        # out_slot = number of slots (output size for slot filling)\n",
        "        # out_int = number of intents (ouput size for intent class)\n",
        "        # emb_size = word embedding size\n",
        "        \n",
        "        #A simple lookup table that stores embeddings of a fixed dictionary and size.\n",
        "        #The input to the module is a list of indices, and the output is the corresponding word embeddings.\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_len, emb_size, padding_idx=pad_index) #pad idx --> the entities at pad_index do not contribute to the gradient\n",
        "        \n",
        "        self.utt_encoder = nn.LSTM(emb_size, hid_size, n_layer, bidirectional=False)     #network, unidirectional\n",
        "        self.slot_out = nn.Linear(hid_size, out_slot)\n",
        "        self.intent_out = nn.Linear(hid_size, out_int)\n",
        "        self.dropout = nn.Dropout(0.1) #regularization --> randomly mute a neuron, only on training phase. Helps to avoid overfitting\n",
        "        \n",
        "    def forward(self, utterance, seq_lengths): #define the architecture\n",
        "        # utterance.size() = batch_size X seq_len\n",
        "        utt_emb = self.embedding(utterance) # utt_emb.size() = batch_size X seq_len X emb_size\n",
        "        #--> get word embedding\n",
        "        utt_emb = utt_emb.permute(1,0,2) # we need seq len first -> seq_len X batch_size X emb_size\n",
        "        \n",
        "        # pack_padded_sequence avoid computation over pad tokens reducing the computational cost\n",
        "        \n",
        "        packed_input = pack_padded_sequence(utt_emb, seq_lengths.cpu().numpy())\n",
        "        # Process the batch\n",
        "        packed_output, (last_hidden, cell) = self.utt_encoder(packed_input) \n",
        "\n",
        "        #packed output containing the output features (h_t) from the last layer of the LSTM, \n",
        "        #for each t. If a torch.nn.utils.rnn.PackedSequence has been given as the \n",
        "        #input, the output will also be a packed sequence.\n",
        "\n",
        "        #last_hidden containing the final hidden state for each element in the sequence\n",
        "        #cell containing the final cell state for each element in the sequence\n",
        "        \n",
        "        # Unpack the sequence\n",
        "        utt_encoded, input_sizes = pad_packed_sequence(packed_output)\n",
        "        # Get the last hidden state\n",
        "        last_hidden = last_hidden[-1,:,:]\n",
        "        # Compute slot logits\n",
        "        slots = self.slot_out(utt_encoded)\n",
        "        # Compute intent logits\n",
        "        intent = self.intent_out(last_hidden)\n",
        "        \n",
        "        # Slot size: seq_len, batch size, classes \n",
        "        slots = slots.permute(1,2,0) # We need this for computing the loss\n",
        "        # Slot size: batch_size, classes, seq_len\n",
        "        return slots, intent"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train Loop Definition"
      ],
      "metadata": {
        "id": "VVxiiXrENKGp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "oFTi4TXUewtE"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "6bf6dfca"
      },
      "outputs": [],
      "source": [
        "from conll import evaluate\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def train_loop(data, optimizer, criterion_slots, criterion_intents, model):\n",
        "    model.train()\n",
        "    loss_array = []\n",
        "    loss_intent_array = []\n",
        "    loss_slot_array = []\n",
        "    for sample in data:\n",
        "        optimizer.zero_grad() # Zeroing the gradient\n",
        "        slots, intent = model(sample['utterances'], sample['slots_len'])\n",
        "        loss_intent = criterion_intents(intent, sample['intents'])\n",
        "\n",
        "        loss_slot = criterion_slots(slots, sample['y_slots'])\n",
        "\n",
        "        loss_intent_array.append(loss_intent.item())\n",
        "        loss_slot_array.append(loss_slot.item())\n",
        "\n",
        "\n",
        "\n",
        "        loss = loss_intent + loss_slot \n",
        "\n",
        "        loss_array.append(loss.item())\n",
        "        loss.backward() # Compute the gradient, deleting the computational graph\n",
        "        optimizer.step() # Update the weights\n",
        "    return loss_array, loss_intent_array, loss_slot_array\n",
        "\n",
        "def eval_loop(data, criterion_slots, criterion_intents, model, lang):\n",
        "    model.eval()\n",
        "    loss_array = []\n",
        "    loss_intent_array = []\n",
        "    loss_slot_array = []\n",
        "    \n",
        "    ref_intents = []\n",
        "    hyp_intents = []\n",
        "    \n",
        "    ref_slots = []\n",
        "    hyp_slots = []\n",
        "   \n",
        "    with torch.no_grad(): # It used to avoid the creation of computational graph\n",
        "        for sample in data:\n",
        "            slots, intents = model(sample['utterances'], sample['slots_len'])\n",
        "            loss_intent = criterion_intents(intents, sample['intents'])\n",
        "            loss_slot = criterion_slots(slots, sample['y_slots'])\n",
        "            loss = loss_intent + loss_slot \n",
        "\n",
        "            loss_intent_array.append(loss_intent.item())\n",
        "            loss_slot_array.append(loss_slot.item())\n",
        "            loss_array.append(loss.item())\n",
        "            # Intent inference\n",
        "            # Get the highest probable class\n",
        "            out_intents = [lang.id2intent[x] \n",
        "                           for x in torch.argmax(intents, dim=1).tolist()] \n",
        "            gt_intents = [lang.id2intent[x] for x in sample['intents'].tolist()]\n",
        "            ref_intents.extend(gt_intents)\n",
        "            hyp_intents.extend(out_intents)\n",
        "            \n",
        "            # Slot inference \n",
        "            output_slots = torch.argmax(slots, dim=1)\n",
        "            for id_seq, seq in enumerate(output_slots):\n",
        "                length = sample['slots_len'].tolist()[id_seq]\n",
        "                utt_ids = sample['utterance'][id_seq][:length].tolist()\n",
        "                gt_ids = sample['y_slots'][id_seq].tolist()\n",
        "                gt_slots = [lang.id2slot[elem] for elem in gt_ids[:length]]\n",
        "            \n",
        "                utterance = [lang.id2word[elem] for elem in utt_ids]\n",
        "            \n",
        "                to_decode = seq[:length].tolist()\n",
        "                ref_slots.append([(utterance[id_el], elem) for id_el, elem in enumerate(gt_slots)])\n",
        "                tmp_seq = []\n",
        "                for id_el, elem in enumerate(to_decode):\n",
        "                    tmp_seq.append((utterance[id_el], lang.id2slot[elem]) if elem != 0 else (utterance[id_el], 'O'))\n",
        "                hyp_slots.append(tmp_seq)\n",
        "           \n",
        "    try:            \n",
        "        results = evaluate(ref_slots, hyp_slots)\n",
        "    except Exception as ex: #if your model predict slot that are not in ref, it gives error\n",
        "        # Sometimes the model predics a class that is not in REF\n",
        "        print(ex)\n",
        "        ref_s = set([x[1] for x in ref_slots])\n",
        "        hyp_s = set([x[1] for x in hyp_slots])\n",
        "        print(hyp_s.difference(ref_s))\n",
        "        \n",
        "    report_intent = classification_report(ref_intents, hyp_intents, \n",
        "                                          zero_division=False, output_dict=True)\n",
        "    \n",
        "    return results, report_intent, loss_array, loss_intent_array, loss_slot_array"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, test_loader, dev_loader, model, optimizer, lang, n_epochs=200, patience=5):\n",
        "  losses_train = []\n",
        "  loss_intent_train = []\n",
        "  loss_slot_train = []\n",
        "  losses_dev = [] \n",
        "  loss_intent_dev_array = []\n",
        "  loss_slot_dev_array= []\n",
        "\n",
        "  sampled_epochs = []\n",
        "  best_f1 = 0\n",
        "  for x in tqdm(range(1,n_epochs)):\n",
        "      if train:\n",
        "        loss, loss_intent, loss_slot = train_loop(train_loader, optimizer, criterion_slots, \n",
        "                          criterion_intents, model)\n",
        "        if x % 3 == 0:\n",
        "            sampled_epochs.append(x)\n",
        "            losses_train.append(np.asarray(loss).mean())\n",
        "            loss_intent_train.append(np.asarray(loss_intent).mean())\n",
        "            loss_slot_train.append(np.asarray(loss_slot).mean())\n",
        "\n",
        "            results_dev, intent_res, loss_dev, loss_intent_dev, loss_slot_dev = eval_loop(dev_loader, criterion_slots, \n",
        "                                                          criterion_intents, model, lang)\n",
        "            losses_dev.append(np.asarray(loss_dev).mean())\n",
        "            loss_intent_dev_array.append(np.asarray(loss_intent_dev).mean())\n",
        "            loss_slot_dev_array.append(np.asarray(loss_slot_dev).mean())\n",
        "            f1 = results_dev['total']['f']\n",
        "          \n",
        "            #print('\\nSlot F1: ', results_dev['total']['f'])\n",
        "            #print('Intent Accuracy:', intent_res['accuracy'])\n",
        "            \n",
        "            if f1 > best_f1: #sometimes loss words but f1 increases, we have to look at both and figure out what of the 2 to use to stop the training\n",
        "                best_f1 = f1\n",
        "            else:\n",
        "                patience -= 1\n",
        "            if patience <= 0: # Early stopping with patience\n",
        "                break # Not nice but it keeps the code clean\n",
        "\n",
        "  results_test, intent_test, _ , _ , _ = eval_loop(test_loader, criterion_slots, \n",
        "                                          criterion_intents, model, lang)    \n",
        "  print('\\nSlot F1: ', results_test['total']['f'])\n",
        "  print('Intent Accuracy:', intent_test['accuracy'])\n",
        "  return results_test, intent_test, sampled_epochs, losses_train, losses_dev, loss_intent_train, loss_slot_train, loss_intent_dev_array, loss_slot_dev_array"
      ],
      "metadata": {
        "id": "xDSS2jyZ21Em"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some hyperparameters"
      ],
      "metadata": {
        "id": "RchRvTXlBMMJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "7e5edf6c"
      },
      "outputs": [],
      "source": [
        "hid_size = 200\n",
        "emb_size = 300\n",
        "\n",
        "lr = 0.0001 # learning rate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definition of loss for slots and intents"
      ],
      "metadata": {
        "id": "j0alqHlCB_Bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion_slots = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN) #we want to ignore the padding token\n",
        "criterion_intents = nn.CrossEntropyLoss() # Because we do not have the pad token"
      ],
      "metadata": {
        "id": "Yq9-PlVMYyH9"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train on ATIS"
      ],
      "metadata": {
        "id": "ztby1UCi4M3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ATIS_model = ModelIAS(hid_size, ATIS_out_slot, ATIS_out_int, emb_size, ATIS_vocab_len, pad_index=PAD_TOKEN).to(device)\n",
        "ATIS_model.apply(init_weights)\n",
        "ATIS_optimizer = optim.Adam(ATIS_model.parameters(), lr=lr) #take default parameters, just modify lr"
      ],
      "metadata": {
        "id": "cSRYOZSK4RBv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "f62ae1d4-f6ba-432a-f4d8-ab5878c1a3a6"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-accffe4f1c76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mATIS_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelIAS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhid_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mATIS_out_slot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mATIS_out_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mATIS_vocab_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPAD_TOKEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mATIS_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mATIS_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mATIS_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#take default parameters, just modify lr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    923\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    924\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 925\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "runs = 5\n",
        "slot_f1s, intent_acc = [], []\n",
        "ATIS_tot_losses_train, ATIS_tot_losses_dev = [], []\n",
        "ATIS_tot_losses_intent_train, ATIS_tot_losses_intent_dev = [], []\n",
        "ATIS_tot_losses_slot_train, ATIS_tot_losses_slot_dev = [], []\n",
        "ATIS_tot_sampled_epochs = []\n",
        "ATIS_tot_intent_test = []\n",
        "ATIS_tot_results_test = []\n",
        "\n",
        "for x in tqdm(range(0, runs)):\n",
        "    \n",
        "    ATIS_model = ModelIAS(hid_size, ATIS_out_slot, ATIS_out_int, emb_size, ATIS_vocab_len, pad_index=PAD_TOKEN).to(device)\n",
        "    ATIS_model.apply(init_weights)\n",
        "    ATIS_optimizer_adv = optim.Adam(ATIS_model.parameters(), lr=lr) #take default parameters, just modify lr\n",
        "    \n",
        "    results_test, intent_test, sampled_epochs, losses_train, losses_dev, loss_intent_train, loss_slot_train, loss_intent_dev_array, loss_slot_dev_array = train(\n",
        "        train_loader = ATIS_train_loader, \n",
        "        test_loader = ATIS_test_loader, \n",
        "        dev_loader = ATIS_dev_loader, \n",
        "        model = ATIS_model, \n",
        "        optimizer = ATIS_optimizer_adv,\n",
        "        lang = ATIS_lang) \n",
        "    \n",
        "    intent_acc.append(intent_test['accuracy'])\n",
        "    slot_f1s.append(results_test['total']['f'])\n",
        "    ATIS_tot_losses_train.append(losses_train)\n",
        "    ATIS_tot_losses_dev.append(losses_dev)\n",
        "    ATIS_tot_losses_intent_train.append(loss_intent_train)\n",
        "    ATIS_tot_losses_intent_dev.append(loss_intent_dev_array)\n",
        "    ATIS_tot_losses_slot_train.append(loss_slot_train)\n",
        "    ATIS_tot_losses_slot_dev.append(loss_slot_dev_array) \n",
        "    ATIS_tot_sampled_epochs.append(sampled_epochs)\n",
        "    ATIS_tot_intent_test.append(intent_test)\n",
        "    ATIS_tot_results_test.append(results_test)\n",
        "\n",
        "slot_f1s = np.asarray(slot_f1s)\n",
        "intent_acc = np.asarray(intent_acc)\n",
        "print('\\nSlot F1', round(slot_f1s.mean(),3), '+-', round(slot_f1s.std(),3))\n",
        "print('Intent Acc', round(intent_acc.mean(), 3), '+-', round(slot_f1s.std(), 3))"
      ],
      "metadata": {
        "id": "6KCkl9sVDHnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Intent classification analysis "
      ],
      "metadata": {
        "id": "td8aS0dbL_An"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = ATIS_tot_intent_test[0]\n",
        "print(\"Accuracy: \", x.pop('accuracy'))"
      ],
      "metadata": {
        "id": "tOrFJZx4Jboo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Macro average and weighted average"
      ],
      "metadata": {
        "id": "Y4FRt3oYSiNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg = {'weighted avg': x['weighted avg'], 'macro avg' :  x['macro avg']}\n",
        "x.pop('macro avg')\n",
        "x.pop('weighted avg')\n",
        "table = pd.DataFrame.from_dict(avg).transpose()\n",
        "table.round(decimals=3)"
      ],
      "metadata": {
        "id": "EvhiBIBHShZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10 best classified intent labels (based on F1-score):"
      ],
      "metadata": {
        "id": "o9DK0AdUMmqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best = dict(sorted(x.items(), key=lambda item: item[1]['f1-score'], reverse = True))\n",
        "table = pd.DataFrame.from_dict(best).transpose()[:10]\n",
        "table.round(decimals=3)"
      ],
      "metadata": {
        "id": "wiVIOJ3AzrN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10 worst classified intent labels (based on F1-score):"
      ],
      "metadata": {
        "id": "TnAVlNRCNI_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "worst = dict(sorted(x.items(), key=lambda item: item[1]['f1-score'], reverse = False))\n",
        "table = pd.DataFrame.from_dict(worst).transpose()[:10]\n",
        "table.round(decimals=3)"
      ],
      "metadata": {
        "id": "GQBHSkLeM7lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Slot filling analysis"
      ],
      "metadata": {
        "id": "eE76gMauNt9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = ATIS_tot_results_test[0]"
      ],
      "metadata": {
        "id": "FYKKYEgHN4tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15 best slot labels"
      ],
      "metadata": {
        "id": "Klh1OmQ5OVB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best = dict(sorted(x.items(), key=lambda item: item[1]['f'], reverse = True))\n",
        "table = pd.DataFrame.from_dict(best).transpose()[:15]\n",
        "table.round(decimals=3)"
      ],
      "metadata": {
        "id": "gHRIG5-yON0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15 worst slot labels"
      ],
      "metadata": {
        "id": "X6Q1CSsbOhZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "worst = dict(sorted(x.items(), key=lambda item: item[1]['f'], reverse = False))\n",
        "table = pd.DataFrame.from_dict(worst).transpose()[:15]\n",
        "table.round(decimals=3)"
      ],
      "metadata": {
        "id": "RDfwt1tiOjWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Losses plots "
      ],
      "metadata": {
        "id": "YbVBpalzCMPJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total loss plot"
      ],
      "metadata": {
        "id": "arwipReHB_Yg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(ATIS_tot_sampled_epochs[0], ATIS_tot_losses_train[0], ATIS_tot_losses_dev[0])"
      ],
      "metadata": {
        "id": "pvqRorfVzrN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Intent loss plot"
      ],
      "metadata": {
        "id": "OzB3BhYYCCiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(ATIS_tot_sampled_epochs[0], ATIS_tot_losses_intent_train[0], ATIS_tot_losses_intent_dev[0])"
      ],
      "metadata": {
        "id": "lSzbRKsezrN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Slot loss plot"
      ],
      "metadata": {
        "id": "iC_VI9M5CEVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(ATIS_tot_sampled_epochs[0], ATIS_tot_losses_slot_train[0], ATIS_tot_losses_slot_dev[0])"
      ],
      "metadata": {
        "id": "TqLEuN1UzrN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train on SNIPS"
      ],
      "metadata": {
        "id": "_-rNG8kn5Bjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "runs = 5\n",
        "slot_f1s, intent_acc = [], []\n",
        "SNIPS_tot_losses_train, SNIPS_tot_losses_dev = [], []\n",
        "SNIPS_tot_losses_intent_train, SNIPS_tot_losses_intent_dev = [], []\n",
        "SNIPS_tot_losses_slot_train, SNIPS_tot_losses_slot_dev = [], []\n",
        "SNIPS_tot_sampled_epochs = []\n",
        "SNIPS_tot_intent_test = []\n",
        "SNIPS_tot_results_test = []\n",
        " \n",
        "for x in tqdm(range(0, runs)):\n",
        "    \n",
        "    SNIPS_model_adv = ModelIAS(hid_size, SNIPS_out_slot, SNIPS_out_int, emb_size, SNIPS_vocab_len, pad_index=PAD_TOKEN).to(device)\n",
        "    SNIPS_model_adv.apply(init_weights)\n",
        "    SNIPS_optimizer_adv = optim.Adam(SNIPS_model_adv.parameters(), lr=lr) #take default parameters, just modify lr\n",
        "    \n",
        "    results_test, intent_test, sampled_epochs, losses_train, losses_dev, loss_intent_train, loss_slot_train, loss_intent_dev_array, loss_slot_dev_array = train(\n",
        "        train_loader = SNIPS_train_loader, \n",
        "        test_loader = SNIPS_test_loader, \n",
        "        dev_loader = SNIPS_dev_loader, \n",
        "        model = SNIPS_model_adv, \n",
        "        optimizer = SNIPS_optimizer_adv,\n",
        "        lang = SNIPS_lang) \n",
        "    \n",
        "    intent_acc.append(intent_test['accuracy'])\n",
        "    slot_f1s.append(results_test['total']['f'])\n",
        "    SNIPS_tot_losses_train.append(losses_train)\n",
        "    SNIPS_tot_losses_dev.append(losses_dev)\n",
        "    SNIPS_tot_losses_intent_train.append(loss_intent_train)\n",
        "    SNIPS_tot_losses_intent_dev.append(loss_intent_dev_array)\n",
        "    SNIPS_tot_losses_slot_train.append(loss_slot_train)\n",
        "    SNIPS_tot_losses_slot_dev.append(loss_slot_dev_array) \n",
        "    SNIPS_tot_sampled_epochs.append(sampled_epochs)\n",
        "    SNIPS_tot_intent_test.append(intent_test)\n",
        "    SNIPS_tot_results_test.append(results_test)\n",
        " \n",
        "slot_f1s = np.asarray(slot_f1s)\n",
        "intent_acc = np.asarray(intent_acc)\n",
        "print('\\nSlot F1', round(slot_f1s.mean(),3), '+-', round(slot_f1s.std(),3))\n",
        "print('Intent Acc', round(intent_acc.mean(), 3), '+-', round(slot_f1s.std(), 3))\n"
      ],
      "metadata": {
        "id": "o7lB9sFbaikg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Intent classification analysis "
      ],
      "metadata": {
        "id": "vopIwzbxPIeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = SNIPS_tot_intent_test[0]\n",
        "x.pop('accuracy')"
      ],
      "metadata": {
        "id": "meqjW8QlRKji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Macro average and weighted average"
      ],
      "metadata": {
        "id": "tQTo2yamRWxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg = {'weighted avg': x['weighted avg'], 'macro avg' :  x['macro avg']}\n",
        "x.pop('macro avg')\n",
        "x.pop('weighted avg')\n",
        "table = pd.DataFrame.from_dict(avg).transpose()\n",
        "table.round(decimals=3)"
      ],
      "metadata": {
        "id": "zd4u_E95PIeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classified intent labels (based on F1-score):"
      ],
      "metadata": {
        "id": "vcu97Fz2PIeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best = dict(sorted(x.items(), key=lambda item: item[1]['f1-score'], reverse = True))\n",
        "table = pd.DataFrame.from_dict(best).transpose()\n",
        "table.round(decimals=3)"
      ],
      "metadata": {
        "id": "Yvkwg57APIeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Slot filling analysis"
      ],
      "metadata": {
        "id": "2eO8I1vfPIeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = SNIPS_tot_results_test[0]"
      ],
      "metadata": {
        "id": "3foaT-dkPIeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15 best classified slot labels"
      ],
      "metadata": {
        "id": "NmbReV0CCWb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best = dict(sorted(x.items(), key=lambda item: item[1]['f'], reverse = True))\n",
        "table = pd.DataFrame.from_dict(best).transpose()[:15]\n",
        "table.round(decimals=3)"
      ],
      "metadata": {
        "id": "QJKzD5WyPIeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15 worst classified slot labels"
      ],
      "metadata": {
        "id": "KmDY16QOPIeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "worst = dict(sorted(x.items(), key=lambda item: item[1]['f'], reverse = False))\n",
        "table = pd.DataFrame.from_dict(worst).transpose()[:15]\n",
        "table.round(decimals=3)"
      ],
      "metadata": {
        "id": "oyveNqJyPIeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Losses plots"
      ],
      "metadata": {
        "id": "d2xT32bgCbYg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total loss plot"
      ],
      "metadata": {
        "id": "ywowtcRDEqA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(SNIPS_tot_sampled_epochs[0], SNIPS_tot_losses_train[0], SNIPS_tot_losses_dev[0])"
      ],
      "metadata": {
        "id": "GWI7FsCG0um6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Intent loss plot"
      ],
      "metadata": {
        "id": "J9DpYCV9Erb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(SNIPS_tot_sampled_epochs[0], SNIPS_tot_losses_intent_train[0], SNIPS_tot_losses_intent_dev[0])"
      ],
      "metadata": {
        "id": "6AxSxWYQ0um6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Slot loss plot"
      ],
      "metadata": {
        "id": "bHQzo5K8EtEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(SNIPS_tot_sampled_epochs[0], SNIPS_tot_losses_slot_train[0], SNIPS_tot_losses_slot_dev[0])"
      ],
      "metadata": {
        "id": "X9dY6mhv0um6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Second model: Bi-LSMT Model"
      ],
      "metadata": {
        "id": "lIhylzjzU_Nb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model_adv(nn.Module):\n",
        "#hidden size of rnn, embedding size (size of the vector that represent the word embedding)\n",
        "    def __init__(self, hid_size, out_slot, out_int, emb_size, vocab_len, n_layer=2, pad_index=0):\n",
        "        super(Model_adv, self).__init__()\n",
        "        # hid_size = Hidden size\n",
        "        # out_slot = number of slots (output size for slot filling)\n",
        "        # out_int = number of intents (ouput size for intent class)\n",
        "        # emb_size = word embedding size\n",
        "        \n",
        "        #A simple lookup table that stores embeddings of a fixed dictionary and size.\n",
        "        #The input to the module is a list of indices, and the output is the corresponding word embeddings.\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_len, \n",
        "                                      emb_size, \n",
        "                                      padding_idx=pad_index) #pad idx --> the entities at pad_index do not contribute to the gradient\n",
        "        \n",
        "        \"\"\"\n",
        "        num_embeddings (int) – size of the dictionary of embeddings\n",
        "\n",
        "        embedding_dim (int) – the size of each embedding vector\n",
        "\n",
        "        padding_idx (int, optional) – If specified, the entries at padding_idx do not contribute to the gradient; \n",
        "      \n",
        "        \"\"\"\n",
        "        self.utt_encoder = nn.LSTM(emb_size, \n",
        "                                   hid_size, \n",
        "                                   n_layer,\n",
        "                                   dropout=0.1,\n",
        "                                   bidirectional=True)     #network, bidirectional\n",
        "\n",
        "        \"\"\"  \n",
        "        input_size – The number of expected features in the input x\n",
        "        hidden_size – The number of features in the hidden state h\n",
        "        num_layers – Number of recurrent layers. \n",
        "        \"\"\"\n",
        "        #regularization --> randomly mute a neuron, only on training phase. Helps to avoid overfitting\n",
        "        self.dropout = nn.Dropout(0.6)\n",
        "\n",
        "        self.slot_out = nn.Linear(hid_size*2, out_slot)\n",
        "\n",
        "        self.intent_out = nn.Linear(hid_size, out_int)\n",
        "      \n",
        "        \n",
        "    def forward(self, utterance, seq_lengths): #define the architecture\n",
        "        # utterance.size() = batch_size X seq_len\n",
        "        utt_emb = self.embedding(utterance) # utt_emb.size() = batch_size X seq_len X emb_size\n",
        "\n",
        "        #--> get word embedding\n",
        "        utt_emb = utt_emb.permute(1,0,2) # we need seq len first -> seq_len X batch_size X emb_size\n",
        "        \n",
        "        # pack_padded_sequence avoid computation over pad tokens reducing the computational cost\n",
        "\n",
        "        utt_emb_drop = self.dropout(utt_emb)\n",
        "        \n",
        "        packed_input = pack_padded_sequence(utt_emb_drop, seq_lengths.cpu().numpy())\n",
        "        # Process the batch\n",
        "        packed_output, (last_hidden, cell) = self.utt_encoder(packed_input) \n",
        "        \n",
        "        # Unpack the sequence\n",
        "        utt_encoded, input_sizes = pad_packed_sequence(packed_output)\n",
        "        #utt_encoded.shape: [sentence lenght, 128, 200] \n",
        "\n",
        "        # Get the last hidden state\n",
        "        #last_hidde.shape: [1, 128, 200]\n",
        "        #last_hidde.shape: [128, 200] -> [batch size, hidden_size]\n",
        "\n",
        "        hidden_conv = last_hidden\n",
        "\n",
        "        hidden_conv = hidden_conv[-1,:,:]\n",
        "\n",
        "        drop_utt = self.dropout(utt_encoded)\n",
        "        drop_hidden = self.dropout(hidden_conv)\n",
        "       \n",
        "        # Compute slot logits, i use the encoded representation of the utterance, with the encoding of each word\n",
        "        slots = self.slot_out(drop_utt)\n",
        "\n",
        "        intent = self.intent_out(drop_hidden)\n",
        "       \n",
        "        slots = slots.permute(1,2,0) # We need this for computing the loss\n",
        "\n",
        "        return slots, intent"
      ],
      "metadata": {
        "id": "76kccv_huSiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train Methods"
      ],
      "metadata": {
        "id": "ghf7BC0sNfbU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train loops that outputs also the intent and slot losses"
      ],
      "metadata": {
        "id": "YgnoQiJKKtd3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y40BsHiRKlgi"
      },
      "outputs": [],
      "source": [
        "from conll import evaluate\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def train_loop_adv(data, optimizer, criterion_slots, criterion_intents, model):\n",
        "    model.train()\n",
        "    loss_array = []\n",
        "    loss_intent_array = []\n",
        "    loss_slot_array = []\n",
        "    for sample in data:\n",
        "        optimizer.zero_grad() # Zeroing the gradient\n",
        "        slots, intent = model(sample['utterances'], sample['slots_len'])\n",
        "        loss_intent = criterion_intents(intent, sample['intents'])\n",
        "\n",
        "        loss_slot = criterion_slots(slots, sample['y_slots'])\n",
        "\n",
        "        loss_intent_array.append(loss_intent.item())\n",
        "        loss_slot_array.append(loss_slot.item())\n",
        "\n",
        "        if random.random() > 0.8:\n",
        "          alfa = random.random()\n",
        "        else: \n",
        "          alfa = 0.3\n",
        "\n",
        "        loss = alfa*loss_intent + (1-alfa)*loss_slot \n",
        "\n",
        "        loss_array.append(loss.item())\n",
        "        loss.backward() # Compute the gradient, deleting the computational graph\n",
        "        optimizer.step() # Update the weights\n",
        "    return loss_array, loss_intent_array, loss_slot_array\n",
        "\n",
        "def eval_loop_adv(data, criterion_slots, criterion_intents, model, lang):\n",
        "    model.eval()\n",
        "    loss_array = []\n",
        "    loss_intent_array = []\n",
        "    loss_slot_array = []\n",
        "    \n",
        "    ref_intents = []\n",
        "    hyp_intents = []\n",
        "    \n",
        "    ref_slots = []\n",
        "    hyp_slots = []\n",
        "    #softmax = nn.Softmax(dim=1) # Use Softmax if you need the actual probability\n",
        "    with torch.no_grad(): # It used to avoid the creation of computational graph\n",
        "        for sample in data:\n",
        "            slots, intents = model(sample['utterances'], sample['slots_len'])\n",
        "            loss_intent = criterion_intents(intents, sample['intents'])\n",
        "            loss_slot = criterion_slots(slots, sample['y_slots'])\n",
        "            loss = loss_intent + loss_slot \n",
        "\n",
        "            loss_intent_array.append(loss_intent.item())\n",
        "            loss_slot_array.append(loss_slot.item())\n",
        "            loss_array.append(loss.item())\n",
        "            # Intent inference\n",
        "            # Get the highest probable class\n",
        "            out_intents = [lang.id2intent[x] \n",
        "                           for x in torch.argmax(intents, dim=1).tolist()] \n",
        "            gt_intents = [lang.id2intent[x] for x in sample['intents'].tolist()]\n",
        "            ref_intents.extend(gt_intents)\n",
        "            hyp_intents.extend(out_intents)\n",
        "            \n",
        "            # Slot inference \n",
        "            output_slots = torch.argmax(slots, dim=1)\n",
        "            for id_seq, seq in enumerate(output_slots):\n",
        "                length = sample['slots_len'].tolist()[id_seq]\n",
        "                utt_ids = sample['utterance'][id_seq][:length].tolist()\n",
        "                gt_ids = sample['y_slots'][id_seq].tolist()\n",
        "                gt_slots = [lang.id2slot[elem] for elem in gt_ids[:length]]\n",
        "                utterance = [lang.id2word[elem] for elem in utt_ids]\n",
        "                to_decode = seq[:length].tolist()\n",
        "                ref_slots.append([(utterance[id_el], elem) for id_el, elem in enumerate(gt_slots)])\n",
        "                tmp_seq = []\n",
        "                for id_el, elem in enumerate(to_decode):\n",
        "                    tmp_seq.append((utterance[id_el], lang.id2slot[elem]) if elem != 0 else (utterance[id_el], 'O'))\n",
        "                hyp_slots.append(tmp_seq)\n",
        "                #print(hyp_slots)\n",
        "    try:            \n",
        "        results = evaluate(ref_slots, hyp_slots)\n",
        "    except Exception as ex: #if your model predict slot that are not in ref, it gives error\n",
        "        # Sometimes the model predics a class that is not in REF\n",
        "        print(ex)\n",
        "        ref_s = set([x[1] for x in ref_slots])\n",
        "        hyp_s = set([x[1] for x in hyp_slots])\n",
        "        print(hyp_s.difference(ref_s))\n",
        "        \n",
        "    report_intent = classification_report(ref_intents, hyp_intents, \n",
        "                                          zero_division=False, output_dict=True)\n",
        "    \n",
        "    return results, report_intent, loss_array, loss_intent_array, loss_slot_array\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_adv(train_loader, test_loader, dev_loader, model, criterion_slots, criterion_intents, optimizer, lang, n_epochs=200, patience=3, train=True):\n",
        " \n",
        "  losses_train = []\n",
        "  loss_intent_train = []\n",
        "  loss_slot_train = []\n",
        "  losses_dev = [] \n",
        "  loss_intent_dev_array = []\n",
        "  loss_slot_dev_array= []\n",
        "\n",
        "  sampled_epochs = []\n",
        "  best_f1 = 0\n",
        "  last_loss = 0\n",
        "  for x in tqdm(range(1,n_epochs)):\n",
        "      if train:\n",
        "        loss, loss_intent, loss_slot = train_loop_adv(train_loader, optimizer, criterion_slots, \n",
        "                          criterion_intents, model)\n",
        "        if x % 3 == 0:\n",
        "            sampled_epochs.append(x)\n",
        "            losses_train.append(np.asarray(loss).mean())\n",
        "            loss_intent_train.append(np.asarray(loss_intent).mean())\n",
        "            loss_slot_train.append(np.asarray(loss_slot).mean())\n",
        "\n",
        "            results_dev, intent_res, loss_dev, loss_intent_dev, loss_slot_dev = eval_loop_adv(dev_loader, criterion_slots, \n",
        "                                                          criterion_intents, model, lang)\n",
        "            losses_dev.append(np.asarray(loss_dev).mean())\n",
        "            loss_intent_dev_array.append(np.asarray(loss_intent_dev).mean())\n",
        "            loss_slot_dev_array.append(np.asarray(loss_slot_dev).mean())\n",
        "            f1 = results_dev['total']['f']\n",
        "            accuracy = intent_res['accuracy']\n",
        "            #print('\\nSlot F1: ', results_dev['total']['f'])\n",
        "            #print('Intent Accuracy:', intent_res['accuracy'])\n",
        "            \n",
        "\n",
        "            if f1 > best_f1: #sometimes loss words but f1 increases, we have to look at both and figure out what of the 2 to use to stop the training\n",
        "                best_f1 = f1\n",
        "            else:\n",
        "                patience -= 1\n",
        "\n",
        "            if patience <= 0: # Early stopping with patience\n",
        "                break # Not nice but it keeps the code clean\n",
        "\n",
        "  results_test, intent_test, _ , _ , _ = eval_loop_adv(test_loader, criterion_slots, \n",
        "                                          criterion_intents, model, lang)    \n",
        "  print('\\nSlot F1: ', results_test['total']['f'])\n",
        "  print('Intent Accuracy:', intent_test['accuracy'])\n",
        "  return results_test, intent_test, sampled_epochs, losses_train, losses_dev, loss_intent_train, loss_slot_train, loss_intent_dev_array, loss_slot_dev_array"
      ],
      "metadata": {
        "id": "Eurl1BAQnnRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some hyperparameters"
      ],
      "metadata": {
        "id": "hzW4GxQyDpYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emb_size = 400\n",
        "hid_size = 400\n",
        "\n",
        "lr = 0.0001"
      ],
      "metadata": {
        "id": "TIta_PURDskq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Losses definition"
      ],
      "metadata": {
        "id": "pKeTh4f_DxQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion_slots = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN) #we want to ignore the padding token\n",
        "criterion_intents = nn.CrossEntropyLoss() # Because we do not have the pad token"
      ],
      "metadata": {
        "id": "EiyKydiUuoJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train on ATIS "
      ],
      "metadata": {
        "id": "CJk5tYrAqZ6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "runs = 5\n",
        "slot_f1s, intent_acc = [], []\n",
        "ATIS_tot_losses_train, ATIS_tot_losses_dev = [], []\n",
        "ATIS_tot_losses_intent_train, ATIS_tot_losses_intent_dev = [], []\n",
        "ATIS_tot_losses_slot_train, ATIS_tot_losses_slot_dev = [], []\n",
        "ATIS_tot_sampled_epochs = []\n",
        "ATIS_tot_intent_test = []\n",
        "ATIS_tot_results_test = []\n",
        "\n",
        "for x in tqdm(range(0, runs)):\n",
        "    \n",
        "    ATIS_model_adv = Model_adv(hid_size, ATIS_out_slot, ATIS_out_int, emb_size, ATIS_vocab_len, pad_index=PAD_TOKEN).to(device)\n",
        "    ATIS_model_adv.apply(init_weights)\n",
        "    ATIS_optimizer_adv = optim.Adam(ATIS_model_adv.parameters(), lr=lr) #take default parameters, just modify lr\n",
        "    \n",
        "    results_test, intent_test, sampled_epochs, losses_train, losses_dev, loss_intent_train, loss_slot_train, loss_intent_dev_array, loss_slot_dev_array = train_adv(\n",
        "        train_loader = ATIS_train_loader, \n",
        "        test_loader = ATIS_test_loader, \n",
        "        dev_loader = ATIS_dev_loader, \n",
        "        model = ATIS_model_adv, \n",
        "        criterion_slots = criterion_slots,\n",
        "        criterion_intents = criterion_intents,\n",
        "        optimizer = ATIS_optimizer_adv,\n",
        "        lang = ATIS_lang,\n",
        "        patience=5) \n",
        "    \n",
        "    intent_acc.append(intent_test['accuracy'])\n",
        "    slot_f1s.append(results_test['total']['f'])\n",
        "    ATIS_tot_losses_train.append(losses_train)\n",
        "    ATIS_tot_losses_dev.append(losses_dev)\n",
        "    ATIS_tot_losses_intent_train.append(loss_intent_train)\n",
        "    ATIS_tot_losses_intent_dev.append(loss_intent_dev_array)\n",
        "    ATIS_tot_losses_slot_train.append(loss_slot_train)\n",
        "    ATIS_tot_losses_slot_dev.append(loss_slot_dev_array) \n",
        "    ATIS_tot_sampled_epochs.append(sampled_epochs)\n",
        "    ATIS_tot_intent_test.append(intent_test)\n",
        "    ATIS_tot_results_test.append(results_test)\n",
        "\n",
        "slot_f1s = np.asarray(slot_f1s)\n",
        "intent_acc = np.asarray(intent_acc)\n",
        "print('\\nSlot F1', round(slot_f1s.mean(),3), '+-', round(slot_f1s.std(),3))\n",
        "print('Intent Acc', round(intent_acc.mean(), 3), '+-', round(slot_f1s.std(), 3))"
      ],
      "metadata": {
        "id": "3Dxe0saGnnMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Intent classification analysis "
      ],
      "metadata": {
        "id": "N9shZfUltLjH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy"
      ],
      "metadata": {
        "id": "Q98BLjsoy1FY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = ATIS_tot_intent_test[0]\n",
        "x.pop('accuracy')"
      ],
      "metadata": {
        "id": "olpLH1QetLjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Macro average and weighted average"
      ],
      "metadata": {
        "id": "dMbEQkYztLjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg = {'weighted avg': x['weighted avg'], 'macro avg' :  x['macro avg']}\n",
        "x.pop('macro avg')\n",
        "x.pop('weighted avg')\n",
        "table = pd.DataFrame.from_dict(avg).transpose()\n",
        "table.round(decimals=3)"
      ],
      "metadata": {
        "id": "bDEVGKtvtLjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10 best classified intent labels (based on F1-score):"
      ],
      "metadata": {
        "id": "68sYXf42tLjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best = dict(sorted(x.items(), key=lambda item: item[1]['f1-score'], reverse = True))\n",
        "table = pd.DataFrame.from_dict(best).transpose()[:10]\n",
        "table.round(decimals=3)"
      ],
      "metadata": {
        "id": "FkqEfwH2tLjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10 worst classified intent labels (based on F1-score):"
      ],
      "metadata": {
        "id": "lF4QvniitLjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "worst = dict(sorted(x.items(), key=lambda item: item[1]['f1-score'], reverse = False))\n",
        "table = pd.DataFrame.from_dict(worst).transpose()[:10]\n",
        "table.round(decimals=3)"
      ],
      "metadata": {
        "id": "yXXPHDUqtLjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Slot filling analysis"
      ],
      "metadata": {
        "id": "daGwBTnEtLjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = ATIS_tot_results_test[0]"
      ],
      "metadata": {
        "id": "Qdnhtgo7tLjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15 best classified slot labels"
      ],
      "metadata": {
        "id": "QHZRWsb3tLjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best = dict(sorted(x.items(), key=lambda item: item[1]['f'], reverse = True))\n",
        "table = pd.DataFrame.from_dict(best).transpose()[:15]\n",
        "table.round(decimals=3)"
      ],
      "metadata": {
        "id": "eBVNAvdYtLjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15 worst classified slot labels"
      ],
      "metadata": {
        "id": "0Ytc7gjvtLjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "worst = dict(sorted(x.items(), key=lambda item: item[1]['f'], reverse = False))\n",
        "table = pd.DataFrame.from_dict(worst).transpose()[:15]\n",
        "table.round(decimals=3)"
      ],
      "metadata": {
        "id": "G4STiyG1tLjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Losses Plots "
      ],
      "metadata": {
        "id": "pgt-ueY2EiMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total loss plot"
      ],
      "metadata": {
        "id": "D_rTEROVElMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(ATIS_tot_sampled_epochs[0], ATIS_tot_losses_train[0], ATIS_tot_losses_dev[0])"
      ],
      "metadata": {
        "id": "ajWWJ_fx07kS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Intent loss plot "
      ],
      "metadata": {
        "id": "neN8gPDoEzu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(ATIS_tot_sampled_epochs[0], ATIS_tot_losses_intent_train[0], ATIS_tot_losses_intent_dev[0])"
      ],
      "metadata": {
        "id": "iD35ZPRgUpbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Slot loss plot"
      ],
      "metadata": {
        "id": "fr5gQOFCE1SJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(ATIS_tot_sampled_epochs[0], ATIS_tot_losses_slot_train[0], ATIS_tot_losses_slot_dev[0])"
      ],
      "metadata": {
        "id": "vcFsV21mUplN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train on SNIPS"
      ],
      "metadata": {
        "id": "5IThtpUxqefc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "runs = 5\n",
        "slot_f1s, intent_acc = [], []\n",
        "SNIPS_tot_losses_train, SNIPS_tot_losses_dev = [], []\n",
        "SNIPS_tot_losses_intent_train, SNIPS_tot_losses_intent_dev = [], []\n",
        "SNIPS_tot_losses_slot_train, SNIPS_tot_losses_slot_dev = [], []\n",
        "SNIPS_tot_sampled_epochs = []\n",
        " \n",
        "for x in tqdm(range(0, runs)):\n",
        "\n",
        "    SNIPS_model_adv = Model_adv(hid_size, SNIPS_out_slot, SNIPS_out_int, emb_size, SNIPS_vocab_len, pad_index=PAD_TOKEN).to(device)\n",
        "    SNIPS_model_adv.apply(init_weights)\n",
        "    SNIPS_optimizer_adv = optim.Adam(SNIPS_model_adv.parameters(), lr=lr) #take default parameters, just modify lr\n",
        "    \n",
        "    results_test, intent_test, sampled_epochs, losses_train, losses_dev, loss_intent_train, loss_slot_train, loss_intent_dev_array, loss_slot_dev_array = train_adv(\n",
        "        train_loader = SNIPS_train_loader, \n",
        "        test_loader = SNIPS_test_loader, \n",
        "        dev_loader = SNIPS_dev_loader, \n",
        "        model = SNIPS_model_adv, \n",
        "        criterion_slots = criterion_slots,\n",
        "        criterion_intents = criterion_intents,\n",
        "        optimizer = SNIPS_optimizer_adv,\n",
        "        lang = SNIPS_lang,\n",
        "        patience=5)\n",
        "    \n",
        "    intent_acc.append(intent_test['accuracy'])\n",
        "    slot_f1s.append(results_test['total']['f'])\n",
        "    SNIPS_tot_losses_train.append(losses_train)\n",
        "    SNIPS_tot_losses_dev.append(losses_dev)\n",
        "    SNIPS_tot_losses_intent_train.append(loss_intent_train)\n",
        "    SNIPS_tot_losses_intent_dev.append(loss_intent_dev_array)\n",
        "    SNIPS_tot_losses_slot_train.append(loss_slot_train)\n",
        "    SNIPS_tot_losses_slot_dev.append(loss_slot_dev_array) \n",
        "    SNIPS_tot_sampled_epochs.append(sampled_epochs)\n",
        " \n",
        "slot_f1s = np.asarray(slot_f1s)\n",
        "intent_acc = np.asarray(intent_acc)\n",
        "print('\\nSlot F1', round(slot_f1s.mean(),3), '+-', round(slot_f1s.std(),3))\n",
        "print('Intent Acc', round(intent_acc.mean(), 3), '+-', round(slot_f1s.std(), 3))"
      ],
      "metadata": {
        "id": "r-vg-wO8qheH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Intent classification analysis "
      ],
      "metadata": {
        "id": "swrxM1NR-BSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = SNIPS_tot_intent_test[0]\n",
        "x.pop('accuracy')"
      ],
      "metadata": {
        "id": "sTAQ7C2e-BSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Macro average and weighted average"
      ],
      "metadata": {
        "id": "KT9txNWC-BSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg = {'weighted avg': x['weighted avg'], 'macro avg' :  x['macro avg']}\n",
        "x.pop('macro avg')\n",
        "x.pop('weighted avg')\n",
        "table = pd.DataFrame.from_dict(avg).transpose()\n",
        "table.round(decimals=3)"
      ],
      "metadata": {
        "id": "mlctqWY0-BSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "classified intent labels (based on F1-score):"
      ],
      "metadata": {
        "id": "CNx97Z1C-BSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best = dict(sorted(x.items(), key=lambda item: item[1]['f1-score'], reverse = True))\n",
        "table = pd.DataFrame.from_dict(best).transpose()\n",
        "table.round(decimals=3)"
      ],
      "metadata": {
        "id": "B1vwC2c_-BSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Slot filling analysis"
      ],
      "metadata": {
        "id": "uB7JJbEK-BSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = SNIPS_tot_results_test[0]"
      ],
      "metadata": {
        "id": "EN1bXuaW-BSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15 best classified slots"
      ],
      "metadata": {
        "id": "RWOldOuBFHnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best = dict(sorted(x.items(), key=lambda item: item[1]['f'], reverse = True))\n",
        "table = pd.DataFrame.from_dict(best).transpose()[:15]\n",
        "table.round(decimals=3)"
      ],
      "metadata": {
        "id": "98478aDx-BSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15 worst classified slot labels"
      ],
      "metadata": {
        "id": "PfP2QtPK-BSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "worst = dict(sorted(x.items(), key=lambda item: item[1]['f'], reverse = False))\n",
        "table = pd.DataFrame.from_dict(worst).transpose()[:15]\n",
        "table.round(decimals=3)"
      ],
      "metadata": {
        "id": "Mh2O1LSJ-BSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Losses Plots"
      ],
      "metadata": {
        "id": "0JweE6U-FN5X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total loss plot "
      ],
      "metadata": {
        "id": "SsvTgFUCFQQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(SNIPS_tot_sampled_epochs[0], SNIPS_tot_losses_train[0], SNIPS_tot_losses_dev[0])"
      ],
      "metadata": {
        "id": "eKRq_k0cUp28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Intent loss plot "
      ],
      "metadata": {
        "id": "KcQtAL7cFRmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(SNIPS_tot_sampled_epochs[0], SNIPS_tot_losses_intent_train[0], SNIPS_tot_losses_intent_dev[0])"
      ],
      "metadata": {
        "id": "PbbeDEHnUp9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Slot loss plot "
      ],
      "metadata": {
        "id": "d5W-ZKY2FUss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(SNIPS_tot_sampled_epochs[0], SNIPS_tot_losses_slot_train[0], SNIPS_tot_losses_slot_dev[0])"
      ],
      "metadata": {
        "id": "h0M6OpFaUqCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Third model: BERT Model"
      ],
      "metadata": {
        "id": "Xihe-20hWwcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "edCcLhP0c5eN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e9d7236-bfb9-4b1f-f7a5-d8e077d77faf"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 13.6 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 59.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 38.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT model script from: huggingface.co\n",
        "from transformers import BertModel, BertConfig"
      ],
      "metadata": {
        "id": "jjHD55flXE66"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Bert_model(nn.Module):\n",
        "#hidden size of rnn, embedding size (size of the vector that represent the word embedding)\n",
        "    def __init__(self, hid_size, out_slot, out_int, emb_size, vocab_len, pad_index=0):\n",
        "        super(Bert_model, self).__init__()\n",
        "        \n",
        "        #self.embedding = nn.Embedding(vocab_len, \n",
        "        #                              emb_size, \n",
        "        #                              padding_idx=pad_index) #pad idx --> the entities at pad_index do not contribute to the gradient\n",
        "\n",
        "        config = BertConfig(vocab_size=vocab_len)\n",
        "        \n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\", config = config, ignore_mismatched_sizes=True)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "        self.slot_out = nn.Linear(768, out_slot)\n",
        "\n",
        "        self.intent_out = nn.Linear(768, out_int)\n",
        "      \n",
        "        \n",
        "    def forward(self, utterance, seq_lengths): \n",
        "\n",
        "        #utt_emb = self.embedding(utterance) # utt_emb.size() = batch_size X seq_len X emb_size\n",
        "\n",
        "        #utt_emb = utt_emb.permute(1,0,2) # we need seq len first -> seq_len X batch_size X emb_size\n",
        "           \n",
        "        output = self.bert(utterance) \n",
        "\n",
        "        hidden_slot = output.last_hidden_state\n",
        "        hidden_slot = hidden_slot.permute(1,0,2) \n",
        "\n",
        "        utt_encoded = output.pooler_output\n",
        "\n",
        "        drop_utt = self.dropout(utt_encoded)\n",
        "        drop_hidden = self.dropout(hidden_slot)\n",
        "\n",
        "        slots = self.slot_out(drop_hidden)\n",
        "\n",
        "        intent = self.intent_out(drop_utt)\n",
        "\n",
        "        slots = slots.permute(1,2,0) # We need this for computing the loss\n",
        "\n",
        "        return slots, intent"
      ],
      "metadata": {
        "id": "OGIQ86j3WvvY"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train on ATIS"
      ],
      "metadata": {
        "id": "Czjs6rJRF6vQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "runs = 1\n",
        "slot_f1s, intent_acc = [], []\n",
        "ATIS_tot_losses_train, ATIS_tot_losses_dev = [], []\n",
        "ATIS_tot_losses_intent_train, ATIS_tot_losses_intent_dev = [], []\n",
        "ATIS_tot_losses_slot_train, ATIS_tot_losses_slot_dev = [], []\n",
        "ATIS_tot_sampled_epochs = []\n",
        " \n",
        "for x in tqdm(range(0, runs)):\n",
        "    \n",
        "    ATIS_model_bert = Bert_model(hid_size, ATIS_out_slot, ATIS_out_int, emb_size, ATIS_vocab_len, pad_index=PAD_TOKEN).to(device)\n",
        "    ATIS_model_bert.apply(init_weights)\n",
        "    ATIS_optimizer_bert = optim.Adam(ATIS_model_bert.parameters(), lr=lr) #take default parameters, just modify lr\n",
        "    \n",
        "    results_test, intent_test, sampled_epochs, losses_train, losses_dev, loss_intent_train, loss_slot_train, loss_intent_dev_array, loss_slot_dev_array = train_adv(\n",
        "        train_loader = ATIS_train_loader, \n",
        "        test_loader = ATIS_test_loader, \n",
        "        dev_loader = ATIS_dev_loader, \n",
        "        model = ATIS_model_bert, \n",
        "        criterion_slots = criterion_slots,\n",
        "        criterion_intents = criterion_intents,\n",
        "        optimizer = ATIS_optimizer_bert,\n",
        "        lang = ATIS_lang,\n",
        "        patience=8)\n",
        "    \n",
        "    intent_acc.append(intent_test['accuracy'])\n",
        "    slot_f1s.append(results_test['total']['f'])\n",
        "    ATIS_tot_losses_train.append(losses_train)\n",
        "    ATIS_tot_losses_dev.append(losses_dev)\n",
        "    ATIS_tot_losses_intent_train.append(loss_intent_train)\n",
        "    ATIS_tot_losses_intent_dev.append(loss_intent_dev_array)\n",
        "    ATIS_tot_losses_slot_train.append(loss_slot_train)\n",
        "    ATIS_tot_losses_slot_dev.append(loss_slot_dev_array) \n",
        "    ATIS_tot_sampled_epochs.append(sampled_epochs)\n",
        " \n",
        "slot_f1s = np.asarray(slot_f1s)\n",
        "intent_acc = np.asarray(intent_acc)\n",
        "print('\\nSlot F1', round(slot_f1s.mean(),3), '+-', round(slot_f1s.std(),3))\n",
        "print('Intent Acc', round(intent_acc.mean(), 3), '+-', round(slot_f1s.std(), 3))"
      ],
      "metadata": {
        "id": "Xe7isvZk1nyF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309,
          "referenced_widgets": [
            "b0f6519363854974810a92c69e572157",
            "b668ec350d634a32bfd0fb0bc753d87a",
            "5740f58f84c34a7e99f4984db13b956e",
            "900fedd80c984cdaa1df431f4105c2c0",
            "a7395d0b5ee54e66ae7d9ea177ecd3b1",
            "06bd04b9f45e4b2ca28e34b9c754f10d",
            "2c73d229ee7541c1aaaad011b778ac17",
            "239b4b7a0c17452c92ac6a4d89ae2a36",
            "1c306494f41b44a9a017adce5e4286d7",
            "21111f4e1d6648469abb292abb5b2a48",
            "68599ee639e842c2b60698074d3ae49d",
            "3fc367d32f4747afbe6379241d72ba91",
            "12d973bbeeab4dcd820f0b1ac9d6b8d8",
            "0c2749ba96854a09a48d33006c598696",
            "3178e1bdc24a407ea2e04b2071c54c5a",
            "80303f59b7ef4ac1ba9897af6b2f8ae8",
            "83f5c7c431314521bb9d91bfc8a35aec",
            "1c465efdb5204bb28f6ef17068716654",
            "37eef8c9c2384f6b8742fa5f8e328583",
            "d6c2604234224cf8ad51871e77508d0b",
            "db10a3b69a324900a0f53d8d37380041",
            "29239bb39e234d40bc1929f514e001f3"
          ]
        },
        "outputId": "db6124cc-7447-4151-f781-b3fa6413b810"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0f6519363854974810a92c69e572157"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized because the shapes did not match:\n",
            "- bert.embeddings.word_embeddings.weight: found shape torch.Size([30522, 768]) in the checkpoint and torch.Size([863, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/199 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3fc367d32f4747afbe6379241d72ba91"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Slot F1:  0.0\n",
            "Intent Accuracy: 0.7077267637178052\n",
            "\n",
            "Slot F1 0.0 +- 0.0\n",
            "Intent Acc 0.708 +- 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Intent classification analysis "
      ],
      "metadata": {
        "id": "27uyPjtVF4lo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy"
      ],
      "metadata": {
        "id": "SPeLrID9F4lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = ATIS_tot_intent_test[0]\n",
        "x.pop('accuracy')"
      ],
      "metadata": {
        "id": "ivWTVZaFF4lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Macro average and weighted average"
      ],
      "metadata": {
        "id": "xhsaSTzFF4lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg = {'weighted avg': x['weighted avg'], 'macro avg' :  x['macro avg']}\n",
        "x.pop('macro avg')\n",
        "x.pop('weighted avg')\n",
        "table = pd.DataFrame.from_dict(avg).transpose()\n",
        "table.round(decimals=3)"
      ],
      "metadata": {
        "id": "jupaoFHaF4lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10 best classified intent labels (based on F1-score):"
      ],
      "metadata": {
        "id": "1ZAkELWYF4lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best = dict(sorted(x.items(), key=lambda item: item[1]['f1-score'], reverse = True))\n",
        "table = pd.DataFrame.from_dict(best).transpose()[:10]\n",
        "table.round(decimals=3)"
      ],
      "metadata": {
        "id": "wJF0lAfAF4lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10 worst classified intent labels (based on F1-score):"
      ],
      "metadata": {
        "id": "fkGhnMDYF4lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "worst = dict(sorted(x.items(), key=lambda item: item[1]['f1-score'], reverse = False))\n",
        "table = pd.DataFrame.from_dict(worst).transpose()[:10]\n",
        "table.round(decimals=3)"
      ],
      "metadata": {
        "id": "l70ZpFfZF4lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Slot filling analysis"
      ],
      "metadata": {
        "id": "Fr3WfunpF4lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = ATIS_tot_results_test[0]"
      ],
      "metadata": {
        "id": "2xsMzDQ8F4lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15 best classified slot labels"
      ],
      "metadata": {
        "id": "DjI1NIChF4lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best = dict(sorted(x.items(), key=lambda item: item[1]['f'], reverse = True))\n",
        "table = pd.DataFrame.from_dict(best).transpose()[:15]\n",
        "table.round(decimals=3)"
      ],
      "metadata": {
        "id": "YfXT1TbhF4lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15 worst classified slot labels"
      ],
      "metadata": {
        "id": "scYQReLTF4lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "worst = dict(sorted(x.items(), key=lambda item: item[1]['f'], reverse = False))\n",
        "table = pd.DataFrame.from_dict(worst).transpose()[:15]\n",
        "table.round(decimals=3)"
      ],
      "metadata": {
        "id": "w-Orcu2cF4lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Losses Plots "
      ],
      "metadata": {
        "id": "1_u_9D6OF4lq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total loss plot"
      ],
      "metadata": {
        "id": "HFxADvCjF4lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(ATIS_tot_sampled_epochs[0], ATIS_tot_losses_train[0], ATIS_tot_losses_dev[0])"
      ],
      "metadata": {
        "id": "4fmx3ghkF4lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Intent loss plot "
      ],
      "metadata": {
        "id": "Kjrczh_kF4lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(ATIS_tot_sampled_epochs[0], ATIS_tot_losses_intent_train[0], ATIS_tot_losses_intent_dev[0])"
      ],
      "metadata": {
        "id": "HnoBEz_mF4lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Slot loss plot"
      ],
      "metadata": {
        "id": "P_pTaUG6F4lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(ATIS_tot_sampled_epochs[0], ATIS_tot_losses_slot_train[0], ATIS_tot_losses_slot_dev[0])"
      ],
      "metadata": {
        "id": "Q74M8fWtF4lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train on SNIPS "
      ],
      "metadata": {
        "id": "I2HHFbarGEEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "runs = 1\n",
        "slot_f1s, intent_acc = [], []\n",
        "SNIPS_tot_losses_train, SNIPS_tot_losses_dev = [], []\n",
        "SNIPS_tot_losses_intent_train, SNIPS_tot_losses_intent_dev = [], []\n",
        "SNIPS_tot_losses_slot_train, SNIPS_tot_losses_slot_dev = [], []\n",
        "SNIPS_tot_sampled_epochs = []\n",
        " \n",
        "for x in tqdm(range(0, runs)):\n",
        "    \n",
        "    SNIPS_model_bert = Bert_model(hid_size, SNIPS_out_slot, SNIPS_out_int, emb_size, SNIPS_vocab_len, pad_index=PAD_TOKEN).to(device)\n",
        "    SNIPS_model_adv.apply(init_weights)\n",
        "    SNIPS_optimizer_bert = optim.Adam(SNIPS_model_bert.parameters(), lr=lr) #take default parameters, just modify lr\n",
        "    \n",
        "    results_test, intent_test, sampled_epochs, losses_train, losses_dev, loss_intent_train, loss_slot_train, loss_intent_dev_array, loss_slot_dev_array = train_adv(\n",
        "        train_loader = SNIPS_train_loader, \n",
        "        test_loader = SNIPS_test_loader, \n",
        "        dev_loader = SNIPS_dev_loader, \n",
        "        model = SNIPS_model_bert, \n",
        "        criterion_slots = criterion_slots,\n",
        "        criterion_intents = criterion_intents,\n",
        "        optimizer = SNIPS_optimizer_bert,\n",
        "        lang = SNIPS_lang,\n",
        "        patience=8)\n",
        "    \n",
        "    intent_acc.append(intent_test['accuracy'])\n",
        "    slot_f1s.append(results_test['total']['f'])\n",
        "    SNIPS_tot_losses_train.append(losses_train)\n",
        "    SNIPS_tot_losses_dev.append(losses_dev)\n",
        "    SNIPS_tot_losses_intent_train.append(loss_intent_train)\n",
        "    SNIPS_tot_losses_intent_dev.append(loss_intent_dev_array)\n",
        "    SNIPS_tot_losses_slot_train.append(loss_slot_train)\n",
        "    SNIPS_tot_losses_slot_dev.append(loss_slot_dev_array) \n",
        "    SNIPS_tot_sampled_epochs.append(sampled_epochs)\n",
        " \n",
        "slot_f1s = np.asarray(slot_f1s)\n",
        "intent_acc = np.asarray(intent_acc)\n",
        "print('\\nSlot F1', round(slot_f1s.mean(),3), '+-', round(slot_f1s.std(),3))\n",
        "print('Intent Acc', round(intent_acc.mean(), 3), '+-', round(slot_f1s.std(), 3))"
      ],
      "metadata": {
        "id": "arBO9HTD1Cfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Intent classification analysis "
      ],
      "metadata": {
        "id": "FHgCeK1YGo_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = SNIPS_tot_intent_test[0]\n",
        "x.pop('accuracy')"
      ],
      "metadata": {
        "id": "X2tWqMr1Go_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Macro average and weighted average"
      ],
      "metadata": {
        "id": "BOKYEEbEGo_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg = {'weighted avg': x['weighted avg'], 'macro avg' :  x['macro avg']}\n",
        "x.pop('macro avg')\n",
        "x.pop('weighted avg')\n",
        "table = pd.DataFrame.from_dict(avg).transpose()\n",
        "table.round(decimals=3)"
      ],
      "metadata": {
        "id": "aHjFj6fOGo_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "classified intent labels (based on F1-score):"
      ],
      "metadata": {
        "id": "RzuwULYzGo_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best = dict(sorted(x.items(), key=lambda item: item[1]['f1-score'], reverse = True))\n",
        "table = pd.DataFrame.from_dict(best).transpose()\n",
        "table.round(decimals=3)"
      ],
      "metadata": {
        "id": "vB4mU2TQGo_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Slot filling analysis"
      ],
      "metadata": {
        "id": "crzs6LlLGo_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = SNIPS_tot_results_test[0]"
      ],
      "metadata": {
        "id": "lYxH1pKCGo_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15 best classified slots"
      ],
      "metadata": {
        "id": "aH15Y4IKGo_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best = dict(sorted(x.items(), key=lambda item: item[1]['f'], reverse = True))\n",
        "table = pd.DataFrame.from_dict(best).transpose()[:15]\n",
        "table.round(decimals=3)"
      ],
      "metadata": {
        "id": "1z1I2sFCGo_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15 worst classified slot labels"
      ],
      "metadata": {
        "id": "tvt1lRDIGo_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "worst = dict(sorted(x.items(), key=lambda item: item[1]['f'], reverse = False))\n",
        "table = pd.DataFrame.from_dict(worst).transpose()[:15]\n",
        "table.round(decimals=3)"
      ],
      "metadata": {
        "id": "60V1hiSDGo_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Losses Plots"
      ],
      "metadata": {
        "id": "YjMft-1kGo_k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total loss plot "
      ],
      "metadata": {
        "id": "DEu18TIVGo_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(SNIPS_tot_sampled_epochs[0], SNIPS_tot_losses_train[0], SNIPS_tot_losses_dev[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "4d456420-8ca3-480f-85c7-0c278b08c435",
        "id": "PNy_8yZeGo_k"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Intent loss plot "
      ],
      "metadata": {
        "id": "kMbHSjDqGo_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(SNIPS_tot_sampled_epochs[0], SNIPS_tot_losses_intent_train[0], SNIPS_tot_losses_intent_dev[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "a98d785c-5bfc-4da2-a7c4-43b0375e56d9",
        "id": "f--q5piWGo_l"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Slot loss plot "
      ],
      "metadata": {
        "id": "rYHxrZnsGo_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(SNIPS_tot_sampled_epochs[0], SNIPS_tot_losses_slot_train[0], SNIPS_tot_losses_slot_dev[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "4496ffdf-cc22-4446-83b4-37639ddddfe2",
        "id": "5TcptZycGo_l"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1MZcfyr71n8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bloVbWUG1n-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0sV7GtlN1oBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "By0Byj8a1oEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gMrZDN7MGrrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ft6kp3ssGrvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tolto voc size --> prossima cambia dropout probability (0.1)"
      ],
      "metadata": {
        "id": "5xZaK4Ym_7yA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bScn0huJzIvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ATIS_model.load_state_dict(torch.load('/content/drive/MyDrive/NLU_trained_models/ATIS_model_bert.pt'))"
      ],
      "metadata": {
        "id": "RSode7nPjo5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(ATIS_model.state_dict(), '/content/drive/MyDrive/NLU_trained_models/ATIS_model_bert.pt')"
      ],
      "metadata": {
        "id": "gUnq0s9GTI3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(num = 3, figsize=(8, 5)).patch.set_facecolor('white')\n",
        "plt.title('Train and Dev Losses')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.plot(ATIS_sampled_epochs, ATIS_losses_train, label='Train loss')\n",
        "plt.plot(ATIS_sampled_epochs, ATIS_losses_dev, label='Dev loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "erbqc1xKkweH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(num = 3, figsize=(8, 5)).patch.set_facecolor('white')\n",
        "plt.title('Train and Dev Intent Losses')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "\n",
        "plt.plot(ATIS_sampled_epochs, ATIS_loss_intent_train, label='Train intent loss')\n",
        "plt.plot(ATIS_sampled_epochs, ATIS_loss_intent_dev, label='Dev intent loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QK_otkYA31jB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(num = 3, figsize=(8, 5)).patch.set_facecolor('white')\n",
        "plt.title('Train and Dev Slot Losses')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.plot(ATIS_sampled_epochs, ATIS_loss_slot_train, label='Train slot loss')\n",
        "plt.plot(ATIS_sampled_epochs, ATIS_loss_slot_dev, label='Dev slot loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aIfkyP6e31jB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SNIPS_model = Bert_model(hid_size, SNIPS_out_slot, SNIPS_out_int, emb_size, SNIPS_vocab_len, pad_index=PAD_TOKEN).to(device)"
      ],
      "metadata": {
        "id": "uFv8NAlqAEwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr=0.0001\n",
        "SNIPS_optimizer = optim.Adam(SNIPS_model.parameters(), lr=lr) #take default parameters, just modify lr"
      ],
      "metadata": {
        "id": "fo8Sq4vpALhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SNIPS_sampled_epochs, SNIPS_losses_train, SNIPS_losses_dev, SNIPS_loss_intent_train, SNIPS_loss_slot_train, SNIPS_loss_intent_dev, SNIPS_loss_slot_dev = train_try(\n",
        "    train_loader = SNIPS_train_loader, \n",
        "    test_loader = SNIPS_test_loader, \n",
        "    dev_loader = SNIPS_dev_loader, \n",
        "    model = SNIPS_model, \n",
        "    optimizer = SNIPS_optimizer,\n",
        "    lang = SNIPS_lang,\n",
        "    train = True)"
      ],
      "metadata": {
        "id": "IUoKHwtWAPKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(num = 3, figsize=(8, 5)).patch.set_facecolor('white')\n",
        "plt.title('Train and Dev Losses')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.plot(SNIPS_sampled_epochs, SNIPS_losses_train, label='Train loss')\n",
        "plt.plot(SNIPS_sampled_epochs, SNIPS_losses_dev, label='Dev loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6qoERPDhAny4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(num = 3, figsize=(20, 12)).patch.set_facecolor('white')\n",
        "plt.title('Train and Dev Intent Losses')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "\n",
        "plt.plot(SNIPS_sampled_epochs, SNIPS_loss_intent_train, label='Train intent loss')\n",
        "plt.plot(SNIPS_sampled_epochs, SNIPS_loss_intent_dev, label='Dev intent loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F0W3ddGSWt5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(num = 3, figsize=(20, 12)).patch.set_facecolor('white')\n",
        "plt.title('Train and Dev Losses')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.plot(SNIPS_sampled_epochs, SNIPS_loss_slot_train, label='Train slot loss')\n",
        "plt.plot(SNIPS_sampled_epochs, SNIPS_loss_slot_dev, label='Dev slot loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0CbAAl5QWt5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from conll import evaluate\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def train_loop_try2(data, optimizer, criterion_slots, criterion_intents, model):\n",
        "    model.train()\n",
        "    loss_array = []\n",
        "    loss_intent_array = []\n",
        "    loss_slot_array = []\n",
        "    for sample in data:\n",
        "        optimizer.zero_grad() # Zeroing the gradient\n",
        "        slots, intent = model(sample['utterances'], sample['slots_len'])\n",
        "        loss_intent = criterion_intents(intent, sample['intents'])\n",
        "\n",
        "        #print(\"\\nslots.shape:\\n \",slots.shape)\n",
        "        #print(\"\\nsample.shape\\n: \",sample['y_slots'].shape)\n",
        "\n",
        "        #print(\"\\nslots:\\n \",slots)\n",
        "        #print(\"\\nsample\\n: \",sample['y_slots'])\n",
        "\n",
        "        loss_slot = criterion_slots(slots, sample['y_slots'])\n",
        "\n",
        "        loss_intent_array.append(loss_intent.item())\n",
        "        loss_slot_array.append(loss_slot.item())\n",
        "\n",
        "\n",
        "\n",
        "        loss = 0.3*loss_intent + 0.7*loss_slot # In joint training we sum the losses. \n",
        "                                       # Is there another way to do that?\n",
        "                                       # you can decide to give more imporante to intent or slots with a linear combination\n",
        "\n",
        "        \"\"\"#Add L2 regularization \n",
        "        l2_lambda = 0.001\n",
        "        l2_norm = sum(p.pow(2.0).sum()\n",
        "                  for p in model.intent_out.parameters())\n",
        "        \n",
        "        loss = loss + l2_lambda * l2_norm\"\"\"\n",
        "\n",
        "        loss_array.append(loss.item())\n",
        "        loss.backward() # Compute the gradient, deleting the computational graph\n",
        "        # clip the gradient to avoid explosioning gradients\n",
        "        # torch.nn.utils.clip_grad_norm_(model.parameters(), clip)  \n",
        "        optimizer.step() # Update the weights\n",
        "    return loss_array, loss_intent_array, loss_slot_array\n",
        "\n",
        "def eval_loop_try2(data, criterion_slots, criterion_intents, model, lang):\n",
        "    model.eval()\n",
        "    loss_array = []\n",
        "    loss_intent_array = []\n",
        "    loss_slot_array = []\n",
        "    \n",
        "    ref_intents = []\n",
        "    hyp_intents = []\n",
        "    \n",
        "    ref_slots = []\n",
        "    hyp_slots = []\n",
        "    #softmax = nn.Softmax(dim=1) # Use Softmax if you need the actual probability\n",
        "    with torch.no_grad(): # It used to avoid the creation of computational graph\n",
        "        for sample in data:\n",
        "            slots, intents = model(sample['utterances'], sample['slots_len'])\n",
        "            loss_intent = criterion_intents(intents, sample['intents'])\n",
        "            loss_slot = criterion_slots(slots, sample['y_slots'])\n",
        "            loss = 0.3*loss_intent + 0.7*loss_slot \n",
        "\n",
        "            loss_intent_array.append(loss_intent.item())\n",
        "            loss_slot_array.append(loss_slot.item())\n",
        "            loss_array.append(loss.item())\n",
        "            # Intent inference\n",
        "            # Get the highest probable class\n",
        "            out_intents = [lang.id2intent[x] \n",
        "                           for x in torch.argmax(intents, dim=1).tolist()] \n",
        "            gt_intents = [lang.id2intent[x] for x in sample['intents'].tolist()]\n",
        "            ref_intents.extend(gt_intents)\n",
        "            hyp_intents.extend(out_intents)\n",
        "            \n",
        "            # Slot inference \n",
        "            output_slots = torch.argmax(slots, dim=1)\n",
        "            for id_seq, seq in enumerate(output_slots):\n",
        "                length = sample['slots_len'].tolist()[id_seq]\n",
        "                utt_ids = sample['utterance'][id_seq][:length].tolist()\n",
        "                gt_ids = sample['y_slots'][id_seq].tolist()\n",
        "                gt_slots = [lang.id2slot[elem] for elem in gt_ids[:length]]\n",
        "                #print(utt_ids)\n",
        "                utterance = [lang.id2word[elem] for elem in utt_ids]\n",
        "                #print(utterance)\n",
        "                to_decode = seq[:length].tolist()\n",
        "                ref_slots.append([(utterance[id_el], elem) for id_el, elem in enumerate(gt_slots)])\n",
        "                tmp_seq = []\n",
        "                for id_el, elem in enumerate(to_decode):\n",
        "                    tmp_seq.append((utterance[id_el], lang.id2slot[elem]) if elem != 0 else (utterance[id_el], 'O'))\n",
        "                hyp_slots.append(tmp_seq)\n",
        "                #print(hyp_slots)\n",
        "    try:            \n",
        "        results = evaluate(ref_slots, hyp_slots)\n",
        "    except Exception as ex: #if your model predict slot that are not in ref, it gives error\n",
        "        # Sometimes the model predics a class that is not in REF\n",
        "        print(ex)\n",
        "        ref_s = set([x[1] for x in ref_slots])\n",
        "        hyp_s = set([x[1] for x in hyp_slots])\n",
        "        print(hyp_s.difference(ref_s))\n",
        "        \n",
        "    report_intent = classification_report(ref_intents, hyp_intents, \n",
        "                                          zero_division=False, output_dict=True)\n",
        "    return results, report_intent, loss_array, loss_intent_array, loss_slot_array\n"
      ],
      "metadata": {
        "id": "ca32iVZlM90W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_try2(train_loader, test_loader, dev_loader, model, optimizer, lang, tokenizer, n_epochs=200, patience=3, train=True):\n",
        " \n",
        "  losses_train = []\n",
        "  loss_intent_train = []\n",
        "  loss_slot_train = []\n",
        "  losses_dev = [] \n",
        "  loss_intent_dev_array = []\n",
        "  loss_slot_dev_array= []\n",
        "\n",
        "  sampled_epochs = []\n",
        "  best_f1 = 0\n",
        "  for x in tqdm(range(1,n_epochs)):\n",
        "      if train:\n",
        "        loss, loss_intent, loss_slot = train_loop_try2(train_loader, optimizer, criterion_slots, \n",
        "                          criterion_intents, model)\n",
        "        if x % 3 == 0:\n",
        "            sampled_epochs.append(x)\n",
        "            losses_train.append(np.asarray(loss).mean())\n",
        "            loss_intent_train.append(np.asarray(loss_intent).mean())\n",
        "            loss_slot_train.append(np.asarray(loss_slot).mean())\n",
        "\n",
        "            results_dev, intent_res, loss_dev, loss_intent_dev, loss_slot_dev = eval_loop_try2(dev_loader, criterion_slots, \n",
        "                                                          criterion_intents, model, lang)\n",
        "            losses_dev.append(np.asarray(loss_dev).mean())\n",
        "            loss_intent_dev_array.append(np.asarray(loss_intent_dev).mean())\n",
        "            loss_slot_dev_array.append(np.asarray(loss_slot_dev).mean())\n",
        "            f1 = results_dev['total']['f']\n",
        "\n",
        "            \"\"\"if(x=50):\n",
        "              parameters = []\n",
        "              for param in model.parameters():\"\"\"\n",
        "\n",
        "            \n",
        "            if f1 > best_f1: #sometimes loss words but f1 increases, we have to look at both and figure out what of the 2 to use to stop the training\n",
        "                best_f1 = f1\n",
        "            else:\n",
        "                patience -= 1\n",
        "            if patience <= 0: # Early stopping with patience\n",
        "                break # Not nice but it keeps the code clean\n",
        "\n",
        "  results_test, intent_test, _ , _ , _ = eval_loop_try2(test_loader, criterion_slots, \n",
        "                                          criterion_intents, model, lang)    \n",
        "  print('\\nSlot F1: ', results_test['total']['f'])\n",
        "  print('Intent Accuracy:', intent_test['accuracy'])\n",
        "  return sampled_epochs, losses_train, losses_dev, loss_intent_train, loss_slot_train, loss_intent_dev_array, loss_slot_dev_array"
      ],
      "metadata": {
        "id": "OYogDyFpF9Nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PCxjboMHAn1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6PWC3nShF828"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vVYyIKH9F85C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Yd3m1V7SF87L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PI1EdIf8F89j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WxAx9aoYAn4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjIkTY3LO0y0"
      },
      "outputs": [],
      "source": [
        "class Lang():\n",
        "    def __init__(self, words, intents, slots, tokenizer, cutoff=0):\n",
        "        self.word2id = self.w2id(words, tokenizer, cutoff=cutoff, unk=True)\n",
        "        self.slot2id = self.lab2id(slots)\n",
        "        self.intent2id = self.lab2id(intents, pad=False)\n",
        "        self.id2word = {v:k for k, v in self.word2id.items()}\n",
        "        self.id2slot = {v:k for k, v in self.slot2id.items()}\n",
        "        self.id2intent = {v:k for k, v in self.intent2id.items()}\n",
        "\n",
        "    #method to transform words to id \n",
        "    def w2id(self, elements, tokenizer, cutoff=None, unk=True):\n",
        "        vocab = {'pad': PAD_TOKEN}\n",
        "        if unk:\n",
        "            vocab['unk'] = len(vocab)\n",
        "        count = Counter(elements)\n",
        "        for k, v in count.items():\n",
        "            if v > cutoff:\n",
        "                #print(\"k: \", k)\n",
        "                #print(\"v: \", v)\n",
        "                #print(\"len(vocab): \", len(vocab))\n",
        "                vocab[k] = tokenizer.convert_tokens_to_ids(k)\n",
        "                #print(\"vocab[k]: \", vocab[k])\n",
        "        #pprint(vocab)\n",
        "        return vocab\n",
        "    \n",
        "    def lab2id(self, elements, pad=True):\n",
        "        vocab = {}\n",
        "        if pad:\n",
        "            vocab['pad'] = PAD_TOKEN\n",
        "        for elem in elements:\n",
        "                vocab[elem] = len(vocab)\n",
        "        return vocab"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr=0.0001\n",
        "\n",
        "parameters = []\n",
        "\n",
        "for param in ATIS_model.slot_out.parameters():\n",
        "  parameters.append(param)\n",
        "\n",
        "for param in ATIS_model.intent_out.parameters():\n",
        "  parameters.append(param)\n",
        "\n",
        "ATIS_optimizer = optim.Adam(parameters, lr=lr) #take default parameters, just modify lr"
      ],
      "metadata": {
        "id": "dmH-Ose-o2wR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dn3JmMnKPCbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DHJBxmgOPCdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.utils.data as data\n",
        "\n",
        "class IntentsAndSlotsBert(data.Dataset):\n",
        "    # Mandatory methods are __init__, __len__ and __getitem__\n",
        "    def __init__(self, dataset, lang, tokenizer, unk='unk'):\n",
        "        self.utterances = []\n",
        "        self.intents = []\n",
        "        self.slots = []\n",
        "        self.unk = unk\n",
        "\n",
        "        \n",
        "        for x in dataset:\n",
        "            self.utterances.append(x['utterance'])\n",
        "            self.slots.append(x['slots'])\n",
        "            self.intents.append(x['intent'])\n",
        "\n",
        "        max_length = max(len([x.split()]) for x in self.utterances)\n",
        "        \n",
        "        \"\"\"        \n",
        "        slot_map = {}\n",
        "        for label in self.slots:\n",
        "            slot_map[label] = lang.slot2id(label)\n",
        "        \"\"\"\n",
        "#convert to numbers\n",
        "        self.utt_ids = self.mapping_utt(self.utterances, tokenizer, max_length)\n",
        "        #self.slot_ids = self.encode_token_labels(self.utterances, self.slots, tokenizer, lang.slot2id, max_length)\n",
        "        self.slot_ids = self.mapping_seq(self.slots, lang.slot2id)\n",
        "        self.intent_ids = self.mapping_lab(self.intents, lang.intent2id)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.utterances)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        utt = torch.Tensor(self.utt_ids[idx])\n",
        "        slots = torch.Tensor(self.slot_ids[idx])\n",
        "        intent = self.intent_ids[idx]\n",
        "        sample = {'utterance': utt, 'slots': slots, 'intent': intent}\n",
        "        return sample #dictionary with 3 keys\n",
        "    \n",
        "    # Auxiliary methods\n",
        "    \n",
        "    def mapping_lab(self, data, mapper):\n",
        "        return [mapper[x] if x in mapper else mapper[self.unk] for x in data]\n",
        "    \n",
        "    def mapping_utt(self, utterances, tokenizer, max_length): # Map sequences to number\n",
        "        token_ids = np.zeros(shape=(len(utterances), max_length+2), dtype=np.int32) #max_length +2 because of [CLS] and [SEP] tokens\n",
        "        for i, utterance in enumerate(utterances):\n",
        "          #print(utterance)\n",
        "          encoded = tokenizer.encode(utterance)\n",
        "          #print(len(encoded))\n",
        "          token_ids[i, 0:len(encoded)] = encoded\n",
        "        #print(token_ids)\n",
        "        return token_ids\n",
        "\n",
        "    def encode_token_labels(self, utterances, slot_names, tokenizer, slot_map, max_length):\n",
        "      encoded = np.zeros(shape=(len(utterances), max_length+2), dtype=np.int32)\n",
        "      for i, (utterance, word_labels) in enumerate(zip(utterances, slot_names)):\n",
        "          encoded_labels = []\n",
        "          for word, word_label in zip(utterance.split(), word_labels.split()):\n",
        "              tokens = [word]\n",
        "              encoded_labels.append(slot_map[word_label])\n",
        "              expand_label = word_label.replace(\"B-\", \"I-\")\n",
        "              if not expand_label in slot_map:\n",
        "                  expand_label = word_label\n",
        "              encoded_labels.extend([slot_map[expand_label]] *\\\n",
        "                                      (len(tokens) - 1))\n",
        "          encoded[i, 1:len(encoded_labels) + 1] = encoded_labels\n",
        "          #print(len(utterance.split()))\n",
        "          #print(len(encoded_labels))\n",
        "\n",
        "      return encoded\n",
        "\n",
        "    def mapping_seq(self, data, mapper): # Map sequences to number\n",
        "      res = []\n",
        "      for seq in data:\n",
        "          tmp_seq = []\n",
        "          for x in seq.split():\n",
        "              if x in mapper:\n",
        "                  tmp_seq.append(mapper[x])\n",
        "              else:\n",
        "                  tmp_seq.append(mapper[self.unk])\n",
        "          res.append(tmp_seq)\n",
        "      return res\n",
        "\n",
        "    def mapping_seq_old(self, data, mapper): # Map sequences to number\n",
        "      res = []\n",
        "      for seq in data:\n",
        "          tmp_seq = []\n",
        "          for x in seq.split():\n",
        "              if x in mapper:\n",
        "                  tmp_seq.append(mapper[x])\n",
        "              else:\n",
        "                  tmp_seq.append(mapper[self.unk])\n",
        "          res.append(tmp_seq)\n",
        "      return res\n"
      ],
      "metadata": {
        "id": "RpaXlEnNDASX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "l0jg6i8fPCgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ert3-b3cF9Ng"
      },
      "outputs": [],
      "source": [
        "from conll import evaluate\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def train_loop_try2(data, optimizer, criterion_slots, criterion_intents, model):\n",
        "    model.train()\n",
        "    loss_array = []\n",
        "    loss_intent_array = []\n",
        "    loss_slot_array = []\n",
        "    for sample in data:\n",
        "        optimizer.zero_grad() # Zeroing the gradient\n",
        "        slots, intent = model(sample['utterances'], sample['slots_len'])\n",
        "        loss_intent = criterion_intents(intent, sample['intents'])\n",
        "\n",
        "        #print(\"\\nslots.shape:\\n \",slots.shape)\n",
        "        #print(\"\\nsample.shape\\n: \",sample['y_slots'].shape)\n",
        "\n",
        "        #print(\"\\nslots:\\n \",slots)\n",
        "        #print(\"\\nsample\\n: \",sample['y_slots'])\n",
        "\n",
        "        loss_slot = criterion_slots(slots, sample['y_slots'])\n",
        "\n",
        "        loss_intent_array.append(loss_intent.item())\n",
        "        loss_slot_array.append(loss_slot.item())\n",
        "\n",
        "\n",
        "        #loss = loss_intent #HO CAMBIATO IL LOSSSSSSSSSSSSSSSSSS\n",
        "        loss = 0.3*loss_intent + 0.7*loss_slot # In joint training we sum the losses. \n",
        "                                       # Is there another way to do that?\n",
        "                                       # you can decide to give more imporante to intent or slots with a linear combination\n",
        "\n",
        "        \"\"\"#Add L2 regularization \n",
        "        l2_lambda = 0.001\n",
        "        l2_norm = sum(p.pow(2.0).sum()\n",
        "                  for p in model.intent_out.parameters())\n",
        "        \n",
        "        loss = loss + l2_lambda * l2_norm\"\"\"\n",
        "\n",
        "        loss_array.append(loss.item())\n",
        "        loss.backward() # Compute the gradient, deleting the computational graph\n",
        "        # clip the gradient to avoid explosioning gradients\n",
        "        # torch.nn.utils.clip_grad_norm_(model.parameters(), clip)  \n",
        "        optimizer.step() # Update the weights\n",
        "    return loss_array, loss_intent_array, loss_slot_array\n",
        "\n",
        "def eval_loop_try2(data, criterion_slots, criterion_intents, model, lang, tokenizer):\n",
        "    model.eval()\n",
        "    loss_array = []\n",
        "    loss_intent_array = []\n",
        "    loss_slot_array = []\n",
        "    \n",
        "    ref_intents = []\n",
        "    hyp_intents = []\n",
        "    \n",
        "    ref_slots = []\n",
        "    hyp_slots = []\n",
        "    #softmax = nn.Softmax(dim=1) # Use Softmax if you need the actual probability\n",
        "    with torch.no_grad(): # It used to avoid the creation of computational graph\n",
        "        for sample in data:\n",
        "            slots, intents = model(sample['utterances'], sample['slots_len'])\n",
        "\n",
        "            #print(slots.shape)\n",
        "            #print(\"\\nutt\\n:\", sample[\"utterances\"].shape)\n",
        "            #print(slots)\n",
        "            loss_intent = criterion_intents(intents, sample['intents'])\n",
        "            loss_slot = criterion_slots(slots, sample['y_slots'])\n",
        "            loss = 0.3*loss_intent + 0.7*loss_slot \n",
        "\n",
        "            loss_intent_array.append(loss_intent.item())\n",
        "            loss_slot_array.append(loss_slot.item())\n",
        "            loss_array.append(loss.item())\n",
        "            # Intent inference\n",
        "            # Get the highest probable class\n",
        "            out_intents = [lang.id2intent[x] \n",
        "                           for x in torch.argmax(intents, dim=1).tolist()] \n",
        "            gt_intents = [lang.id2intent[x] for x in sample['intents'].tolist()]\n",
        "            ref_intents.extend(gt_intents)\n",
        "            hyp_intents.extend(out_intents)\n",
        "            \n",
        "            # Slot inference \n",
        "            output_slots = torch.argmax(slots, dim=1)\n",
        "            for id_seq, seq in enumerate(output_slots):\n",
        "                length = sample['slots_len'].tolist()[id_seq]\n",
        "                utt_ids = sample['utterance'][id_seq][:length].tolist()\n",
        "                gt_ids = sample['y_slots'][id_seq].tolist()\n",
        "                gt_slots = [lang.id2slot[elem] for elem in gt_ids[:length]] \n",
        "                \n",
        "                \n",
        "                #print(utt_ids)\n",
        "                #print(gt_slots)\n",
        "                utterance = tokenizer.decode(utt_ids)\n",
        "                utterance = utterance.split()\n",
        "                #print(utterance)\n",
        "                \n",
        "                to_decode = seq[:length].tolist()\n",
        "                \n",
        "                \"\"\"if len(gt_slots) > len(utterance) :\n",
        "                  gt_slots.pop()\n",
        "                  to_decode.pop()\n",
        "                elif len(gt_slots) < len(utterance):\n",
        "                  utterance.pop()\n",
        "              \n",
        "                print(len(gt_slots))\n",
        "                print(len(utterance))\"\"\"\n",
        "                #utterance = tokenizer.\n",
        "                \n",
        "                #print(to_decode)\n",
        "                ref_slots.append([(utterance[id_el], elem) for id_el, elem in enumerate(gt_slots)])\n",
        "                tmp_seq = []\n",
        "                #print(len(utterance))\n",
        "                #print(\"len to_decode\", len(to_decode))\n",
        "                for id_el, elem in enumerate(to_decode):\n",
        "                    #print(\"utterance: \", utterance[id_el])\n",
        "                    tmp_seq.append((utterance[id_el], lang.id2slot[elem]) if elem != 0 else (utterance[id_el], 'O'))\n",
        "                    #print(tmp_seq)\n",
        "                hyp_slots.append(tmp_seq)\n",
        "                #print(ref_slots)\n",
        "    \n",
        "    try:            \n",
        "        results = evaluate(ref_slots, hyp_slots)\n",
        "    except Exception as ex: #if your model predict slot that are not in ref, it gives error\n",
        "        # Sometimes the model predics a class that is not in REF\n",
        "        print(ex)\n",
        "        ref_s = set([x[1] for x in ref_slots])\n",
        "        hyp_s = set([x[1] for x in hyp_slots])\n",
        "        print(hyp_s.difference(ref_s))\n",
        "        \n",
        "    report_intent = classification_report(ref_intents, hyp_intents, \n",
        "                                          zero_division=False, output_dict=True)\n",
        "    return results, report_intent, loss_array, loss_intent_array, loss_slot_array\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "n_ZpIxFYPCiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-LLO0nt7PCkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5-t4he5ZPCmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##separated lstm"
      ],
      "metadata": {
        "id": "RRKoHt7AuZFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model_sep(nn.Module):\n",
        "#hidden size of rnn, embedding size (size of the vector that represent the word embedding)\n",
        "    def __init__(self, hid_size, out_slot, out_int, emb_size, vocab_len, n_layer=1, pad_index=0):\n",
        "        super(Model_sep, self).__init__()\n",
        "        # hid_size = Hidden size\n",
        "        # out_slot = number of slots (output size for slot filling)\n",
        "        # out_int = number of intents (ouput size for intent class)\n",
        "        # emb_size = word embedding size\n",
        "        \n",
        "        #A simple lookup table that stores embeddings of a fixed dictionary and size.\n",
        "        #The input to the module is a list of indices, and the output is the corresponding word embeddings.\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_len, \n",
        "                                      emb_size, \n",
        "                                      padding_idx=pad_index) #pad idx --> the entities at pad_index do not contribute to the gradient\n",
        "        \n",
        "        \"\"\"\n",
        "        num_embeddings (int) – size of the dictionary of embeddings\n",
        "\n",
        "        embedding_dim (int) – the size of each embedding vector\n",
        "\n",
        "        padding_idx (int, optional) – If specified, the entries at padding_idx do not contribute to the gradient; \n",
        "      \n",
        "        \"\"\"\n",
        "        self.utt_encoder1 = nn.LSTM(emb_size, \n",
        "                                   emb_size, \n",
        "                                   n_layer,\n",
        "                                   bidirectional=True)     #network, bidirectional\n",
        "        \n",
        "        self.utt_encoder2 = nn.LSTM(emb_size*2, \n",
        "                                   emb_size, \n",
        "                                   n_layer,\n",
        "                                   bidirectional=True) \n",
        "\n",
        "\n",
        "        #self.conv_intent = nn.Conv1d(in_channels = 300, out_channels = 200, kernel_size = 4, padding = 1)\n",
        "\n",
        "        \"\"\"  \n",
        "        input_size – The number of expected features in the input x\n",
        "        hidden_size – The number of features in the hidden state h\n",
        "        num_layers – Number of recurrent layers. \n",
        "        \"\"\"\n",
        "        self.dropout = nn.Dropout(0.6) #regularization --> randomly mute a neuron, only on training phase. Helps to avoid overfitting\n",
        "\n",
        "\n",
        "        self.slot_out = nn.Linear(600, out_slot)\n",
        "\n",
        "        self.intent_out = nn.Linear(300, out_int)\n",
        "      \n",
        "        \n",
        "    def forward(self, utterance, seq_lengths): #define the architecture\n",
        "        # utterance.size() = batch_size X seq_len\n",
        "        utt_emb = self.embedding(utterance) # utt_emb.size() = batch_size X seq_len X emb_size\n",
        "\n",
        "        \n",
        "\n",
        "        #--> get word embedding\n",
        "        utt_emb = utt_emb.permute(1,0,2) # we need seq len first -> seq_len X batch_size X emb_size\n",
        "        \n",
        "        # pack_padded_sequence avoid computation over pad tokens reducing the computational cost\n",
        "\n",
        "        utt_emb_drop = self.dropout(utt_emb)\n",
        "        \n",
        "        packed_input = pack_padded_sequence(utt_emb_drop, seq_lengths.cpu().numpy())\n",
        "        # Process the batch\n",
        "        packed_output, (last_hidden, cell) = self.utt_encoder1(packed_input) \n",
        "\n",
        "        packed_output2, (last_hidden, cell) = self.utt_encoder2(packed_output)\n",
        "\n",
        "        #print(\"\\n\",last_hidden)\n",
        "        #print(packed_input.size)\n",
        "        #packed_output2, (last_hidden2, cell2) = self.utt_encoder(packed_output) \n",
        "  \n",
        "        #packed output containing the output features (h_t) from the last layer of the LSTM, \n",
        "        #for each t. If a torch.nn.utils.rnn.PackedSequence has been given as the \n",
        "        #input, the output will also be a packed sequence.\n",
        "\n",
        "        #last_hidden containing the final hidden state for each element in the sequence\n",
        "        #cell containing the final cell state for each element in the sequence\n",
        "        \n",
        "        # Unpack the sequence\n",
        "        utt_encoded, input_sizes = pad_packed_sequence(packed_output2)\n",
        "        #utt_encoded.shape: [sentence lenght, 128, 200] \n",
        "\n",
        "        # Get the last hidden state\n",
        "        #last_hidde.shape: [1, 128, 200]\n",
        "        \n",
        "        #last_hidde.shape: [128, 200] -> [batch size, hidden_size]\n",
        "\n",
        "        #print(\"\\nutt_encoded.shape: \", utt_encoded.shape)\n",
        "        #print(\"\\nlast hidden.shape\",last_hidden.shape)\n",
        "        \n",
        "        \"\"\"\n",
        "        utt_encoded = utt_encoded.permute(1,2,0)\n",
        "\n",
        "        print(\"\\nbefore:\\n\", utt_encoded.shape)\n",
        "\n",
        "        utt_conv = self.conv_slots(utt_encoded)\n",
        "\n",
        "        print(\"\\nafter:\\n\", utt_conv.shape)\n",
        "\n",
        "        utt_conv = utt_conv.permute(2,0,1)\n",
        "        \"\"\"\n",
        "        \n",
        "        \n",
        "        \n",
        "        \"\"\"\n",
        "        last_hidden = last_hidden.permute(1,2,0)\n",
        "\n",
        "        hidden_conv = self.conv_intent(last_hidden)\n",
        "\n",
        "        hidden_conv = hidden_conv.permute(2,0,1)\n",
        "        \"\"\"\n",
        "\n",
        "        hidden_conv = last_hidden\n",
        "\n",
        "        hidden_conv = hidden_conv[-1,:,:]\n",
        "\n",
        "        drop_utt = self.dropout(utt_encoded)\n",
        "        drop_hidden = self.dropout(hidden_conv)\n",
        "       \n",
        "        # Compute slot logits, i use the encoded representation of the utterance, with the encoding of each word\n",
        "        slots = self.slot_out(drop_utt)\n",
        "\n",
        "        #slots.shape: [sentence_lenght, batch_size, out_slots]\n",
        "        #print(\"slots size: \", slots.shape)\n",
        "        #print(\"\\n\\n\",slots,\"\\n\\n\")\n",
        "        \n",
        "        \n",
        "        #print(type(drop_hidden[0][0]))\n",
        "\n",
        "        #FOR EACH SENT IN BATCH, SAVES THE SLOTS IN IT\n",
        "\n",
        "        \"\"\"prova = slots\n",
        "        #print(\"\\n\\nprova size:\", prova.shape, \"\\n\\n\")\n",
        "\n",
        "        prova = prova.permute(1,0,2)\n",
        "          \n",
        "        #print(last_hidden.shape)\n",
        "        sents_slots = []\n",
        "        for i, sent in enumerate(prova):\n",
        "          #print(\"\\nsent:\\n\", sent)\n",
        "          slots_in_sentence = [0] * 73\n",
        "          for word in sent:\n",
        "            #print(\"\\nword:\\n\", word)\n",
        "            pred_slot = int(torch.argmax(word))\n",
        "            slots_in_sentence[pred_slot] += 1\n",
        "            \n",
        "          #tensor_slots = torch.tensor(slots_in_sentence).to(device)\n",
        "          #print(\"\\nlast hidden\\n\",last_hidden[i].shape)\n",
        "          #print(\"\\ntensor_slots.shape\\n\",tensor_slots.shape)\n",
        "          \n",
        "          # repr = torch.cat((last_hidden[i], tensor_slots))\n",
        "          # new_hidden.append(list(repr))\n",
        "          sents_slots.append(slots_in_sentence)\n",
        "\n",
        "        #new_hidden = torch.tensor(new_hidden).to(device)  \n",
        "\n",
        "        sents_slots = torch.tensor(sents_slots).to(device)  \"\"\"\n",
        "\n",
        "        intent = self.intent_out(drop_hidden)\n",
        "       \n",
        "        slots = slots.permute(1,2,0) # We need this for computing the loss\n",
        "\n",
        "\n",
        "        return slots, intent"
      ],
      "metadata": {
        "id": "RD_ncHTVsGTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SNIPS_model_sep = Model_sep(hid_size, SNIPS_out_slot, SNIPS_out_int, emb_size, SNIPS_vocab_len, pad_index=PAD_TOKEN).to(device)\n",
        "SNIPS_model_sep.apply(init_weights)\n",
        "SNIPS_optimizer_sep = optim.Adam(SNIPS_model_sep.parameters(), lr=lr, weight_decay=wd) #take default parameters, just modify lr"
      ],
      "metadata": {
        "id": "P-e4pQIYuedI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SNIPS_sampled_epochs_adv, SNIPS_losses_train_adv, SNIPS_losses_dev_adv = train_adv(\n",
        "train_loader = SNIPS_train_loader, \n",
        "test_loader = SNIPS_test_loader, \n",
        "dev_loader = SNIPS_dev_loader, \n",
        "model = SNIPS_model_sep, \n",
        "optimizer = SNIPS_optimizer_sep,\n",
        "lang = SNIPS_lang,\n",
        "train = True)"
      ],
      "metadata": {
        "id": "T1dmwcc0uiPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = []\n",
        "\n",
        "for param in SNIPS_model_sep.utt_encoder2.parameters():\n",
        "  parameters.append(param)\n",
        "\n",
        "for param in SNIPS_model_sep.slot_out.parameters():\n",
        "  parameters.append(param)\n",
        "\n",
        "SNIPS_optimizer_sep = optim.Adam(parameters, lr=lr, weight_decay=wd) #take default parameters, just modify lr"
      ],
      "metadata": {
        "id": "tofWPHgLu7Si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WuhkDdvFPCo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0Xuqvm9JPCrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SEPARATE CLASSIFIERS"
      ],
      "metadata": {
        "id": "FnwwFRNwxpcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Bert_encoder(nn.Module):\n",
        "#hidden size of rnn, embedding size (size of the vector that represent the word embedding)\n",
        "    def __init__(self, hid_size, out_slot, out_int, emb_size, vocab_len, n_layer=2, pad_index=0):\n",
        "        super(Bert_encoder, self).__init__()\n",
        "\n",
        "        config = BertConfig(vocab_size=vocab_len)\n",
        "        \n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\", config = config, ignore_mismatched_sizes=True)\n",
        "        \n",
        "    def forward(self, utterance): \n",
        "\n",
        "        output = self.bert(utterance) \n",
        "\n",
        "        return output.last_hidden_state, output.pooler_output"
      ],
      "metadata": {
        "id": "VuXVeqR3nrky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Slot_classifier(nn.Module):\n",
        "#hidden size of rnn, embedding size (size of the vector that represent the word embedding)\n",
        "    def __init__(self,out_slot):\n",
        "        super(Slot_classifier, self).__init__()\n",
        "        \n",
        "        self.slot_out = nn.Linear(768, out_slot)\n",
        "        \n",
        "    def forward(self, hidden_slot): \n",
        "\n",
        "        hidden_slot = hidden_slot.permute(1,0,2) \n",
        "        \n",
        "        slots = self.slot_out(hidden_slot)\n",
        "       \n",
        "        slots = slots.permute(1,2,0) # We need this for computing the loss\n",
        "\n",
        "        return slots"
      ],
      "metadata": {
        "id": "_s2h9NzpwAa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Intent_classifier(nn.Module):\n",
        "#hidden size of rnn, embedding size (size of the vector that represent the word embedding)\n",
        "    def __init__(self,out_int):\n",
        "        super(Intent_classifier, self).__init__()\n",
        "\n",
        "        self.intent_out = nn.Linear(768, out_int)      \n",
        "        \n",
        "    def forward(self, pooler_output): \n",
        "\n",
        "        intent = self.intent_out(pooler_output)\n",
        "\n",
        "        return intent"
      ],
      "metadata": {
        "id": "sPH1QQeywjkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Train"
      ],
      "metadata": {
        "id": "RqdTVGsqx99s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bert(train_loader, test_loader, dev_loader, encoder, slot_classifier, intent_classifier, encoder_optimizer, slot_optimizer, intent_optimizer, lang, n_epochs=200, patience=3):\n",
        " \n",
        "  losses_train = []\n",
        "  losses_dev = []\n",
        "  sampled_epochs = []\n",
        "  best_f1 = 0\n",
        "  for x in tqdm(range(1,n_epochs)):\n",
        "      loss = train_loop_bert(train_loader, encoder_optimizer, slot_optimizer, intent_optimizer, criterion_slots, \n",
        "                        criterion_intents, encoder, slot_classifier, intent_classifier)\n",
        "      if x % 5 == 0:\n",
        "          sampled_epochs.append(x)\n",
        "          losses_train.append(np.asarray(loss).mean())\n",
        "          results_dev, intent_res, loss_dev = eval_loop_bert(dev_loader, criterion_slots, \n",
        "                                                        criterion_intents, encoder, slot_classifier, intent_classifier, lang)\n",
        "          losses_dev.append(np.asarray(loss_dev).mean())\n",
        "          f1 = results_dev['total']['f']\n",
        "          \n",
        "          if f1 > best_f1: #sometimes loss words but f1 increases, we have to look at both and figure out what of the 2 to use to stop the training\n",
        "              best_f1 = f1\n",
        "          else:\n",
        "              patience -= 1\n",
        "          if patience <= 0: # Early stopping with patience\n",
        "              break # Not nice but it keeps the code clean\n",
        "\n",
        "  results_test, intent_test, _ = eval_loop_bert(test_loader, criterion_slots, \n",
        "                                          criterion_intents, encoder, slot_classifier, intent_classifier, lang)    \n",
        "  print('\\nSlot F1: ', results_test['total']['f'])\n",
        "  print('Intent Accuracy:', intent_test['accuracy'])\n",
        "  return sampled_epochs, losses_train, losses_dev"
      ],
      "metadata": {
        "id": "Z-5swAGgx8Xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGh0fMrRx2a5"
      },
      "outputs": [],
      "source": [
        "from conll import evaluate\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def train_loop_bert(data, encoder_optimizer, slot_optimizer, intent_optimizer, criterion_slots, criterion_intents, encoder, slot_classifier, intent_classifier):\n",
        "    encoder.train()\n",
        "    slot_classifier.train()\n",
        "    intent_classifier.train()\n",
        "    loss_array = []\n",
        "    for sample in data:\n",
        "        encoder_optimizer.zero_grad()\n",
        "        slot_optimizer.zero_grad()\n",
        "        intent_optimizer.zero_grad()\n",
        "        slots_hidden, intent_hidden = encoder(sample['utterances'])\n",
        "        intent = intent_classifier(intent_hidden)\n",
        "        slots = slot_classifier(slots_hidden)\n",
        "        loss_intent = criterion_intents(intent, sample['intents'])\n",
        "        loss_slot = criterion_slots(slots, sample['y_slots'])\n",
        "        loss = loss_intent + loss_slot # In joint training we sum the losses. \n",
        "                                       # Is there another way to do that?\n",
        "                                       # you can decide to give more imporante to intent or slots with a linear combination\n",
        "        loss_array.append(loss.item())\n",
        "        loss.backward() # Compute the gradient, deleting the computational graph\n",
        "        # clip the gradient to avoid explosioning gradients\n",
        "        # torch.nn.utils.clip_grad_norm_(model.parameters(), clip)  \n",
        "        encoder_optimizer.step()\n",
        "        slot_optimizer.step()\n",
        "        intent_optimizer.step()\n",
        "    return loss_array\n",
        "\n",
        "def eval_loop_bert(data, criterion_slots, criterion_intents, encoder, slot_classifier, intent_classifier, lang):\n",
        "    encoder.eval()\n",
        "    slot_classifier.eval()\n",
        "    intent_classifier.eval()\n",
        "    loss_array = []\n",
        "    \n",
        "    ref_intents = []\n",
        "    hyp_intents = []\n",
        "    \n",
        "    ref_slots = []\n",
        "    hyp_slots = []\n",
        "    #softmax = nn.Softmax(dim=1) # Use Softmax if you need the actual probability\n",
        "    with torch.no_grad(): # It used to avoid the creation of computational graph\n",
        "        for sample in data:\n",
        "            slots_hidden, intent_hidden = encoder(sample['utterances'])\n",
        "            intents = intent_classifier(intent_hidden)\n",
        "            slots = slot_classifier(slots_hidden)\n",
        "            loss_intent = criterion_intents(intents, sample['intents'])\n",
        "            loss_slot = criterion_slots(slots, sample['y_slots'])\n",
        "            loss = loss_intent + loss_slot \n",
        "            loss_array.append(loss.item())\n",
        "            # Intent inference\n",
        "            # Get the highest probable class\n",
        "            out_intents = [lang.id2intent[x] \n",
        "                           for x in torch.argmax(intents, dim=1).tolist()] \n",
        "            gt_intents = [lang.id2intent[x] for x in sample['intents'].tolist()]\n",
        "            ref_intents.extend(gt_intents)\n",
        "            hyp_intents.extend(out_intents)\n",
        "            \n",
        "            # Slot inference \n",
        "            output_slots = torch.argmax(slots, dim=1)\n",
        "            for id_seq, seq in enumerate(output_slots):\n",
        "                length = sample['slots_len'].tolist()[id_seq]\n",
        "                utt_ids = sample['utterance'][id_seq][:length].tolist()\n",
        "                gt_ids = sample['y_slots'][id_seq].tolist()\n",
        "                gt_slots = [lang.id2slot[elem] for elem in gt_ids[:length]]\n",
        "                utterance = [lang.id2word[elem] for elem in utt_ids]\n",
        "                to_decode = seq[:length].tolist()\n",
        "                ref_slots.append([(utterance[id_el], elem) for id_el, elem in enumerate(gt_slots)])\n",
        "                tmp_seq = []\n",
        "                for id_el, elem in enumerate(to_decode):\n",
        "                    tmp_seq.append((utterance[id_el], lang.id2slot[elem]) if elem != 0 else (utterance[id_el], 'O'))\n",
        "                hyp_slots.append(tmp_seq)\n",
        "    try:            \n",
        "        results = evaluate(ref_slots, hyp_slots)\n",
        "    except Exception as ex: #if your model predict slot that are not in ref, it gives error\n",
        "        # Sometimes the model predics a class that is not in REF\n",
        "        print(ex)\n",
        "        ref_s = set([x[1] for x in ref_slots])\n",
        "        hyp_s = set([x[1] for x in hyp_slots])\n",
        "        print(hyp_s.difference(ref_s))\n",
        "        \n",
        "    report_intent = classification_report(ref_intents, hyp_intents, \n",
        "                                          zero_division=False, output_dict=True)\n",
        "    return results, report_intent, loss_array\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ATIS_encoder = Bert_encoder(hid_size, ATIS_out_slot, ATIS_out_int, emb_size, ATIS_vocab_len, pad_index=PAD_TOKEN).to(device)\n",
        "ATIS_slot_classifier = Slot_classifier(ATIS_out_slot).to(device)\n",
        "ATIS_intent_classifier = Intent_classifier(ATIS_out_int).to(device)"
      ],
      "metadata": {
        "id": "VvVAP9Etx03T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr=0.0001\n",
        "ATIS_encoder_optimizer = optim.Adam(ATIS_encoder.parameters(), lr=lr) #take default parameters, just modify lr\n",
        "lr=0.0001\n",
        "ATIS_slot_optimizer = optim.Adam(ATIS_encoder.parameters(), lr=lr) #take default parameters, just modify lr\n",
        "lr=0.0001\n",
        "ATIS_intent_optimizer = optim.Adam(ATIS_encoder.parameters(), lr=lr) #take default parameters, just modify lr"
      ],
      "metadata": {
        "id": "pg8xphWxx056"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ATIS_sampled_epochs, ATIS_losses_train, ATIS_losses_dev = train_bert(\n",
        "    train_loader = ATIS_train_loader, \n",
        "    test_loader = ATIS_test_loader, \n",
        "    dev_loader = ATIS_dev_loader, \n",
        "    encoder = ATIS_encoder, \n",
        "    slot_classifier=ATIS_slot_classifier,\n",
        "    intent_classifier=ATIS_intent_classifier,\n",
        "    encoder_optimizer=ATIS_encoder_optimizer,\n",
        "    slot_optimizer=ATIS_slot_optimizer,\n",
        "    intent_optimizer=ATIS_intent_optimizer,\n",
        "    lang = ATIS_lang)"
      ],
      "metadata": {
        "id": "xeEqcY38x076"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(num = 3, figsize=(8, 5)).patch.set_facecolor('white')\n",
        "plt.title('Train and Dev Losses')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.plot(ATIS_sampled_epochs, ATIS_losses_train, label='Train loss')\n",
        "plt.plot(ATIS_sampled_epochs, ATIS_losses_dev, label='Dev loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UaAAvtjxx0-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GI5Uzg2zx1C5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YDqSx4Ppx1JT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Try convolution"
      ],
      "metadata": {
        "id": "71_kt8BAX5nx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model_adv(nn.Module):\n",
        "#hidden size of rnn, embedding size (size of the vector that represent the word embedding)\n",
        "    def __init__(self, hid_size, out_slot, out_int, emb_size, vocab_len, n_layer=2, pad_index=0):\n",
        "        super(Model_adv, self).__init__()\n",
        "        # hid_size = Hidden size\n",
        "        # out_slot = number of slots (output size for slot filling)\n",
        "        # out_int = number of intents (ouput size for intent class)\n",
        "        # emb_size = word embedding size\n",
        "        \n",
        "        #A simple lookup table that stores embeddings of a fixed dictionary and size.\n",
        "        #The input to the module is a list of indices, and the output is the corresponding word embeddings.\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_len, \n",
        "                                      emb_size, \n",
        "                                      padding_idx=pad_index) #pad idx --> the entities at pad_index do not contribute to the gradient\n",
        "        \n",
        "        \"\"\"\n",
        "        num_embeddings (int) – size of the dictionary of embeddings\n",
        "\n",
        "        embedding_dim (int) – the size of each embedding vector\n",
        "\n",
        "        padding_idx (int, optional) – If specified, the entries at padding_idx do not contribute to the gradient; \n",
        "      \n",
        "        \"\"\"\n",
        "        self.utt_encoder = nn.LSTM(emb_size, \n",
        "                                   hid_size, \n",
        "                                   n_layer,\n",
        "                                   bidirectional=True)     #network, bidirectional\n",
        "\n",
        "\n",
        "        self.conv_intent = nn.Conv1d(in_channels = 200, out_channels = 100, kernel_size = 3, padding =1)\n",
        "\n",
        "        \"\"\"  \n",
        "        input_size – The number of expected features in the input x\n",
        "        hidden_size – The number of features in the hidden state h\n",
        "        num_layers – Number of recurrent layers. \n",
        "        \"\"\"\n",
        "        self.dropout = nn.Dropout(0.7) #regularization --> randomly mute a neuron, only on training phase. Helps to avoid overfitting\n",
        "\n",
        "\n",
        "        self.slot_out = nn.Linear(hid_size*2, out_slot)\n",
        "\n",
        "        self.intent_out = nn.Linear(100, out_int)\n",
        "      \n",
        "        #self.dropout = nn.Dropout(0.7) #regularization --> randomly mute a neuron, only on training phase. Helps to avoid overfitting\n",
        "        \n",
        "    def forward(self, utterance, seq_lengths): #define the architecture\n",
        "        # utterance.size() = batch_size X seq_len\n",
        "        utt_emb = self.embedding(utterance) # utt_emb.size() = batch_size X seq_len X emb_size\n",
        "        #--> get word embedding\n",
        "        utt_emb = utt_emb.permute(1,0,2) # we need seq len first -> seq_len X batch_size X emb_size\n",
        "        \n",
        "        # pack_padded_sequence avoid computation over pad tokens reducing the computational cost\n",
        "        \n",
        "        packed_input = pack_padded_sequence(utt_emb, seq_lengths.cpu().numpy())\n",
        "        # Process the batch\n",
        "        packed_output, (last_hidden, cell) = self.utt_encoder(packed_input) \n",
        "\n",
        "        #print(\"\\n\",last_hidden)\n",
        "        #print(packed_input.size)\n",
        "        #packed_output2, (last_hidden2, cell2) = self.utt_encoder(packed_output) \n",
        "  \n",
        "        #packed output containing the output features (h_t) from the last layer of the LSTM, \n",
        "        #for each t. If a torch.nn.utils.rnn.PackedSequence has been given as the \n",
        "        #input, the output will also be a packed sequence.\n",
        "\n",
        "        #last_hidden containing the final hidden state for each element in the sequence\n",
        "        #cell containing the final cell state for each element in the sequence\n",
        "        \n",
        "        # Unpack the sequence\n",
        "        utt_encoded, input_sizes = pad_packed_sequence(packed_output)\n",
        "        #utt_encoded.shape: [sentence lenght, 128, 200] \n",
        "\n",
        "        # Get the last hidden state\n",
        "        #last_hidde.shape: [1, 128, 200]\n",
        "        \n",
        "        #last_hidde.shape: [128, 200] -> [batch size, hidden_size]\n",
        "\n",
        "        #print(\"\\nutt_encoded.shape: \", utt_encoded.shape)\n",
        "        #print(\"\\nlast hidden.shape\",last_hidden.shape)\n",
        "        \n",
        "        \"\"\"\n",
        "        utt_encoded = utt_encoded.permute(1,2,0)\n",
        "\n",
        "        print(\"\\nbefore:\\n\", utt_encoded.shape)\n",
        "\n",
        "        utt_conv = self.conv_slots(utt_encoded)\n",
        "\n",
        "        print(\"\\nafter:\\n\", utt_conv.shape)\n",
        "\n",
        "        utt_conv = utt_conv.permute(2,0,1)\n",
        "        \"\"\"\n",
        "        \n",
        "        last_hidden = last_hidden.permute(1,2,0)\n",
        "\n",
        "        \"\"\"hidden_conv = self.conv_intent(last_hidden)\n",
        "\n",
        "        hidden_conv = hidden_conv.permute(2,0,1)\n",
        "\n",
        "        hidden_conv = hidden_conv[-1,:,:]\"\"\"\n",
        "\n",
        "        drop_utt = self.dropout(utt_encoded)\n",
        "        drop_hidden = self.dropout(last_hidden)\n",
        "       \n",
        "        # Compute slot logits, i use the encoded representation of the utterance, with the encoding of each word\n",
        "        slots = self.slot_out(drop_utt)\n",
        "        #slots.shape: [sentence_lenght, batch_size, out_slots]\n",
        "        #print(\"slots size: \", slots.shape)\n",
        "        #print(\"\\n\\n\",slots,\"\\n\\n\")\n",
        "        \n",
        "        \"\"\"\n",
        "        prova = slots\n",
        "        #print(\"\\n\\nprova size:\", prova.shape, \"\\n\\n\")\n",
        "\n",
        "        prova = prova.permute(1,0,2)\n",
        "          \n",
        "        #print(last_hidden.shape)\n",
        "        new_hidden = []\n",
        "        for i, sent in enumerate(prova):\n",
        "          #print(\"\\nsent:\\n\", sent)\n",
        "          slots_in_sentence = [0] * 73\n",
        "          for word in sent:\n",
        "            #print(\"\\nword:\\n\", word)\n",
        "            pred_slot = int(torch.argmax(word))\n",
        "            slots_in_sentence[pred_slot] += 1 \n",
        "          #tensor_pred_slots = torch.tensor(pred_slots).to(device)\n",
        "          #last_hidden[i] = torch.cat((last_hidden[i], tensor_pred_slots))\n",
        "          #print(\"\\npred_slots\\n\", slots_in_sentence)\n",
        "          tensor_slots = torch.tensor(slots_in_sentence).to(device)\n",
        "          #print(\"\\nlast hidden\\n\",last_hidden[i].shape)\n",
        "          #print(\"\\ntensor_slots.shape\\n\",tensor_slots.shape)\n",
        "          repr = torch.cat((last_hidden[i], tensor_slots))\n",
        "          new_hidden.append(list(repr))\n",
        "        new_hidden = torch.tensor(new_hidden).to(device)  \n",
        "        #print(\"\\n New hidden SHAPE\\n\",new_hidden.shape)\n",
        "        #last_hidden[i] = new_hidden\n",
        "        \"\"\"\n",
        "\n",
        "        #print(last_hidden.shape)\n",
        "        #utt_encoded[1] = torch.cat((utt_encoded[1], slots[2]))\n",
        "        #utt_and_slot = torch.cat((utt_encoded, slots[2]), dim=1) \n",
        "        #print(\"\\nutt_and_slot.shape: \", utt_encoded.shape)\n",
        "\n",
        "        # Compute intent logits\n",
        "        #intent = self.intent_out(last_hidden)\n",
        "\n",
        "        #drop_hidden = self.dropout(last_hidden)\n",
        "\n",
        "        intent = self.intent_out(drop_hidden)\n",
        "        #print(intent.shape)\n",
        "\n",
        "        #intent.shape: [128, out_intent] --> [batch_size, possible slots in dataset]\n",
        "        \n",
        "        #print(\"\\n intent.shape: \\n\", intent.shape)\n",
        "        #print(\"\\n slots.shape first: \\n\", slots.shape)\n",
        "        #print(\"\\n intent: \\n\", intent)\n",
        "        #print(\"\\n slots first: \\n\", slots)\n",
        "\n",
        "\n",
        "        # Slot size: [seq_len, batch size, out_slot] \n",
        "        slots = slots.permute(1,2,0) # We need this for computing the loss\n",
        "        # Slot size: [batch_size, out_slot, seq_len]\n",
        "\n",
        "        return slots, intent"
      ],
      "metadata": {
        "id": "hcrXFrpDYYhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tIhwgs8fWu2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model_adv(nn.Module):\n",
        "#hidden size of rnn, embedding size (size of the vector that represent the word embedding)\n",
        "    def __init__(self, hid_size, out_slot, out_int, emb_size, vocab_len, n_layer=1, pad_index=0):\n",
        "        super(Model_adv, self).__init__()\n",
        "        # hid_size = Hidden size\n",
        "        # out_slot = number of slots (output size for slot filling)\n",
        "        # out_int = number of intents (ouput size for intent class)\n",
        "        # emb_size = word embedding size\n",
        "        \n",
        "        #A simple lookup table that stores embeddings of a fixed dictionary and size.\n",
        "        #The input to the module is a list of indices, and the output is the corresponding word embeddings.\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_len, \n",
        "                                      emb_size, \n",
        "                                      padding_idx=pad_index) #pad idx --> the entities at pad_index do not contribute to the gradient\n",
        "        \n",
        "        \"\"\"\n",
        "        num_embeddings (int) – size of the dictionary of embeddings\n",
        "\n",
        "        embedding_dim (int) – the size of each embedding vector\n",
        "\n",
        "        padding_idx (int, optional) – If specified, the entries at padding_idx do not contribute to the gradient; \n",
        "      \n",
        "        \"\"\"\n",
        "        self.utt_encoder = nn.LSTM(emb_size, \n",
        "                                   hid_size, \n",
        "                                   n_layer,\n",
        "                                   bidirectional=True)     #network, bidirectional\n",
        "\n",
        "\n",
        "\n",
        "        \"\"\"  \n",
        "        input_size – The number of expected features in the input x\n",
        "        hidden_size – The number of features in the hidden state h\n",
        "        num_layers – Number of recurrent layers. \n",
        "        \"\"\"\n",
        "        self.dropout = nn.Dropout(0.7) #regularization --> randomly mute a neuron, only on training phase. Helps to avoid overfitting\n",
        "\n",
        "        self.slot_out = nn.Linear(hid_size*2, out_slot)\n",
        "\n",
        "        self.intent_out = nn.Linear(hid_size, out_int)\n",
        "      \n",
        "        #self.dropout = nn.Dropout(0.7) #regularization --> randomly mute a neuron, only on training phase. Helps to avoid overfitting\n",
        "        \n",
        "    def forward(self, utterance, seq_lengths): #define the architecture\n",
        "        # utterance.size() = batch_size X seq_len\n",
        "        utt_emb = self.embedding(utterance) # utt_emb.size() = batch_size X seq_len X emb_size\n",
        "        #--> get word embedding\n",
        "        utt_emb = utt_emb.permute(1,0,2) # we need seq len first -> seq_len X batch_size X emb_size\n",
        "        \n",
        "        # pack_padded_sequence avoid computation over pad tokens reducing the computational cost\n",
        "        \n",
        "        packed_input = pack_padded_sequence(utt_emb, seq_lengths.cpu().numpy())\n",
        "        # Process the batch\n",
        "        packed_output, (last_hidden, cell) = self.utt_encoder(packed_input) \n",
        "\n",
        "        #print(\"\\n\",last_hidden)\n",
        "        #print(packed_input.size)\n",
        "        #packed_output2, (last_hidden2, cell2) = self.utt_encoder(packed_output) \n",
        "  \n",
        "        #packed output containing the output features (h_t) from the last layer of the LSTM, \n",
        "        #for each t. If a torch.nn.utils.rnn.PackedSequence has been given as the \n",
        "        #input, the output will also be a packed sequence.\n",
        "\n",
        "        #last_hidden containing the final hidden state for each element in the sequence\n",
        "        #cell containing the final cell state for each element in the sequence\n",
        "        \n",
        "        # Unpack the sequence\n",
        "        utt_encoded, input_sizes = pad_packed_sequence(packed_output)\n",
        "        #utt_encoded.shape: [sentence lenght, 128, 200] \n",
        "\n",
        "        # Get the last hidden state\n",
        "        #last_hidde.shape: [1, 128, 200]\n",
        "        last_hidden = last_hidden[-1,:,:]\n",
        "        #last_hidde.shape: [128, 200] -> [batch size, hidden_size]\n",
        "\n",
        "        #print(\"\\nutt_encoded.shape: \", utt_encoded.shape)\n",
        "        #print(\"\\nlast hidden.shape\",last_hidden.shape)\n",
        "        \n",
        "        drop_utt = self.dropout(utt_encoded)\n",
        "        drop_hidden = self.dropout(last_hidden)\n",
        "       \n",
        "        # Compute slot logits, i use the encoded representation of the utterance, with the encoding of each word\n",
        "        slots = self.slot_out(drop_utt)\n",
        "        #slots.shape: [sentence_lenght, batch_size, out_slots]\n",
        "        #print(\"slots size: \", slots.shape)\n",
        "        #print(\"\\n\\n\",slots,\"\\n\\n\")\n",
        "        #print(\"\\nslots_before.shape:\\n\", slots.shape)\n",
        "        \"\"\"\n",
        "        prova = slots\n",
        "        #print(\"\\n\\nprova size:\", prova.shape, \"\\n\\n\")\n",
        "\n",
        "        prova = prova.permute(1,0,2)\n",
        "          \n",
        "        #print(last_hidden.shape)\n",
        "        new_hidden = []\n",
        "        for i, sent in enumerate(prova):\n",
        "          #print(\"\\nsent:\\n\", sent)\n",
        "          slots_in_sentence = [0] * 73\n",
        "          for word in sent:\n",
        "            #print(\"\\nword:\\n\", word)\n",
        "            pred_slot = int(torch.argmax(word))\n",
        "            slots_in_sentence[pred_slot] += 1 \n",
        "          #tensor_pred_slots = torch.tensor(pred_slots).to(device)\n",
        "          #last_hidden[i] = torch.cat((last_hidden[i], tensor_pred_slots))\n",
        "          #print(\"\\npred_slots\\n\", slots_in_sentence)\n",
        "          tensor_slots = torch.tensor(slots_in_sentence).to(device)\n",
        "          #print(\"\\nlast hidden\\n\",last_hidden[i].shape)\n",
        "          #print(\"\\ntensor_slots.shape\\n\",tensor_slots.shape)\n",
        "          repr = torch.cat((last_hidden[i], tensor_slots))\n",
        "          new_hidden.append(list(repr))\n",
        "        new_hidden = torch.tensor(new_hidden).to(device)  \n",
        "        #print(\"\\n New hidden SHAPE\\n\",new_hidden.shape)\n",
        "        #last_hidden[i] = new_hidden\n",
        "        \"\"\"\n",
        "\n",
        "        #print(last_hidden.shape)\n",
        "        #utt_encoded[1] = torch.cat((utt_encoded[1], slots[2]))\n",
        "        #utt_and_slot = torch.cat((utt_encoded, slots[2]), dim=1) \n",
        "        #print(\"\\nutt_and_slot.shape: \", utt_encoded.shape)\n",
        "\n",
        "        # Compute intent logits\n",
        "        #intent = self.intent_out(last_hidden)\n",
        "\n",
        "        #drop_hidden = self.dropout(last_hidden)\n",
        "\n",
        "        intent = self.intent_out(drop_hidden)\n",
        "        #print(intent.shape)\n",
        "\n",
        "        #intent.shape: [128, out_intent] --> [batch_size, possible slots in dataset]\n",
        "        \n",
        "        #print(\"\\n intent.shape: \\n\", intent.shape)\n",
        "        #print(\"\\n slots.shape first: \\n\", slots.shape)\n",
        "        #print(\"\\n intent: \\n\", intent)\n",
        "        #print(\"\\n slots first: \\n\", slots)\n",
        "\n",
        "\n",
        "        # Slot size: [seq_len, batch size, out_slot] \n",
        "        slots = slots.permute(1,2,0) # We need this for computing the loss\n",
        "        # Slot size: [batch_size, out_slot, seq_len]\n",
        "\n",
        "        return slots, intent"
      ],
      "metadata": {
        "id": "J_g6sqSUVCDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Te_W_dItWu43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VkXgMD2xWu73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "576hptF5Wu9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "L6wu3QcwWvA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zMbk8KHaWvCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xTjoA0SIWvIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xkwg4zxuWvKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZXvwASqqWvM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "luI3etNfWvPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_EobQ675WvR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "H3dUKb6nWvVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROVO 2 LSTM"
      ],
      "metadata": {
        "id": "bzMAH7XJFp8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model_both(nn.Module):\n",
        "#hidden size of rnn, embedding size (size of the vector that represent the word embedding)\n",
        "    def __init__(self, hid_size, out_slot, out_int, emb_size, vocab_len, n_layer=1, pad_index=0):\n",
        "        super(Model_both, self).__init__()\n",
        "        # hid_size = Hidden size\n",
        "        # out_slot = number of slots (output size for slot filling)\n",
        "        # out_int = number of intents (ouput size for intent class)\n",
        "        # emb_size = word embedding size\n",
        "        \n",
        "        #A simple lookup table that stores embeddings of a fixed dictionary and size.\n",
        "        #The input to the module is a list of indices, and the output is the corresponding word embeddings.\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_len, \n",
        "                                      emb_size, \n",
        "                                      padding_idx=pad_index) #pad idx --> the entities at pad_index do not contribute to the gradient\n",
        "        \n",
        "        \"\"\"\n",
        "        num_embeddings (int) – size of the dictionary of embeddings\n",
        "\n",
        "        embedding_dim (int) – the size of each embedding vector\n",
        "\n",
        "        padding_idx (int, optional) – If specified, the entries at padding_idx do not contribute to the gradient; \n",
        "      \n",
        "        \"\"\"\n",
        "        self.utt_encoder = nn.LSTM(emb_size, \n",
        "                                   hid_size, \n",
        "                                   n_layer,\n",
        "                                   bidirectional=False)     #network, bidirectional\n",
        "\n",
        "        self.intent_LSTM = nn.LSTM(hid_size, \n",
        "                                  hid_size, \n",
        "                                  n_layer,\n",
        "                                  bidirectional=False) \n",
        "\n",
        "        \"\"\"  \n",
        "        input_size – The number of expected features in the input x\n",
        "        hidden_size – The number of features in the hidden state h\n",
        "        num_layers – Number of recurrent layers. \n",
        "        \"\"\"\n",
        "        self.dropout = nn.Dropout(0.1) #regularization --> randomly mute a neuron, only on training phase. Helps to avoid overfitting\n",
        "\n",
        "        self.slot_out = nn.Linear(hid_size, out_slot)\n",
        "\n",
        "        self.intent_out = nn.Linear(hid_size, out_int)\n",
        "      \n",
        "        #self.dropout = nn.Dropout(0.7) #regularization --> randomly mute a neuron, only on training phase. Helps to avoid overfitting\n",
        "        \n",
        "    def forward(self, utterance, seq_lengths, both_LSTM): #define the architecture\n",
        "        # utterance.size() = batch_size X seq_len\n",
        "        utt_emb = self.embedding(utterance) # utt_emb.size() = batch_size X seq_len X emb_size\n",
        "        #--> get word embedding\n",
        "        utt_emb = utt_emb.permute(1,0,2) # we need seq len first -> seq_len X batch_size X emb_size\n",
        "        \n",
        "        # pack_padded_sequence avoid computation over pad tokens reducing the computational cost\n",
        "        \n",
        "        packed_input = pack_padded_sequence(utt_emb, seq_lengths.cpu().numpy())\n",
        "        # Process the batch\n",
        "        packed_output, (last_hidden, cell) = self.utt_encoder(packed_input) \n",
        "\n",
        "        \n",
        "        if both_LSTM:\n",
        "          packed_output, (last_hidden, cell) = self.intent_LSTM(packed_output)\n",
        "          \n",
        "        # Unpack the sequence\n",
        "        utt_encoded, input_sizes = pad_packed_sequence(packed_output)\n",
        "        #utt_encoded.shape: [sentence lenght, 128, 200] \n",
        "        #print(utt_encoded.shape)\n",
        "        # Get the last hidden state\n",
        "        #last_hidde.shape: [1, 128, 200]\n",
        "        last_hidden = last_hidden[-1,:,:]\n",
        "        #last_hidde.shape: [128, 200] -> [batch size, hidden_size]\n",
        "\n",
        "        #print(\"\\nutt_encoded.shape: \", utt_encoded.shape)\n",
        "        #print(\"\\nlast hidden.shape\",last_hidden.shape)\n",
        "        \n",
        "        #drop_utt = self.dropout(utt_encoded)\n",
        "\n",
        "        # Compute slot logits, i use the encoded representation of the utterance, with the encoding of each word\n",
        "        \n",
        "        #slots.shape: [sentence_lenght, batch_size, out_slots]\n",
        "        intent = self.intent_out(last_hidden)\n",
        "        \n",
        "        if not both_LSTM:\n",
        "          slots = self.slot_out(utt_encoded)\n",
        "          slots = slots.permute(1,2,0) # We need this for computing the loss\n",
        "        else:\n",
        "          slots = None\n",
        "        #print(intent.shape)\n",
        "\n",
        "        #intent.shape: [128, out_intent] --> [batch_size, possible slots in dataset]\n",
        "\n",
        "        # Slot size: [seq_len, batch size, out_slot] \n",
        "       \n",
        "        # Slot size: [batch_size, out_slot, seq_len]\n",
        "\n",
        "        return slots, intent"
      ],
      "metadata": {
        "id": "PpxesL0YGvZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAIN BOTH"
      ],
      "metadata": {
        "id": "Vkij35UvIpQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_adv(train_loader, test_loader, dev_loader, model, optimizer, lang, both_LSTM, n_epochs=200, patience=8):\n",
        " \n",
        "  losses_train = []\n",
        "  losses_dev = []\n",
        "  sampled_epochs = []\n",
        "  best_f1 = 0\n",
        "  for x in tqdm(range(1,n_epochs)):\n",
        "      loss = train_loop_adv(train_loader, optimizer, criterion_slots, \n",
        "                        criterion_intents, model, both_LSTM)\n",
        "      if x % 5 == 0:\n",
        "          sampled_epochs.append(x)\n",
        "          losses_train.append(np.asarray(loss).mean())\n",
        "          results_dev, intent_res, loss_dev = eval_loop_adv(dev_loader, criterion_slots, \n",
        "                                                        criterion_intents, model, lang, both_LSTM)\n",
        "          losses_dev.append(np.asarray(loss_dev).mean())\n",
        "          f1 = results_dev['total']['f']\n",
        "          \n",
        "          if f1 > best_f1: #sometimes loss words but f1 increases, we have to look at both and figure out what of the 2 to use to stop the training\n",
        "              best_f1 = f1\n",
        "          else:\n",
        "              patience -= 1\n",
        "          if patience <= 0: # Early stopping with patience\n",
        "              break # Not nice but it keeps the code clean\n",
        "\n",
        "  results_test, intent_test, _ = eval_loop_adv(test_loader, criterion_slots, \n",
        "                                          criterion_intents, model, lang, both_LSTM)    \n",
        "  print('\\nSlot F1: ', results_test['total']['f'])\n",
        "  print('Intent Accuracy:', intent_test['accuracy'])\n",
        "  return sampled_epochs, losses_train, losses_dev"
      ],
      "metadata": {
        "id": "dSc6ZSvqIoUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_fOXtHhIuKP"
      },
      "outputs": [],
      "source": [
        "from conll import evaluate\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def train_loop_adv(data, optimizer, criterion_slots, criterion_intents, model, both_LSTM):\n",
        "    model.train()\n",
        "    loss_array = []\n",
        "    for sample in data:\n",
        "        optimizer.zero_grad() # Zeroing the gradient\n",
        "        slots, intent = model(utterance = sample['utterances'], seq_lengths = sample['slots_len'], both_LSTM = both_LSTM)\n",
        "        loss_intent = criterion_intents(intent, sample['intents'])\n",
        "        loss = loss_intent # In joint training we sum the losses. \n",
        "                                       # Is there another way to do that?\n",
        "                                       # you can decide to give more imporante to intent or slots with a linear combination\n",
        "        loss_array.append(loss.item())\n",
        "        loss.backward() # Compute the gradient, deleting the computational graph\n",
        "        # clip the gradient to avoid explosioning gradients\n",
        "        # torch.nn.utils.clip_grad_norm_(model.parameters(), clip)  \n",
        "        optimizer.step() # Update the weights\n",
        "    return loss_array\n",
        "\n",
        "def eval_loop_adv(data, criterion_slots, criterion_intents, model, lang, both_LSTM):\n",
        "    model.eval()\n",
        "    loss_array = []\n",
        "    \n",
        "    ref_intents = []\n",
        "    hyp_intents = []\n",
        "    \n",
        "    ref_slots = []\n",
        "    hyp_slots = []\n",
        "    #softmax = nn.Softmax(dim=1) # Use Softmax if you need the actual probability\n",
        "    with torch.no_grad(): # It used to avoid the creation of computational graph\n",
        "        for sample in data:\n",
        "            slots, intents = model(sample['utterances'], sample['slots_len'], both_LSTM)\n",
        "            loss_intent = criterion_intents(intents, sample['intents'])\n",
        "            \n",
        "            loss = loss_intent\n",
        "            loss_array.append(loss.item())\n",
        "            # Intent inference\n",
        "            # Get the highest probable class\n",
        "            out_intents = [lang.id2intent[x] \n",
        "                           for x in torch.argmax(intents, dim=1).tolist()] \n",
        "            gt_intents = [lang.id2intent[x] for x in sample['intents'].tolist()]\n",
        "            ref_intents.extend(gt_intents)\n",
        "            hyp_intents.extend(out_intents)\n",
        "            \n",
        "            if not both_LSTM:\n",
        "              # Slot inference \n",
        "              output_slots = torch.argmax(slots, dim=1)\n",
        "              for id_seq, seq in enumerate(output_slots):\n",
        "                  length = sample['slots_len'].tolist()[id_seq]\n",
        "                  utt_ids = sample['utterance'][id_seq][:length].tolist()\n",
        "                  gt_ids = sample['y_slots'][id_seq].tolist()\n",
        "                  gt_slots = [lang.id2slot[elem] for elem in gt_ids[:length]]\n",
        "                  utterance = [lang.id2word[elem] for elem in utt_ids]\n",
        "                  to_decode = seq[:length].tolist()\n",
        "                  ref_slots.append([(utterance[id_el], elem) for id_el, elem in enumerate(gt_slots)])\n",
        "                  tmp_seq = []\n",
        "                  for id_el, elem in enumerate(to_decode):\n",
        "                      tmp_seq.append((utterance[id_el], lang.id2slot[elem]) if elem != 0 else (utterance[id_el], 'O'))\n",
        "                  hyp_slots.append(tmp_seq)\n",
        "    try:            \n",
        "        results = evaluate(ref_slots, hyp_slots)\n",
        "    except Exception as ex: #if your model predict slot that are not in ref, it gives error\n",
        "        # Sometimes the model predics a class that is not in REF\n",
        "        print(ex)\n",
        "        ref_s = set([x[1] for x in ref_slots])\n",
        "        hyp_s = set([x[1] for x in hyp_slots])\n",
        "        print(hyp_s.difference(ref_s))\n",
        "        \n",
        "    report_intent = classification_report(ref_intents, hyp_intents, \n",
        "                                          zero_division=False, output_dict=True)\n",
        "    return results, report_intent, loss_array\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SNIPS_model_both = Model_both(hid_size, SNIPS_out_slot, SNIPS_out_int, emb_size, SNIPS_vocab_len, pad_index=PAD_TOKEN).to(device)\n",
        "SNIPS_model_both.apply(init_weights)\n",
        "SNIPS_optimizer_adv = optim.Adam(SNIPS_model_both.parameters(), lr=lr, weight_decay=wd) #take default parameters, just modify lr"
      ],
      "metadata": {
        "id": "FyC_cMWUKrmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SNIPS_sampled_epochs_adv, SNIPS_losses_train_adv, SNIPS_losses_dev_adv = train_adv(\n",
        "  train_loader = SNIPS_train_loader, \n",
        "  test_loader = SNIPS_test_loader, \n",
        "  dev_loader = SNIPS_dev_loader, \n",
        "  model = SNIPS_model_both, \n",
        "  optimizer = SNIPS_optimizer_adv,\n",
        "  lang = SNIPS_lang,\n",
        "  both_LSTM = False)"
      ],
      "metadata": {
        "id": "_JddQ-3aTjbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(num = 3, figsize=(8, 5)).patch.set_facecolor('white')\n",
        "plt.title('Train and Dev Losses')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.plot(SNIPS_sampled_epochs_adv, SNIPS_losses_train_adv, label='Train loss')\n",
        "plt.plot(SNIPS_sampled_epochs_adv, SNIPS_losses_dev_adv, label='Dev loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xtsAUl33Vcx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SNIPS_sampled_epochs_adv, SNIPS_losses_train_adv, SNIPS_losses_dev_adv = train_adv(\n",
        "train_loader = SNIPS_train_loader, \n",
        "test_loader = SNIPS_test_loader, \n",
        "dev_loader = SNIPS_dev_loader, \n",
        "model = SNIPS_model_both, \n",
        "optimizer = SNIPS_optimizer_adv,\n",
        "lang = SNIPS_lang,\n",
        "both_LSTM = True)"
      ],
      "metadata": {
        "id": "efuzW9Z-J4qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(num = 3, figsize=(8, 5)).patch.set_facecolor('white')\n",
        "plt.title('Train and Dev Losses')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.plot(SNIPS_sampled_epochs_adv, SNIPS_losses_train_adv, label='Train loss')\n",
        "plt.plot(SNIPS_sampled_epochs_adv, SNIPS_losses_dev_adv, label='Dev loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dKH4mWb5VfCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_r_OnwGNFWx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tlzC5SoYFW2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "35C94plOFW4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PM4XBlhtFW63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ic0bm7NuFW9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UpFcRkftFW_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "s-2l5kE8FXCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wTBzw3SbFXEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7q81wp6gFXGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "P5ztT2iqFXJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1ssCeKUQFXLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "r74ooNG2FXN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "#hidden size of rnn, embedding size (size of the vector that represent the word embedding)\n",
        "    def __init__(self, hid_size, out_slot, out_int, emb_size, vocab_len, n_layer=1, pad_index=0):\n",
        "        super(Encoder, self).__init__()\n",
        "        # hid_size = Hidden size\n",
        "        # out_slot = number of slots (output size for slot filling)\n",
        "        # out_int = number of intents (ouput size for intent class)\n",
        "        # emb_size = word embedding size\n",
        "        \n",
        "        #A simple lookup table that stores embeddings of a fixed dictionary and size.\n",
        "        #The input to the module is a list of indices, and the output is the corresponding word embeddings.\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_len, \n",
        "                                      emb_size, \n",
        "                                      padding_idx=pad_index) #pad idx --> the entities at pad_index do not contribute to the gradient\n",
        "        \n",
        "        \"\"\"\n",
        "        num_embeddings (int) – size of the dictionary of embeddings\n",
        "\n",
        "        embedding_dim (int) – the size of each embedding vector\n",
        "\n",
        "        padding_idx (int, optional) – If specified, the entries at padding_idx do not contribute to the gradient; \n",
        "        \"\"\"\n",
        "        self.utt_encoder = nn.LSTM(emb_size, \n",
        "                                   hid_size, \n",
        "                                   n_layer,\n",
        "                                   bidirectional=True)     #network, bidirectional\n",
        "\n",
        "        \"\"\"  \n",
        "        input_size – The number of expected features in the input x\n",
        "        hidden_size – The number of features in the hidden state h\n",
        "        num_layers – Number of recurrent layers. \n",
        "        \"\"\"\n",
        "      \n",
        "        \n",
        "    def forward(self, utterance, seq_lengths): #define the architecture\n",
        "        # utterance.size() = batch_size X seq_len\n",
        "        utt_emb = self.embedding(utterance) # utt_emb.size() = batch_size X seq_len X emb_size\n",
        "        #--> get word embedding\n",
        "        utt_emb = utt_emb.permute(1,0,2) # we need seq len first -> seq_len X batch_size X emb_size\n",
        "        \n",
        "        # pack_padded_sequence avoid computation over pad tokens reducing the computational cost\n",
        "        \n",
        "        packed_input = pack_padded_sequence(utt_emb, seq_lengths.cpu().numpy())\n",
        "        # Process the batch\n",
        "        packed_output, (last_hidden, cell) = self.utt_encoder(packed_input) \n",
        "        \n",
        "        # Unpack the sequence\n",
        "        utt_encoded, input_sizes = pad_packed_sequence(packed_output)\n",
        "        #utt_encoded.shape: [sentence lenght, 128, 200] \n",
        "\n",
        "        # Get the last hidden state\n",
        "        #last_hidde.shape: [1, 128, 200]\n",
        "        last_hidden = last_hidden[-1,:,:]\n",
        "        #last_hidde.shape: [128, 200] -> [batch size, hidden_size]\n",
        "\n",
        "        return last_hidden"
      ],
      "metadata": {
        "id": "YuAkSJZNCN13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SNIPS_model_adv = Encoder(hid_size, SNIPS_out_slot, SNIPS_out_int, emb_size, SNIPS_vocab_len, pad_index=PAD_TOKEN).to(device)\n",
        "SNIPS_model_adv.apply(init_weights)\n",
        "SNIPS_optimizer_adv = optim.Adam(SNIPS_model_adv.parameters(), lr=lr, weight_decay=wd) #take default parameters, just modify lr"
      ],
      "metadata": {
        "id": "9IM5nlWBDoyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SNIPS_sampled_epochs_adv, SNIPS_losses_train_adv, SNIPS_losses_dev_adv = train_adv(\n",
        "train_loader = SNIPS_train_loader, \n",
        "test_loader = SNIPS_test_loader, \n",
        "dev_loader = SNIPS_dev_loader, \n",
        "model = SNIPS_model_adv, \n",
        "optimizer = SNIPS_optimizer_adv,\n",
        "lang = SNIPS_lang)"
      ],
      "metadata": {
        "id": "RVTFpnSWDo2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SNIPS_model_adv.slot_out = nn.Identity()\n",
        "SNIPS_model_adv.intent_out = nn.Identity()"
      ],
      "metadata": {
        "id": "i90KQwcwGK6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(SNIPS_model_adv)"
      ],
      "metadata": {
        "id": "BS_lMssNFuVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Intent_LSTM(nn.Module):\n",
        "#hidden size of rnn, embedding size (size of the vector that represent the word embedding)\n",
        "    def __init__(self, hid_size, out_int, vocab_len, n_layer=1, pad_index=0):\n",
        "        super(Intent_LSTM, self).__init__()\n",
        "\n",
        "        self.final_hidden = nn.LSTM(200, \n",
        "                                   200, \n",
        "                                   n_layer,\n",
        "                                   bidirectional=False)     #network, bidirectional\n",
        "\n",
        "        self.dropout = nn.Dropout(0.1) #regularization --> randomly mute a neuron, only on training phase. Helps to avoid overfitting\n",
        "\n",
        "        self.intent_out = nn.Linear(hid_size, out_int)\n",
        "      \n",
        "        \n",
        "    def forward(self, hidden_repr): #define the architecture\n",
        "        # Process the batch\n",
        "        #print(len(hidden_repr[0]))\n",
        "        hidden_tensor = torch.Tensor(hidden_repr[0])\n",
        "        print(hidden_tensor.shape)\n",
        "        packed_output, (last_hidden, cell) = self.final_hidden(hidden_repr[0]) \n",
        "        \n",
        "        #utt_encoded.shape: [sentence lenght, 128, 200] \n",
        "\n",
        "        # Get the last hidden state\n",
        "        #last_hidde.shape: [1, 128, 200]\n",
        "        print(\"last hidden shape\", last_hidden.shape)\n",
        "        last_hidden = last_hidden[-1,:,:]\n",
        "        #last_hidde.shape: [128, 200] -> [batch size, hidden_size]\n",
        "\n",
        "        intent = self.intent_out(last_hidden)\n",
        "\n",
        "        return intent"
      ],
      "metadata": {
        "id": "0Q-ry1RREhYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SNIPS_intent_LSTM = Intent_LSTM(hid_size, SNIPS_out_int, SNIPS_vocab_len, pad_index=PAD_TOKEN).to(device)"
      ],
      "metadata": {
        "id": "p0akVZT3HB8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SNIPS_intent_LSTM.apply(init_weights)\n",
        "SNIPS_optimizer_intent = optim.Adam(SNIPS_intent_LSTM.parameters(), lr=lr) #take default parameters, just modify lr"
      ],
      "metadata": {
        "id": "riUeX9jYEKUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(SNIPS_intent_LSTM)"
      ],
      "metadata": {
        "id": "-75Qj5oqDo5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SNIPS_sampled_epochs_final, SNIPS_losses_train_final, SNIPS_losses_dev_final = train_intent_LSTM(\n",
        "train_loader = SNIPS_train_loader, \n",
        "test_loader = SNIPS_test_loader, \n",
        "dev_loader = SNIPS_dev_loader, \n",
        "encoder = SNIPS_model_adv,\n",
        "model = SNIPS_intent_LSTM, \n",
        "optimizer = SNIPS_optimizer_intent,\n",
        "lang = SNIPS_lang)"
      ],
      "metadata": {
        "id": "z9A5WqK4Do7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2Eb6HC2IFHZ"
      },
      "outputs": [],
      "source": [
        "from conll import evaluate\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def train_loop_intent_LSTM(data, optimizer, criterion_slots, criterion_intents, encoder, model):\n",
        "    model.train()\n",
        "    loss_array = []\n",
        "    for sample in data:\n",
        "        optimizer.zero_grad() # Zeroing the gradient\n",
        "        hidden = encoder(sample['utterances'], sample['slots_len'])\n",
        "        print(\"hidden_shape: \", torch.Tensor(hidden).shape)\n",
        "        final = model(hidden)\n",
        "        loss_intent = criterion_intents(final, sample['intents'])\n",
        "        loss = loss_intent  # In joint training we sum the losses. \n",
        "                            # Is there another way to do that?\n",
        "                            # you can decide to give more imporante to intent or slots with a linear combination\n",
        "        loss_array.append(loss.item())\n",
        "        loss.backward() # Compute the gradient, deleting the computational graph\n",
        "        # clip the gradient to avoid explosioning gradients\n",
        "        # torch.nn.utils.clip_grad_norm_(model.parameters(), clip)  \n",
        "        optimizer.step() # Update the weights\n",
        "    return loss_array\n",
        "\n",
        "def eval_loop_intent_LSTM(data, criterion_slots, criterion_intents, encoder, model, lang):\n",
        "    model.eval()\n",
        "    loss_array = []\n",
        "    \n",
        "    ref_intents = []\n",
        "    hyp_intents = []\n",
        "    \n",
        "    ref_slots = []\n",
        "    hyp_slots = []\n",
        "    #softmax = nn.Softmax(dim=1) # Use Softmax if you need the actual probability\n",
        "    with torch.no_grad(): # It used to avoid the creation of computational graph\n",
        "        for sample in data:\n",
        "            hidden = encoder(sample['utterances'], sample['slots_len'])\n",
        "            final = model(hidden)\n",
        "            loss_intent = criterion_intents(final, sample['intents'])\n",
        "            loss = loss_intent\n",
        "            loss_array.append(loss.item())\n",
        "            # Intent inference\n",
        "            # Get the highest probable class\n",
        "            out_intents = [lang.id2intent[x] \n",
        "                           for x in torch.argmax(final, dim=1).tolist()] \n",
        "            gt_intents = [lang.id2intent[x] for x in sample['intents'].tolist()]\n",
        "            ref_intents.extend(gt_intents)\n",
        "            hyp_intents.extend(out_intents)\n",
        "        \n",
        "    report_intent = classification_report(ref_intents, hyp_intents, \n",
        "                                          zero_division=False, output_dict=True)\n",
        "    return report_intent, loss_array"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_intent_LSTM(train_loader, test_loader, dev_loader,encoder, model, optimizer, lang, n_epochs=200, patience=3):\n",
        " \n",
        "  losses_train = []\n",
        "  losses_dev = []\n",
        "  sampled_epochs = []\n",
        "  best_f1 = 0\n",
        "  for x in tqdm(range(1,n_epochs)):\n",
        "      loss = train_loop_intent_LSTM(train_loader, optimizer, criterion_slots, \n",
        "                        criterion_intents, encoder, model)\n",
        "      if x % 5 == 0:\n",
        "          sampled_epochs.append(x)\n",
        "          losses_train.append(np.asarray(loss).mean())\n",
        "          results_dev, intent_res, loss_dev = eval_loop_adv(dev_loader, criterion_slots, \n",
        "                                                        criterion_intents, encoder, model, lang)\n",
        "          losses_dev.append(np.asarray(loss_dev).mean())\n",
        "          f1 = results_dev['total']['f']\n",
        "          \n",
        "          if f1 > best_f1: #sometimes loss words but f1 increases, we have to look at both and figure out what of the 2 to use to stop the training\n",
        "              best_f1 = f1\n",
        "          else:\n",
        "              patience -= 1\n",
        "          if patience <= 0: # Early stopping with patience\n",
        "              break # Not nice but it keeps the code clean\n",
        "\n",
        "  results_test, intent_test, _ = eval_loop_adv(test_loader, criterion_slots, \n",
        "                                          criterion_intents, model, lang)    \n",
        "  print('\\nSlot F1: ', results_test['total']['f'])\n",
        "  print('Intent Accuracy:', intent_test['accuracy'])\n",
        "  return sampled_epochs, losses_train, losses_dev"
      ],
      "metadata": {
        "id": "ED3nczzXHzmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wuvdF_lEDo-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "v2zg8sw0In_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iGkwAS7JIoBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HcEYqZ6JIoDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8luRYo-sIoFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wDKSbqbNIoHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ck85-2HHIoKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Wztt1f4wIoMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ATIS_model_adv = Model_adv(hid_size, ATIS_out_slot, ATIS_out_int, emb_size, ATIS_vocab_len, pad_index=PAD_TOKEN).to(device)\n",
        "ATIS_model_adv.apply(init_weights)\n",
        "ATIS_optimizer_adv = optim.Adam(ATIS_model_adv.parameters(), lr=lr, weight_decay=wd) #take default parameters, just modify lr"
      ],
      "metadata": {
        "id": "ZHq4SovEDgK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ATIS_sampled_epochs_adv, ATIS_losses_train_adv, ATIS_losses_dev_adv = train(\n",
        "    train_loader = ATIS_train_loader, \n",
        "    test_loader = ATIS_test_loader, \n",
        "    dev_loader = ATIS_dev_loader, \n",
        "    model = ATIS_model_adv, \n",
        "    optimizer = ATIS_optimizer_adv,\n",
        "    lang = ATIS_lang)"
      ],
      "metadata": {
        "id": "IqOkwOmqDWZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(num = 3, figsize=(8, 5)).patch.set_facecolor('white')\n",
        "plt.title('Train and Dev Losses')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.plot(ATIS_sampled_epochs_adv, ATIS_losses_train_adv, label='Train loss')\n",
        "plt.plot(ATIS_sampled_epochs_adv, ATIS_losses_dev_adv, label='Dev loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g_N1NIYoF-CF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "o0t63Pn4qfn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Third model"
      ],
      "metadata": {
        "id": "ZtjN621xluNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT model script from: huggingface.co\n",
        "from transformers import BertModel #tokenizer + architecture (actual weights)\n",
        "\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "outputs = model(**inputs)\n",
        "\n",
        "last_hidden_states = outputs.last_hidden_state"
      ],
      "metadata": {
        "id": "jyPrrdVvlttO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train"
      ],
      "metadata": {
        "id": "kVeM3IxTfkNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "hid_size = 200\n",
        "emb_size = 300\n",
        "\n",
        "lr = 0.0001 # learning rate\n",
        "clip = 5 # Clip the gradient #clip gradient to a threshold (hyperparameter)"
      ],
      "metadata": {
        "id": "-s2LDJ91TjBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SNIPS_model_adv = Model_adv(hid_size, SNIPS_out_slot, SNIPS_out_int, emb_size, SNIPS_vocab_len, pad_index=PAD_TOKEN).to(device)\n",
        "SNIPS_model_adv.apply(init_weights)\n",
        "SNIPS_optimizer_adv = optim.Adam(SNIPS_model_adv.parameters(), lr=lr) #take default parameters, just modify lr"
      ],
      "metadata": {
        "id": "zhCBr8SdXuB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SNIPS_sampled_epochs_adv, SNIPS_losses_train_adv, SNIPS_losses_dev_adv = train_adv(\n",
        "train_loader = SNIPS_train_loader, \n",
        "test_loader = SNIPS_test_loader, \n",
        "dev_loader = SNIPS_dev_loader, \n",
        "model = SNIPS_model_adv, \n",
        "optimizer = SNIPS_optimizer_adv,\n",
        "lang = SNIPS_lang,\n",
        "train = True)"
      ],
      "metadata": {
        "id": "48phA9wRXv6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(num = 3, figsize=(8, 5)).patch.set_facecolor('white')\n",
        "plt.title('Train and Dev Losses')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.plot(SNIPS_sampled_epochs_adv, SNIPS_losses_train_adv, label='Train loss')\n",
        "plt.plot(SNIPS_sampled_epochs_adv, SNIPS_losses_dev_adv, label='Dev loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a_RxYFo7U5n9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ATIS_model_adv = Model_adv(hid_size, ATIS_out_slot, ATIS_out_int, emb_size, ATIS_vocab_len, pad_index=PAD_TOKEN).to(device)\n",
        "ATIS_model_adv.apply(init_weights)\n",
        "lr=0.0001\n",
        "ATIS_optimizer_adv = optim.Adam(ATIS_model_adv.parameters(), lr=lr) #take default parameters, just modify lr"
      ],
      "metadata": {
        "id": "d7G_r3iaa4it"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ATIS_sampled_epochs, ATIS_losses_train, ATIS_losses_dev = train_adv(\n",
        "    train_loader = ATIS_train_loader, \n",
        "    test_loader = ATIS_test_loader, \n",
        "    dev_loader = ATIS_dev_loader, \n",
        "    model = ATIS_model, \n",
        "    optimizer = ATIS_optimizer,\n",
        "    lang = ATIS_lang)"
      ],
      "metadata": {
        "id": "u8i4C0h_bDz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(num = 3, figsize=(8, 5)).patch.set_facecolor('white')\n",
        "plt.title('Train and Dev Losses')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.plot(ATIS_sampled_epochs, ATIS_losses_train, label='Train loss')\n",
        "plt.plot(ATIS_sampled_epochs, ATIS_losses_dev, label='Dev loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MIX91eCBa9rV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nj2w3XCpqiDH"
      },
      "outputs": [],
      "source": [
        "from conll import evaluate\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def train_loop_adv(data, optimizer, criterion_slots, criterion_intents, model):\n",
        "    model.train()\n",
        "    loss_array = []\n",
        "    for sample in data:\n",
        "        optimizer.zero_grad() # Zeroing the gradient\n",
        "        slots, intent = model(sample['utterances'], sample['slots_len'])\n",
        "        loss_intent = criterion_intents(intent, sample['intents'])\n",
        "\n",
        "        #print(\"\\nslots.shape:\\n \",slots.shape)\n",
        "        #print(\"\\nsample.shape\\n: \",sample['y_slots'].shape)\n",
        "\n",
        "        #print(\"\\nslots:\\n \",slots)\n",
        "        #print(\"\\nsample\\n: \",sample['y_slots'])\n",
        "\n",
        "        loss_slot = criterion_slots(slots, sample['y_slots'])\n",
        "        loss = loss_intent + loss_slot # In joint training we sum the losses. \n",
        "                                       # Is there another way to do that?\n",
        "                                       # you can decide to give more imporante to intent or slots with a linear combination\n",
        "        loss_array.append(loss.item())\n",
        "        loss.backward() # Compute the gradient, deleting the computational graph\n",
        "        # clip the gradient to avoid explosioning gradients\n",
        "        # torch.nn.utils.clip_grad_norm_(model.parameters(), clip)  \n",
        "        optimizer.step() # Update the weights\n",
        "    return loss_array\n",
        "\n",
        "def eval_loop_adv(data, criterion_slots, criterion_intents, model, lang):\n",
        "    model.eval()\n",
        "    loss_array = []\n",
        "    \n",
        "    ref_intents = []\n",
        "    hyp_intents = []\n",
        "    \n",
        "    ref_slots = []\n",
        "    hyp_slots = []\n",
        "    #softmax = nn.Softmax(dim=1) # Use Softmax if you need the actual probability\n",
        "    with torch.no_grad(): # It used to avoid the creation of computational graph\n",
        "        for sample in data:\n",
        "            slots, intents = model(sample['utterances'], sample['slots_len'])\n",
        "            loss_intent = criterion_intents(intents, sample['intents'])\n",
        "            loss_slot = criterion_slots(slots, sample['y_slots'])\n",
        "            loss = loss_intent + loss_slot \n",
        "            loss_array.append(loss.item())\n",
        "            # Intent inference\n",
        "            # Get the highest probable class\n",
        "            out_intents = [lang.id2intent[x] \n",
        "                           for x in torch.argmax(intents, dim=1).tolist()] \n",
        "            gt_intents = [lang.id2intent[x] for x in sample['intents'].tolist()]\n",
        "            ref_intents.extend(gt_intents)\n",
        "            hyp_intents.extend(out_intents)\n",
        "            \n",
        "            # Slot inference \n",
        "            output_slots = torch.argmax(slots, dim=1)\n",
        "            for id_seq, seq in enumerate(output_slots):\n",
        "                length = sample['slots_len'].tolist()[id_seq]\n",
        "                utt_ids = sample['utterance'][id_seq][:length].tolist()\n",
        "                gt_ids = sample['y_slots'][id_seq].tolist()\n",
        "                gt_slots = [lang.id2slot[elem] for elem in gt_ids[:length]]\n",
        "                utterance = [lang.id2word[elem] for elem in utt_ids]\n",
        "                to_decode = seq[:length].tolist()\n",
        "                ref_slots.append([(utterance[id_el], elem) for id_el, elem in enumerate(gt_slots)])\n",
        "                tmp_seq = []\n",
        "                for id_el, elem in enumerate(to_decode):\n",
        "                    tmp_seq.append((utterance[id_el], lang.id2slot[elem]) if elem != 0 else (utterance[id_el], 'O'))\n",
        "                hyp_slots.append(tmp_seq)\n",
        "    try:            \n",
        "        results = evaluate(ref_slots, hyp_slots)\n",
        "    except Exception as ex: #if your model predict slot that are not in ref, it gives error\n",
        "        # Sometimes the model predics a class that is not in REF\n",
        "        print(ex)\n",
        "        ref_s = set([x[1] for x in ref_slots])\n",
        "        hyp_s = set([x[1] for x in hyp_slots])\n",
        "        print(hyp_s.difference(ref_s))\n",
        "        \n",
        "    report_intent = classification_report(ref_intents, hyp_intents, \n",
        "                                          zero_division=False, output_dict=True)\n",
        "    return results, report_intent, loss_array\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_adv(train_loader, test_loader, dev_loader, model, optimizer, lang, n_epochs=200, patience=3, train=True):\n",
        " \n",
        "  losses_train = []\n",
        "  losses_dev = []\n",
        "  sampled_epochs = []\n",
        "  best_f1 = 0\n",
        "  for x in tqdm(range(1,n_epochs)):\n",
        "      if train:\n",
        "        loss = train_loop_adv(train_loader, optimizer, criterion_slots, \n",
        "                          criterion_intents, model)\n",
        "        if x % 5 == 0:\n",
        "            sampled_epochs.append(x)\n",
        "            losses_train.append(np.asarray(loss).mean())\n",
        "            results_dev, intent_res, loss_dev = eval_loop_adv(dev_loader, criterion_slots, \n",
        "                                                          criterion_intents, model, lang)\n",
        "            losses_dev.append(np.asarray(loss_dev).mean())\n",
        "            f1 = results_dev['total']['f']\n",
        "            \n",
        "            if f1 > best_f1: #sometimes loss words but f1 increases, we have to look at both and figure out what of the 2 to use to stop the training\n",
        "                best_f1 = f1\n",
        "            else:\n",
        "                patience -= 1\n",
        "            if patience <= 0: # Early stopping with patience\n",
        "                break # Not nice but it keeps the code clean\n",
        "\n",
        "  results_test, intent_test, _ = eval_loop_adv(test_loader, criterion_slots, \n",
        "                                          criterion_intents, model, lang)    \n",
        "  print('\\nSlot F1: ', results_test['total']['f'])\n",
        "  print('Intent Accuracy:', intent_test['accuracy'])\n",
        "  return sampled_epochs, losses_train, losses_dev"
      ],
      "metadata": {
        "id": "BL14A-BRqszl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_try(train_loader, test_loader, dev_loader, model, optimizer, lang, n_epochs=200, patience=3, train=True):\n",
        " \n",
        "  losses_train = []\n",
        "  loss_intent_train = []\n",
        "  loss_slot_train = []\n",
        "  losses_dev = [] \n",
        "  loss_intent_dev_array = []\n",
        "  loss_slot_dev_array= []\n",
        "\n",
        "  sampled_epochs = []\n",
        "  best_f1 = 0\n",
        "  for x in tqdm(range(1,n_epochs)):\n",
        "      if train:\n",
        "        loss, loss_intent, loss_slot = train_loop_try(train_loader, optimizer, criterion_slots, \n",
        "                          criterion_intents, model)\n",
        "        if x % 3 == 0:\n",
        "            sampled_epochs.append(x)\n",
        "            losses_train.append(np.asarray(loss).mean())\n",
        "            loss_intent_train.append(np.asarray(loss_intent).mean())\n",
        "            loss_slot_train.append(np.asarray(loss_slot).mean())\n",
        "\n",
        "            results_dev, intent_res, loss_dev, loss_intent_dev, loss_slot_dev = eval_loop_try(dev_loader, criterion_slots, \n",
        "                                                          criterion_intents, model, lang)\n",
        "            losses_dev.append(np.asarray(loss_dev).mean())\n",
        "            loss_intent_dev_array.append(np.asarray(loss_intent_dev).mean())\n",
        "            loss_slot_dev_array.append(np.asarray(loss_slot_dev).mean())\n",
        "            f1 = results_dev['total']['f']\n",
        "\n",
        "            \"\"\"if(x=50):\n",
        "              parameters = []\n",
        "              for param in model.parameters():\"\"\"\n",
        "\n",
        "            \n",
        "            if f1 > best_f1: #sometimes loss words but f1 increases, we have to look at both and figure out what of the 2 to use to stop the training\n",
        "                best_f1 = f1\n",
        "            else:\n",
        "                patience -= 1\n",
        "            if patience <= 0: # Early stopping with patience\n",
        "                break # Not nice but it keeps the code clean\n",
        "\n",
        "  results_test, intent_test, _ , _ , _ = eval_loop_try(test_loader, criterion_slots, \n",
        "                                          criterion_intents, model, lang)    \n",
        "  print('\\nSlot F1: ', results_test['total']['f'])\n",
        "  print('Intent Accuracy:', intent_test['accuracy'])\n",
        "  return sampled_epochs, losses_train, losses_dev, loss_intent_train, loss_slot_train, loss_intent_dev_array, loss_slot_dev_array"
      ],
      "metadata": {
        "id": "OjTY-FQCKlgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_multiple_runs_try(train_loader, test_loader, dev_loader, model, criterion_slots, criterion_intents, optimizer, lang, n_epochs=200, patience=3, runs=5):\n",
        "  slot_f1s, intent_acc = [], []\n",
        "  tot_losses_train, tot_losses_dev = [], []\n",
        "  tot_losses_intent_train, tot_losses_intent_dev = [], []\n",
        "  tot_losses_slot_train, tot_losses_slot_dev = [], []\n",
        "  tot_sampled_epochs = []\n",
        "\n",
        "  for x in tqdm(range(0, runs)):\n",
        "      model.apply(init_weights)\n",
        "\n",
        "      losses_train = []\n",
        "      losses_dev = []\n",
        "      loss_intent_train = []\n",
        "      loss_slot_train = []\n",
        "      loss_intent_dev_array = []\n",
        "      loss_slot_dev_array= []\n",
        "\n",
        "      sampled_epochs = []\n",
        "      best_f1 = 0\n",
        "      for x in tqdm(range(1,n_epochs)):\n",
        "          loss, loss_intent, loss_slot = train_loop_try(train_loader, optimizer, criterion_slots, \n",
        "                            criterion_intents, model)\n",
        "          if x % 5 == 0:\n",
        "              sampled_epochs.append(x)\n",
        "              losses_train.append(np.asarray(loss).mean())\n",
        "              loss_intent_train.append(np.asarray(loss_intent).mean())\n",
        "              loss_slot_train.append(np.asarray(loss_slot).mean())\n",
        "              \n",
        "              results_dev, intent_res, loss_dev, loss_intent_dev, loss_slot_dev = eval_loop_try(dev_loader, criterion_slots, \n",
        "                                                            criterion_intents, model, lang)\n",
        "              losses_dev.append(np.asarray(loss_dev).mean())\n",
        "              loss_intent_dev_array.append(np.asarray(loss_intent_dev).mean())\n",
        "              loss_slot_dev_array.append(np.asarray(loss_slot_dev).mean())\n",
        "              f1 = results_dev['total']['f']\n",
        "\n",
        "              if f1 > best_f1:\n",
        "                  best_f1 = f1\n",
        "              else:\n",
        "                  patience -= 1\n",
        "              if patience <= 0: # Early stoping with patient\n",
        "                  break # Not nice but it keeps the code clean\n",
        "\n",
        "      results_test, intent_test, _ , _ , _  = eval_loop_try(test_loader, criterion_slots, \n",
        "                                              criterion_intents, model, lang)\n",
        "      intent_acc.append(intent_test['accuracy'])\n",
        "      slot_f1s.append(results_test['total']['f'])\n",
        "      tot_losses_train.append(losses_train)\n",
        "      tot_losses_dev.append(losses_dev)\n",
        "      tot_losses_intent_train.append(loss_intent_train)\n",
        "      tot_losses_intent_dev.append(loss_intent_dev_array)\n",
        "      tot_losses_slot_train.append(loss_slot_train)\n",
        "      tot_losses_slot_dev.append(loss_slot_dev_array) \n",
        "      tot_sampled_epochs.append(sampled_epochs)\n",
        "\n",
        "  slot_f1s = np.asarray(slot_f1s)\n",
        "  intent_acc = np.asarray(intent_acc)\n",
        "  print('\\nSlot F1', round(slot_f1s.mean(),3), '+-', round(slot_f1s.std(),3))\n",
        "  print('Intent Acc', round(intent_acc.mean(), 3), '+-', round(slot_f1s.std(), 3))\n",
        "  return tot_sampled_epochs, tot_losses_train, tot_losses_dev, tot_losses_intent_train, tot_losses_slot_train, tot_losses_intent_dev, tot_losses_slot_dev"
      ],
      "metadata": {
        "id": "yMDY__XpNPzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BihEwceONnog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fdict = {}\n",
        "for k, v in ATIS_tot_intent_test[0].items():\n",
        "  fdict[k] = v['f1-score']\n",
        "\n",
        "plt.barh(list(fdict.keys()), list(fdict.values()), align = 'center')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U8qEHaeNNnrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SNIPS_tot_intent_test[0].pop('accuracy')\n",
        "fdict = {}\n",
        "for k, v in SNIPS_tot_intent_test[0].items():\n",
        "  fdict[k] = v['f1-score']\n",
        "\n",
        "plt.barh(list(fdict.keys()), list(fdict.values()), align = 'center')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mEX_0D7cPohU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HDBDy63VGJ0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "T_ypHgz6GJ6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JrwJzYLzGJ8O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}